{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# import all libraries that will be used in this notebook\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import regex as re\n",
    "import time\n",
    "import warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup   \n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "depanx = pd.read_csv('./data/depanx.csv')\n",
    "depanx.drop(columns = 'Unnamed: 0', inplace = True)\n",
    "\n",
    "\n",
    "depds = pd.read_csv('./data/depds.csv')\n",
    "depds.drop(columns = 'Unnamed: 0', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1502, 2)\n",
      "(1484, 2)\n"
     ]
    }
   ],
   "source": [
    "print(depanx.shape)\n",
    "print(depds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Handling the Missing Values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    749\n",
       "1    719\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depanx.dropna(axis = 0, inplace = True)\n",
    "depanx.reset_index(inplace = True)\n",
    "depanx['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Welcome to /r/depression's check-in post - a p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>instead of called in from work or breaking dow...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>you can stay alive to witness 4/20/69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>**Behaviour**\\n\\n* not going out anymore\\n* no...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A few weeks ago i was ready to end it all. I w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                post  label\n",
       "0  Welcome to /r/depression's check-in post - a p...      0\n",
       "1  instead of called in from work or breaking dow...      0\n",
       "2              you can stay alive to witness 4/20/69      0\n",
       "3  **Behaviour**\\n\\n* not going out anymore\\n* no...      0\n",
       "4  A few weeks ago i was ready to end it all. I w...      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depanx.drop(columns = 'index', inplace = True)\n",
    "depanx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    747\n",
       "1    606\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depds.dropna(axis = 0, inplace = True)\n",
    "depds.reset_index(inplace = True)\n",
    "depds['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Welcome to /r/depression's check-in post - a p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yesterday a friend told me that. To be honest,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As bad as things may be, right now... the worl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I just want to get this shit out and feel bett...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I wonder how many of us can relate to [this ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                post  label\n",
       "0  Welcome to /r/depression's check-in post - a p...      0\n",
       "1  Yesterday a friend told me that. To be honest,...      0\n",
       "2  As bad as things may be, right now... the worl...      0\n",
       "3  I just want to get this shit out and feel bett...      0\n",
       "4  I wonder how many of us can relate to [this ar...      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depds.drop(columns = 'index', inplace = True)\n",
    "depds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view what a typical post looks like to determine what kind of natural language or html artifacts we need to remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A few weeks ago i was ready to end it all. I was working out the where,when and how of it when i decided to visit a cam site i used to frequent. A girl i used to watch and lurk in here chat room was on after a few years of me not seeing her. Something told me to stop in one last time. It ended up being one of the best decision i have ever made. Somehow we struck up a conversation out of thin air. The conversation continued the next night. And the next. Surprisingly i had forgotten all about my plans. I ACTUALLY started looking forward to the next day and our next conversation. Fast forward a few weeks and I'm still here. Still talking to her almost daily. I don't know if it will last, but for today I'm still here and for that i will always be grateful to the unlikeliest person in the world a CAM GIRL!!!!\\n\\n\\n\\n\\nEdit: This is my first post on Reddit I did not expect such a response.    I felt I should clarify some of this. Yes she is a cam girl and that is how we meet. But over the weeks it has transitioned into a friendship I didn't expect. No I'm not expecting a relationship or really anything from her. It's just she has been through some dark days herself so we can just talk to each other when we want/need to about the things people without mental illness just don't understand or whatever we feel like talking about. The point of the post was that I found a genuine friend in the last place I would expect. And maybe if I can find some one like that in the weirdest way possible all hope isn't lost yet. \""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depanx.loc[4, 'post']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Cleaning Up the Posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Credit goes to Matt form General Assmebly for cleaning up the posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define some functions that will help strip html and unnecessary natural language artifacts such as punctuaion off the posts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def posts_to_words(raw_post):\n",
    "    # Function to convert a raw post to a string of words\n",
    "    # The input is a single string (a raw subreddit post), and \n",
    "    # the output is a single string (a preprocessed subreddit post)\n",
    "    \n",
    "    # 1. Remove HTML.\n",
    "    post_text = BeautifulSoup(raw_post).get_text()\n",
    "    \n",
    "    # 2. Remove non-letters.\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", post_text)\n",
    "    \n",
    "    # 3. Convert to lower case, split into individual words.\n",
    "    words = letters_only.lower().split()\n",
    "    \n",
    "    # 4. In Python, searching a set is much faster than searching\n",
    "    # a list, so convert the stop words to a set.\n",
    "    stops = set(stopwords.words('english'))\n",
    " \n",
    "    \n",
    "    # 5. Remove stop words.\n",
    "    meaningful_words = [w for w in words if not w in stops]\n",
    "    \n",
    "    # 6. Join the words back into one string separated by space, \n",
    "    # and return the result.\n",
    "    return(\" \".join(meaningful_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_posts(data):\n",
    "\n",
    "    print(\"Cleaning and parsing posts...\")\n",
    "\n",
    "    j = 0\n",
    "    for post in data:\n",
    "        # Convert review to words, then append to clean_train_reviews.\n",
    "        clean.append(posts_to_words(post))\n",
    "    \n",
    "        # If the index is divisible by 1000, print a message\n",
    "        if (j + 1) % 1000 == 0:\n",
    "            print(f'Review {j + 1} of {total_posts}.')\n",
    "        \n",
    "        j += 1\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Cleaning Depression and Anxiety Posts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1468 posts.\n"
     ]
    }
   ],
   "source": [
    "# Get the number of posts based on the depanx dataframe size.\n",
    "total_posts = depanx.shape[0]\n",
    "print(f'There are {total_posts} posts.')\n",
    "\n",
    "# Initialize an empty list to hold the clean posts.\n",
    "clean = []\n",
    "#clean_test_posts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/bs4/__init__.py:336: UserWarning: \"https://positivepsychologyprogram.com/challenging-automatic-thoughts-positive-thoughts-worksheets/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1000 of 1468.\n"
     ]
    }
   ],
   "source": [
    "clean_depanx = clean_posts(depanx['post'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "behaviour going anymore getting things done work school withdrawing close family friends relying alcohol sedatives usual enjoyable activities unable concentrate feelings overwhelmed guilty irritable frustrated lacking confidence unhappy indecisive disappointed miserable sad thoughts failure fault nothing good ever happens worthless life worth living people would better without physical tired time sick run headaches muscle pains churning gut sleep problems loss change appetite significant weight loss gain\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"**Behaviour**\\n\\n* not going out anymore\\n* not getting things done at work/school\\n* withdrawing from close family and friends\\n* relying on alcohol and sedatives\\n* not doing usual enjoyable activities\\n* unable to concentrate\\n\\n**Feelings**\\n\\n* overwhelmed\\n* guilty\\n* irritable\\n* frustrated\\n* lacking in confidence\\n* unhappy\\n* indecisive\\n* disappointed\\n* miserable\\n* sad\\n\\n**Thoughts**\\n\\n* 'I’m a failure.'\\n* 'It’s my fault.'\\n* 'Nothing good ever happens to me.'\\n* 'I’m worthless.'\\n* 'Life’s not worth living.'\\n* 'People would be better off without me.'\\n\\n**Physical**\\n\\n* tired all the time\\n* sick and run down\\n* headaches and muscle pains\\n* churning gut\\n* sleep problems\\n* loss or change of appetite\\n* significant weight loss or gain\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view and compare cleaned and uncleaned posts\n",
    "print(clean_depanx[3]) # cleaned post\n",
    "depanx['post'][3] # uncleaned post"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Cleaning Depression and Data Science Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1353 posts.\n"
     ]
    }
   ],
   "source": [
    "# Get the number of posts based on the depanx dataframe size.\n",
    "total_posts = depds.shape[0]\n",
    "print(f'There are {total_posts} posts.')\n",
    "\n",
    "# Initialize an empty list to hold the clean posts.\n",
    "clean = []\n",
    "#clean_test_posts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing posts...\n",
      "Review 1000 of 1353.\n"
     ]
    }
   ],
   "source": [
    "clean_depds = clean_posts(depds['post'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning python little r fairly new programming goal mind want make sure spending time learning right things moving right direction help offer would appreciated\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I have been learning Python and a little R, and am fairly new to programming, but this is the goal I have in mind. I want to make sure I am spending time on learning the right things and moving in the right direction. Any help you can offer would be appreciated!'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view and compare cleaned  and uncleaned posts\n",
    "print(clean_depds[1002]) # clean post\n",
    "depds['post'][1002] # unclean post "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Checking Our Expectations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In notebook **1. Problem Statement and Getting Data** I laid out the expectation that the ROC AUC score for depression and data science data will be higher than the ROC AUC score for depression and anxiety data. This is because I assumed that given the disimilarity between depression and data science posts, the classifier model will better be able to predict the correct subreddit from which a given post originated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1.  Define X and y for depression and anxiety data and apply train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = clean_depanx\n",
    "y = depanx['label']\n",
    "X_train_depanx, X_test_depanx, y_train_depanx, y_test_depanx = train_test_split(X, y, random_state = 42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    562\n",
      "1    539\n",
      "Name: label, dtype: int64\n",
      "0    187\n",
      "1    180\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_train_depanx.value_counts())\n",
    "print(y_test_depanx.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2. Apply CountVectorizer() on depanx data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/numpy/matrixlib/defmatrix.py:71: PendingDeprecationWarning: the matrix subclass is not the recommended way to represent matrices or deal with linear algebra (see https://docs.scipy.org/doc/numpy/user/numpy-for-matlab-users.html). Please adjust your code to use regular ndarray.\n",
      "  return matrix(data, dtype=dtype, copy=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<1101x8918 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 71412 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate the vectorizer \n",
    "vec = CountVectorizer()\n",
    "\n",
    "# fit and transform on train data\n",
    "X_train_depanx = vec.fit_transform(X_train_depanx)\n",
    "\n",
    "# transform only on test data\n",
    "X_test_depanx = vec.transform(X_test_depanx)\n",
    "\n",
    "X_train_depanx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the sparse matrix into a dataframe\n",
    "train_df = pd.DataFrame(X_train_depanx.toarray(), columns = vec.get_feature_names())\n",
    "test_df = pd.DataFrame(X_test_depanx.toarray(), columns = vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>aborted</th>\n",
       "      <th>abroad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   able  aborted  abroad\n",
       "4     0        0       0\n",
       "5     0        0       0\n",
       "6     0        0       0\n",
       "7     0        0       0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view vectorized test data \n",
    "test_df.iloc[4:8, 9:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.3. Build a Naive Bayes model and compute the AUC score for depression and anxiety posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's build a basi Naive Bayes model to predict on depression and anxiety data and compute the ROC AUC score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate Multinomial Naive Bayes \n",
    "mnb = MultinomialNB()\n",
    "\n",
    "# fit mnb on the depression and anxiety train data\n",
    "mnb.fit(X_train_depanx, y_train_depanx)\n",
    "\n",
    "# make predictions on depression and anxiety test data\n",
    "pred = mnb.predict(X_test_depanx)\n",
    "\n",
    "# make probability predictions on depression and anxiety test data\n",
    "pred_prob = mnb.predict_proba(X_test_depanx)\n",
    "\n",
    "# calculate the ROC AUC score \n",
    "auc_depanx = roc_auc_score(y_test_depanx, pred_prob[:,1])\n",
    "\n",
    "# extract tn, fp, fn, tp from confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test_depanx, pred).ravel()\n",
    "\n",
    "# plot the ROC curve \n",
    "fpr_depanx, tpr_depanx, thresholds = roc_curve(y_test_depanx, pred_prob[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's repeat steps 4.1.1 - 4.1.3. for depression and data science posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1.  Define X and y for depression and anxiety data and apply train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = clean_depds\n",
    "y = depds['label']\n",
    "X_train_depds, X_test_depds, y_train_depds, y_test_depds = train_test_split(X, y, random_state = 42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    560\n",
      "1    454\n",
      "Name: label, dtype: int64\n",
      "0    187\n",
      "1    152\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_train_depds.value_counts())\n",
    "print(y_test_depds.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2. Apply CountVectorizer() on depds data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/numpy/matrixlib/defmatrix.py:71: PendingDeprecationWarning: the matrix subclass is not the recommended way to represent matrices or deal with linear algebra (see https://docs.scipy.org/doc/numpy/user/numpy-for-matlab-users.html). Please adjust your code to use regular ndarray.\n",
      "  return matrix(data, dtype=dtype, copy=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<1014x9064 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 66743 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate the vectorizer \n",
    "vec = CountVectorizer()\n",
    "\n",
    "# fit and transform on train data\n",
    "X_train_depds = vec.fit_transform(X_train_depds)\n",
    "\n",
    "# transform only on test data\n",
    "X_test_depds = vec.transform(X_test_depds)\n",
    "\n",
    "X_train_depds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the sparse matrix into a dataframe\n",
    "train_df = pd.DataFrame(X_train_depds.toarray(), columns = vec.get_feature_names())\n",
    "test_df = pd.DataFrame(X_test_depds.toarray(), columns = vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abilities</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   abilities  ability  able\n",
       "4          0        0     0\n",
       "5          0        0     0\n",
       "6          0        0     0\n",
       "7          0        0     0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view vectorized test data \n",
    "test_df.iloc[4:8, 9:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3. Build a Naive Bayes model and compute the AUC score for depression and data science posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate Multinomial Naive Bayes \n",
    "mnb = MultinomialNB()\n",
    "\n",
    "# fit mnb on the depression and anxiety train data\n",
    "mnb.fit(X_train_depds, y_train_depds)\n",
    "\n",
    "# make predictions on depression and anxiety test data\n",
    "pred = mnb.predict(X_test_depds)\n",
    "\n",
    "# make probability predictions on depression and anxiety test data\n",
    "pred_prob = mnb.predict_proba(X_test_depds)\n",
    "\n",
    "# calculate the ROC AUC score \n",
    "auc_depds = roc_auc_score(y_test_depds, pred_prob[:,1])\n",
    "\n",
    "# extract tp, fp, fn and tp from confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test_depds, pred).ravel()\n",
    "\n",
    "# plot the ROC curve \n",
    "fpr_depds, tpr_depds, thresholds = roc_curve(y_test_depds, pred_prob[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Compare the ROC AUC scores as well as the ROC curves for depression and anxiety posts vs depression and data science posts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc score for depression and anxiety posts:  0.8869281045751635\n",
      "auc score for depression and data science posts:  0.9997185477061639\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test_depds, pred_prob[:,1])\n",
    "plt.plot(fpr_depanx, tpr_depanx)\n",
    "plt.plot(fpr_depds, tpr_depds)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "\n",
    "print('auc score for depression and anxiety posts: ', auc_depanx)\n",
    "print('auc score for depression and data science posts: ', auc_depds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AUC score for data that includes depression and data science posts is significantly higher than the AUC score for data that includes depression and anxiety posts. Also inspecting the ROC curves for the two datasets, it is clear that the model trained on depression and data science data (orange curve) is a lot more powerful in predictions than the model trained on depression and anxiety data. This is expected and confirms our assumption that disimilar posts will yield models with higher predictive power. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While a more formal hypohtese test can be conducted here to quantify the significance of the difference between the AUC scores in the two cases, I will forgo doing formal hypotheses tests due to the fact that the ROC curves and the AUC scores above make it very apparent that there is a difference. For the purposes of this project, this will suffice.\n",
    "\n",
    "**Note:** If we were to conduct a hypotheses test, this is what it would look like: \n",
    "\n",
    "**H0**: ROC AUC score (r/depression and r/datascience) = ROC AUC score (r/depression and r/anxiety)<br/>\n",
    "<br/>\n",
    "**HA**: ROC AUC score (r/depression and r/datascience) > ROC AUC score (r/depression and r/anxiety)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have confirmed that a strong similarity between narratives coming from the two posts will indeed make it harder for an ML model to separate the two, we can expect that we probably won't be able to build a model with very strong predictive power without doing some significant feature engineering. This project does not rely on thorough feature engineering. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here on, I will move on with only the depression and anxiety posts to build the models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the clean depression and anxiety data to a csv\n",
    "clean_data = pd.concat([pd.DataFrame(clean_depanx, columns = ['post']), depanx['label']], axis = 1)\n",
    "clean_data.to_csv('./data/clean_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
