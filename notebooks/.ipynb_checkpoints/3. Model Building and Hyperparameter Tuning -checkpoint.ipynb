{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all libraries that will be used in this notebook\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import regex as re\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, VotingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "import time\n",
    "import warnings\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "#!pip install pactools\n",
    "#warnings.filterwarnings('ignore')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pactools.grid_search import GridSearchCVProgressBar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_csv('./data/clean_data.csv')\n",
    "dat.drop(columns = 'Unnamed: 0', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>welcome r depression check post place take mom...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>instead called work breaking shift cry drive w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stay alive witness</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>behaviour going anymore getting things done wo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weeks ago ready end working decided visit cam ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                post  label\n",
       "0  welcome r depression check post place take mom...      0\n",
       "1  instead called work breaking shift cry drive w...      0\n",
       "2                                 stay alive witness      0\n",
       "3  behaviour going anymore getting things done wo...      0\n",
       "4  weeks ago ready end working decided visit cam ...      0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1463</th>\n",
       "      <td>anxiety bad long time one simple reason im hol...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1464</th>\n",
       "      <td>hysterectomy due fibroids although gotten clea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>long story short started counseling last year ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>hi guys girls hope well quick summary life suf...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>sooo exhausted f always edge reason poor boyfr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   post  label\n",
       "1463  anxiety bad long time one simple reason im hol...      1\n",
       "1464  hysterectomy due fibroids although gotten clea...      1\n",
       "1465  long story short started counseling last year ...      1\n",
       "1466  hi guys girls hope well quick summary life suf...      1\n",
       "1467  sooo exhausted f always edge reason poor boyfr...      1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "post     0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.dropna(axis = 0, inplace = True)\n",
    "dat.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    749\n",
       "1    718\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Define X, y and apply train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1467\n",
      "(1467,)\n"
     ]
    }
   ],
   "source": [
    "X = list(dat['post'])\n",
    "y = dat['label']\n",
    "print(len(X))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    562\n",
       "1    538\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    187\n",
       "1    180\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Establish the baseline accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a classification problem, the baseline accuracy is computed with the percentage of the majority class. This means that if we had a null model without any predictive power, it would always be predicting the majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.510566\n",
       "1    0.489434\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat['label'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our baseline accuracy score is 51%. If we were to ask a null model to make predictions on our data, the model would be correct in its predictions 51% of the time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Customize stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I add some words to the standard english stopwords to pass this custom list of stop words as another parameter into a grid search. I want to pass this as a parameter to ensure that we are grid searching on a model that excudes words such as **depression**, **anxiety** and derivative words thereof from its feature space. The reason I want to remove these words is because they are the key words that basically define the classes that I want to predict. I'm curious to see how the model performs with the otpions of not having these words in its feature space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_custom = stopwords.words(\"english\") + ['depression', 'depressive', 'depressed', 'anxiety', 'anxious']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Create a function that builds a model, tunes hyperparameters and evaluates the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid redeundancy in large blocks of code, I have created a function that creates a pipeline for model building, does hyperparameter tuning with gridsearch and outputs a variety of evaluation metrics for the best model. This function takes in as arguments our train and test data, a vectorizer transformer (tfidf or count vectorizer) and a classification model for its pipeline, and a dictionary of hyperparameters to do a grid search over. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipe_gs(X_train, X_test, y_train, y_test, vec, pipe_params):\n",
    "    \n",
    "    # build a pipeline \n",
    "    pipe = Pipeline([\n",
    "        ('vec', vec), # pass a vectorizer to the pipeline \n",
    "        ('clf', clf)  # pass a classification model to the pipeline \n",
    "    ])\n",
    "    \n",
    "    # set a dictionary of parameters to tune over\n",
    "    pipe_params \n",
    "    \n",
    "    # do a grid search over the parameters specified in pipe_params and then do a 3-fold cross valiation\n",
    "    gs = GridSearchCVProgressBar(pipe, param_grid=pipe_params, cv=3, verbose = 1, n_jobs = 4)\n",
    "    gs.fit(X_train, y_train)\n",
    "    print('')\n",
    "    print('')\n",
    "    \n",
    "    # best parameters \n",
    "    print('best paramteres: '+str(gs.best_params_))\n",
    "    print('')\n",
    "    print('')\n",
    "   \n",
    "    # cross_val score \n",
    "    cv_score = gs.best_score_\n",
    "  \n",
    "    # training score \n",
    "    train_score = gs.score(X_train, y_train)\n",
    "   \n",
    "    # testing score \n",
    "    test_score = gs.score(X_test, y_test)\n",
    "   \n",
    "    # predictions of the best model \n",
    "    y_pred = gs.predict(X_test)\n",
    "    \n",
    "    # accuracy score \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # print('confusion matrix: '+str(confusion_matrix(y_test,y_pred)))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test,y_pred).ravel()\n",
    "    \n",
    "    # sensitivity\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    \n",
    "    # specificity \n",
    "    specificity = tn / (tn + fp)\n",
    "    \n",
    "    # precision \n",
    "    precision = tp / (tp + fp)\n",
    "    \n",
    "    # misclassification\n",
    "    misclass = 1 - accuracy \n",
    "    \n",
    "    # predicted pprobabilites of the best model\n",
    "    y_pred_prob = gs.predict_proba(X_test)[:,1] \n",
    "    \n",
    "    # auc score \n",
    "    auc = roc_auc_score(y_test, y_pred_prob)\n",
    "    \n",
    "    # plot the ROC curve \n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    \n",
    "    metric_names =  ['cross val score', \n",
    "                     'train score', \n",
    "                     'test score', \n",
    "                     'accuracy', \n",
    "                     'misclassification', \n",
    "                     'true positives', \n",
    "                     'true negatives', \n",
    "                     'false positives', \n",
    "                     'false negatives', \n",
    "                     'sensitivity (tpr)', \n",
    "                     'specificity (tnr)',\n",
    "                     'precision (ppv)']\n",
    "    \n",
    "    metrics = [cv_score, \n",
    "               train_score, \n",
    "               test_score, \n",
    "               accuracy, \n",
    "               misclass, \n",
    "               tp, \n",
    "               tn, \n",
    "               fp, \n",
    "               fn, \n",
    "               sensitivity, \n",
    "               specificity, \n",
    "               precision]\n",
    "    \n",
    "    d = {'metric':metric_names, \n",
    "         'value': metrics}\n",
    "   \n",
    "    df = pd.DataFrame(d)\n",
    "      \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will demonstrate using this function in the case of logistic regression to show the type of output the function creates. I will then provide the code for calling the function for a variety of other models with their specific parameters. However, I will not actually run the code in the case of every remaining model in this notebook due to 1. computational expense, 2.time it will take to run the gridsearch over every single model and 3. the clutter that will be created as a result of pupulating this notebook with the outputs. I have of course done this previously and saved the output of every model in a separate file. The results are shown graphically and are discussed in notebook **4. Model Evaluation and Final Model Selection**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Building and Evaluating Models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.1. Logistic Regression pipeline with count vectorizer with default parameters - no GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/numpy/matrixlib/defmatrix.py:71: PendingDeprecationWarning: the matrix subclass is not the recommended way to represent matrices or deal with linear algebra (see https://docs.scipy.org/doc/numpy/user/numpy-for-matlab-users.html). Please adjust your code to use regular ndarray.\n",
      "  return matrix(data, dtype=dtype, copy=False)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8299477310525066\n",
      "0.9972727272727273\n",
      "0.8147138964577657\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('vec', CountVectorizer(stop_words = 'english')),\n",
    "    ('lr', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Evaluate how your model will perform on unseen data\n",
    "print(cross_val_score(pipe, X_train, y_train, cv=3).mean())\n",
    "# Fit your model\n",
    "pipe.fit(X_train, y_train)\n",
    "# Training score\n",
    "print(pipe.score(X_train, y_train))\n",
    "# Test score\n",
    "print(pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.1. Logistic Regression pipeline with count vectorizer and GridSaerch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1728 candidates, totalling 5184 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   18.7s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:   41.9s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=4)]: Done 1792 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=4)]: Done 2442 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=4)]: Done 3192 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=4)]: Done 4042 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=4)]: Done 4992 tasks      | elapsed:  8.1min\n",
      "[Parallel(n_jobs=4)]: Done 5184 out of 5184 | elapsed:  8.4min finished\n",
      "/anaconda3/lib/python3.7/site-packages/numpy/matrixlib/defmatrix.py:71: PendingDeprecationWarning: the matrix subclass is not the recommended way to represent matrices or deal with linear algebra (see https://docs.scipy.org/doc/numpy/user/numpy-for-matlab-users.html). Please adjust your code to use regular ndarray.\n",
      "  return matrix(data, dtype=dtype, copy=False)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "best paramteres: {'clf__C': 0.5, 'clf__penalty': 'l1', 'vec__max_df': 0.7, 'vec__max_features': 800, 'vec__min_df': 20, 'vec__ngram_range': (1, 2), 'vec__stop_words': 'english'}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cross val score</td>\n",
       "      <td>0.846364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train score</td>\n",
       "      <td>0.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test score</td>\n",
       "      <td>0.798365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.798365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>misclassification</td>\n",
       "      <td>0.201635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>true positives</td>\n",
       "      <td>129.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>true negatives</td>\n",
       "      <td>164.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>false positives</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>false negatives</td>\n",
       "      <td>51.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sensitivity (tpr)</td>\n",
       "      <td>0.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>specificity (tnr)</td>\n",
       "      <td>0.877005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>precision (ppv)</td>\n",
       "      <td>0.848684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               metric       value\n",
       "0     cross val score    0.846364\n",
       "1         train score    0.920000\n",
       "2          test score    0.798365\n",
       "3            accuracy    0.798365\n",
       "4   misclassification    0.201635\n",
       "5      true positives  129.000000\n",
       "6      true negatives  164.000000\n",
       "7     false positives   23.000000\n",
       "8     false negatives   51.000000\n",
       "9   sensitivity (tpr)    0.716667\n",
       "10  specificity (tnr)    0.877005\n",
       "11    precision (ppv)    0.848684"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vec = CountVectorizer()\n",
    "clf = LogisticRegression()\n",
    "\n",
    "pipe_params = {'vec__max_features': [800, 1000, 1500],\n",
    " 'vec__min_df': [10, 15, 20, 25],\n",
    " 'vec__max_df': [.7, .8, .9, 1.0],\n",
    " 'vec__ngram_range': [(1,1), (1,2),(1,3)],\n",
    " 'vec__stop_words':['english', stop_words_custom],\n",
    " 'clf__penalty':['l1', 'l2'],\n",
    " 'clf__C':[0.1, 0.5, 0.99]}\n",
    "\n",
    "pipe_gs(X_train, X_test, y_train, y_test, vec, pipe_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.3. Logistic Regression pipeline with count tfidf vectorizer with default parameters - no GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/numpy/matrixlib/defmatrix.py:71: PendingDeprecationWarning: the matrix subclass is not the recommended way to represent matrices or deal with linear algebra (see https://docs.scipy.org/doc/numpy/user/numpy-for-matlab-users.html). Please adjust your code to use regular ndarray.\n",
      "  return matrix(data, dtype=dtype, copy=False)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8417973390354003\n",
      "0.9709090909090909\n",
      "0.8228882833787466\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('vec', TfidfVectorizer(stop_words = 'english')),\n",
    "    ('lr', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Evaluate how your model will perform on unseen data\n",
    "print(cross_val_score(pipe, X_train, y_train, cv=3).mean())\n",
    "# Fit your model\n",
    "pipe.fit(X_train, y_train)\n",
    "# Training score\n",
    "print(pipe.score(X_train, y_train))\n",
    "# Test score\n",
    "print(pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.1. Logistic Regression pipeline with tfidf vectorizer and GridSaerch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1728 candidates, totalling 5184 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   20.7s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:   44.7s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=4)]: Done 1792 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=4)]: Done 2442 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=4)]: Done 3192 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=4)]: Done 4042 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=4)]: Done 4992 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=4)]: Done 5184 out of 5184 | elapsed:  8.8min finished\n",
      "/anaconda3/lib/python3.7/site-packages/numpy/matrixlib/defmatrix.py:71: PendingDeprecationWarning: the matrix subclass is not the recommended way to represent matrices or deal with linear algebra (see https://docs.scipy.org/doc/numpy/user/numpy-for-matlab-users.html). Please adjust your code to use regular ndarray.\n",
      "  return matrix(data, dtype=dtype, copy=False)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "best paramteres: {'clf__C': 0.99, 'clf__penalty': 'l2', 'vec__max_df': 0.7, 'vec__max_features': 800, 'vec__min_df': 15, 'vec__ngram_range': (1, 1), 'vec__stop_words': 'english'}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cross val score</td>\n",
       "      <td>0.845455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train score</td>\n",
       "      <td>0.932727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test score</td>\n",
       "      <td>0.822888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.822888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>misclassification</td>\n",
       "      <td>0.177112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>true positives</td>\n",
       "      <td>135.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>true negatives</td>\n",
       "      <td>167.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>false positives</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>false negatives</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sensitivity (tpr)</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>specificity (tnr)</td>\n",
       "      <td>0.893048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>precision (ppv)</td>\n",
       "      <td>0.870968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               metric       value\n",
       "0     cross val score    0.845455\n",
       "1         train score    0.932727\n",
       "2          test score    0.822888\n",
       "3            accuracy    0.822888\n",
       "4   misclassification    0.177112\n",
       "5      true positives  135.000000\n",
       "6      true negatives  167.000000\n",
       "7     false positives   20.000000\n",
       "8     false negatives   45.000000\n",
       "9   sensitivity (tpr)    0.750000\n",
       "10  specificity (tnr)    0.893048\n",
       "11    precision (ppv)    0.870968"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vec = TfidfVectorizer()\n",
    "clf = LogisticRegression()\n",
    "\n",
    "pipe_params = {'vec__max_features': [800, 1000, 1500],\n",
    " 'vec__min_df': [10, 15, 20, 25],\n",
    " 'vec__max_df': [.7, .8, .9, 1.0],\n",
    " 'vec__ngram_range': [(1,1), (1,2),(1,3)],\n",
    " 'vec__stop_words':['english', stop_words_custom],\n",
    " 'clf__penalty':['l1', 'l2'],\n",
    " 'clf__C':[0.1, 0.5, 0.99]}\n",
    "\n",
    "pipe_gs(X_train, X_test, y_train, y_test, vec, pipe_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2. Naive Bayes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.1. Naive Bayes pipeline with count vectorizer with default parameters - no GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('vec', CountVectorizer(stop_words = 'english')),\n",
    "    ('mnb', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Evaluate how your model will perform on unseen data\n",
    "print(cross_val_score(pipe, X_train, y_train, cv=3).mean())\n",
    "# Fit your model\n",
    "pipe.fit(X_train, y_train)\n",
    "# Training score\n",
    "print(pipe.score(X_train, y_train))\n",
    "# Test score\n",
    "print(pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.2. Naive Bayes pipeline with count vectorizer with GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer()\n",
    "clf = MultinomialNB()\n",
    "\n",
    "pipe_params = {\n",
    "        'vec__max_features': [800, 1000, 1500],\n",
    "        'vec__min_df': [10, 15, 20, 25],\n",
    "        'vec__max_df': [.7, .8, .9, 1.0],\n",
    "        'vec__ngram_range': [(1,1), (1,2),(1,3)],\n",
    "        'vec__stop_words':['english', stop_words_mod],\n",
    "        'clf__alpha':[0.0, 1.0]\n",
    "    }\n",
    "\n",
    "pipe_gs(X_train, X_test, y_train, y_test, vec, pipe_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.3. Naive Bayes pipeline with tfidf vectorizer with default parameters - no GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('vec', TfidfVectorizer(stop_words = 'english')),\n",
    "    ('mnb', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Evaluate how your model will perform on unseen data\n",
    "print(cross_val_score(pipe, X_train, y_train, cv=3).mean())\n",
    "# Fit your model\n",
    "pipe.fit(X_train, y_train)\n",
    "# Training score\n",
    "print(pipe.score(X_train, y_train))\n",
    "# Test score\n",
    "print(pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.4. Naive Bayes pipeline with tfidf vectorizer with GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer()\n",
    "clf = MultinomialNB()\n",
    "\n",
    "pipe_params = {\n",
    "        'vec__max_features': [800, 1000, 1500],\n",
    "        'vec__min_df': [10, 15, 20, 25],\n",
    "        'vec__max_df': [.7, .8, .9, 1.0],\n",
    "        'vec__ngram_range': [(1,1), (1,2),(1,3)],\n",
    "        'vec__stop_words':['english', stop_words_mod],\n",
    "        'clf__alpha':[0.0, 1.0]\n",
    "    }\n",
    "\n",
    "pipe_gs(X_train, X_test, y_train, y_test, vec, pipe_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3. K-Nearest Neighbors  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.1. KNN pipeline with count vectorizer with default parameters - no GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('vec', CountVectorizer(stop_words = 'english')),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# Evaluate how your model will perform on unseen data\n",
    "print(cross_val_score(pipe, X_train, y_train, cv=3).mean())\n",
    "# Fit your model\n",
    "pipe.fit(X_train, y_train)\n",
    "# Training score\n",
    "print(pipe.score(X_train, y_train))\n",
    "# Test score\n",
    "print(pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.2. KNN pipeline with count vectorizer with GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer()\n",
    "clf = KNeighborsClassifier()\n",
    "\n",
    "pipe_params = {\n",
    "        'vec__max_features': [800, 1000, 1500],\n",
    "        'vec__min_df': [10, 15, 20, 25],\n",
    "        'vec__max_df': [.7, .8, .9, 1.0],\n",
    "        'vec__ngram_range': [(1,1), (1,2),(1,3)],\n",
    "        'vec__stop_words':['english', stop_words_mod],\n",
    "        'clf__n_neighbors':[20, 30, 40, 50],\n",
    "        'clf__weights':['uniform', 'distance'],\n",
    "        'clf__p':[1, 2]\n",
    "    }\n",
    "\n",
    "pipe_gs(X_train, X_test, y_train, y_test, vec, pipe_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.3. KNN pipeline with tfidf vectorizer with default parameters - no GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('vec', TfidfVectorizer(stop_words = 'english')),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# Evaluate how your model will perform on unseen data\n",
    "print(cross_val_score(pipe, X_train, y_train, cv=3).mean())\n",
    "# Fit your model\n",
    "pipe.fit(X_train, y_train)\n",
    "# Training score\n",
    "print(pipe.score(X_train, y_train))\n",
    "# Test score\n",
    "print(pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.4. KNN pipeline with tfidf vectorizer with GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer()\n",
    "clf = KNeighborsClassifier()\n",
    "\n",
    "pipe_params = {\n",
    "        'vec__max_features': [800, 1000, 1500],\n",
    "        'vec__min_df': [10, 15, 20, 25],\n",
    "        'vec__max_df': [.7, .8, .9, 1.0],\n",
    "        'vec__ngram_range': [(1,1), (1,2),(1,3)],\n",
    "        'vec__stop_words':['english', stop_words_mod],\n",
    "        'clf__n_neighbors':[20, 30, 40, 50],\n",
    "        'clf__weights':['uniform', 'distance'],\n",
    "        'clf__p':[1, 2]\n",
    "    }\n",
    "\n",
    "pipe_gs(X_train, X_test, y_train, y_test, vec, pipe_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4. Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.1. Decision Tree pipeline with count vectorizer with default parameters - no GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('vec', CountVectorizer(stop_words = 'english')),\n",
    "    ('dt', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "# Evaluate how your model will perform on unseen data\n",
    "print(cross_val_score(pipe, X_train, y_train, cv=3).mean())\n",
    "# Fit your model\n",
    "pipe.fit(X_train, y_train)\n",
    "# Training score\n",
    "print(pipe.score(X_train, y_train))\n",
    "# Test score\n",
    "print(pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.2. Decision Tree pipeline with count vectorizer with GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer()\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "pipe_params = {\n",
    "        'vec__max_features': [800, 1000, 1500],\n",
    "        'vec__min_df': [10, 15, 20, 25],\n",
    "        'vec__max_df': [.7, .8, .9, 1.0],\n",
    "        'vec__ngram_range': [(1,1), (1,2),(1,3)],\n",
    "        'vec__stop_words':['english', stop_words_mod],\n",
    "        'clf__max_depth':[2,3],\n",
    "        'clf__min_samples_split':[2,5,10]\n",
    "    }\n",
    "\n",
    "pipe_gs(X_train, X_test, y_train, y_test, vec, pipe_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.3. Decision Tree pipeline with tfidf vectorizer with default parameters - no GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('vec', TfidfVectorizer(stop_words = 'english')),\n",
    "    ('dt', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "# Evaluate how your model will perform on unseen data\n",
    "print(cross_val_score(pipe, X_train, y_train, cv=3).mean())\n",
    "# Fit your model\n",
    "pipe.fit(X_train, y_train)\n",
    "# Training score\n",
    "print(pipe.score(X_train, y_train))\n",
    "# Test score\n",
    "print(pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.4. Decision Tree pipeline with tfidf vectorizer with GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer()\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "pipe_params = {\n",
    "        'vec__max_features': [800, 1000, 1500],\n",
    "        'vec__min_df': [10, 15, 20, 25],\n",
    "        'vec__max_df': [.7, .8, .9, 1.0],\n",
    "        'vec__ngram_range': [(1,1), (1,2),(1,3)],\n",
    "        'vec__stop_words':['english', stop_words_mod],\n",
    "        'clf__max_depth':[2,3],\n",
    "        'clf__min_samples_split':[2,5,10]\n",
    "    }\n",
    "\n",
    "pipe_gs(X_train, X_test, y_train, y_test, vec, pipe_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5. Bagging "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.1. Bagging pipeline with count vectorizer with default parameters - no GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('vec', CountVectorizer(stop_words = 'english')),\n",
    "    ('bag', BaggingClassifier())\n",
    "])\n",
    "\n",
    "# Evaluate how your model will perform on unseen data\n",
    "print(cross_val_score(pipe, X_train, y_train, cv=3).mean())\n",
    "# Fit your model\n",
    "pipe.fit(X_train, y_train)\n",
    "# Training score\n",
    "print(pipe.score(X_train, y_train))\n",
    "# Test score\n",
    "print(pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.2. Bagging pipeline with count vectorizer with GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer()\n",
    "clf = BaggingClassifier()\n",
    "\n",
    "pipe_params = {\n",
    "        'vec__max_features': [800, 1000, 1500],\n",
    "        'vec__min_df': [10, 15, 20, 25],\n",
    "        'vec__max_df': [.7, .8, .9, 1.0],\n",
    "        'vec__ngram_range': [(1,1), (1,2),(1,3)],\n",
    "        'vec__stop_words':['english', stop_words_mod],\n",
    "        'clf__n_estimators':[10, 20, 30]\n",
    "    }\n",
    "\n",
    "pipe_gs(X_train, X_test, y_train, y_test, vec, pipe_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.3. Bagging pipeline with tfidf vectorizer with default parameters - no GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('vec', TfidfVectorizer(stop_words = 'english')),\n",
    "    ('bag', BaggingClassifier())\n",
    "])\n",
    "\n",
    "# Evaluate how your model will perform on unseen data\n",
    "print(cross_val_score(pipe, X_train, y_train, cv=3).mean())\n",
    "# Fit your model\n",
    "pipe.fit(X_train, y_train)\n",
    "# Training score\n",
    "print(pipe.score(X_train, y_train))\n",
    "# Test score\n",
    "print(pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.4. Bagging pipeline with tfidf vectorizer with GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer()\n",
    "clf = BaggingClassifier()\n",
    "\n",
    "pipe_params = {\n",
    "        'vec__max_features': [800, 1000, 1500],\n",
    "        'vec__min_df': [10, 15, 20, 25],\n",
    "        'vec__max_df': [.7, .8, .9, 1.0],\n",
    "        'vec__ngram_range': [(1,1), (1,2),(1,3)],\n",
    "        'vec__stop_words':['english', stop_words_mod],\n",
    "        'clf__n_estimators':[10, 20, 30]\n",
    "    }\n",
    "\n",
    "pipe_gs(X_train, X_test, y_train, y_test, vec, pipe_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.6. Random Forest  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6.1. Random Forest pipeline with count vectorizer with default parameters - no GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('vec', CountVectorizer(stop_words = 'english')),\n",
    "    ('rf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Evaluate how your model will perform on unseen data\n",
    "print(cross_val_score(pipe, X_train, y_train, cv=3).mean())\n",
    "# Fit your model\n",
    "pipe.fit(X_train, y_train)\n",
    "# Training score\n",
    "print(pipe.score(X_train, y_train))\n",
    "# Test score\n",
    "print(pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6.2. Random Forest pipeline with count vectorizer with GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer()\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "pipe_params = {\n",
    "        'vec__max_features': [800, 1000, 1500],\n",
    "        'vec__min_df': [10, 15, 20, 25],\n",
    "        'vec__max_df': [.7, .8, .9, 1.0],\n",
    "        'vec__ngram_range': [(1,1), (1,2),(1,3)],\n",
    "        'vec__stop_words':['english', stop_words_mod],\n",
    "        'clf__n_estimators':[10, 20, 30]\n",
    "    }\n",
    "\n",
    "pipe_gs(X_train, X_test, y_train, y_test, vec, pipe_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6.3. Random Forest pipeline with tfidf vectorizer with default parameters - no GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('vec', TfidfVectorizer(stop_words = 'english')),\n",
    "    ('rf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Evaluate how your model will perform on unseen data\n",
    "print(cross_val_score(pipe, X_train, y_train, cv=3).mean())\n",
    "# Fit your model\n",
    "pipe.fit(X_train, y_train)\n",
    "# Training score\n",
    "print(pipe.score(X_train, y_train))\n",
    "# Test score\n",
    "print(pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6.4. Random Forest pipeline with tfidf vectorizer with GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer()\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "pipe_params = {\n",
    "        'vec__max_features': [800, 1000, 1500],\n",
    "        'vec__min_df': [10, 15, 20, 25],\n",
    "        'vec__max_df': [.7, .8, .9, 1.0],\n",
    "        'vec__ngram_range': [(1,1), (1,2),(1,3)],\n",
    "        'vec__stop_words':['english', stop_words_mod],\n",
    "        'clf__n_estimators':[10, 20, 30]\n",
    "    }\n",
    "\n",
    "pipe_gs(X_train, X_test, y_train, y_test, vec, pipe_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.7. Extra Trees "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6.1. Extra Trees pipeline with count vectorizer with default parameters - no GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('vec', CountVectorizer(stop_words = 'english')),\n",
    "    ('et', ExtraTreeClassifier())\n",
    "])\n",
    "\n",
    "# Evaluate how your model will perform on unseen data\n",
    "print(cross_val_score(pipe, X_train, y_train, cv=3).mean())\n",
    "# Fit your model\n",
    "pipe.fit(X_train, y_train)\n",
    "# Training score\n",
    "print(pipe.score(X_train, y_train))\n",
    "# Test score\n",
    "print(pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6.2. Extra Trees pipeline with count vectorizer with GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer()\n",
    "clf = ExtraTreesClassifier()\n",
    "\n",
    "pipe_params = {\n",
    "        'vec__max_features': [800, 1000, 1500],\n",
    "        'vec__min_df': [10, 15, 20, 25],\n",
    "        'vec__max_df': [.7, .8, .9, 1.0],\n",
    "        'vec__ngram_range': [(1,1), (1,2),(1,3)],\n",
    "        'vec__stop_words':['english', stop_words_mod],\n",
    "        'clf__n_estimators':[10, 20, 30]\n",
    "    }\n",
    "\n",
    "pipe_gs(X_train, X_test, y_train, y_test, vec, pipe_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6.3. Extra Trees pipeline with tfidf vectorizer with default parameters - no GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('vec', TfidfVectorizer(stop_words = 'english')),\n",
    "    ('et', ExtraTreeClassifier())\n",
    "])\n",
    "\n",
    "# Evaluate how your model will perform on unseen data\n",
    "print(cross_val_score(pipe, X_train, y_train, cv=3).mean())\n",
    "# Fit your model\n",
    "pipe.fit(X_train, y_train)\n",
    "# Training score\n",
    "print(pipe.score(X_train, y_train))\n",
    "# Test score\n",
    "print(pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6.4. Extra Trees pipeline with tfidf vectorizer with GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer()\n",
    "clf = ExtraTreesClassifier()\n",
    "\n",
    "pipe_params = {\n",
    "        'vec__max_features': [800, 1000, 1500],\n",
    "        'vec__min_df': [10, 15, 20, 25],\n",
    "        'vec__max_df': [.7, .8, .9, 1.0],\n",
    "        'vec__ngram_range': [(1,1), (1,2),(1,3)],\n",
    "        'vec__stop_words':['english', stop_words_mod],\n",
    "        'clf__n_estimators':[10, 20, 30]\n",
    "    }\n",
    "\n",
    "pipe_gs(X_train, X_test, y_train, y_test, vec, pipe_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Prepwork for Conclusive Insights "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In notebook **4. Model Evaluation and Final Model Selection**, I evaluate the models and choose the best model based on the two criteria I defined in notebook **1. Problem Statement and Getting Data**. However, it may be a good idea to do a more qualitative assessment of how weel the best model is performing on classifying between two subreddits by looking at its interpretability. The next three codeblocks will extract the most important features that the best model found. These features will be qualitatively assessed on how well or poorly they may fit within the generalized definition of depression disorder and anxiety disorder. A more thorough discussion on this can be found in notebook **5.Conclusive Insights and Recommendations**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a pipeline with the best model (naive bayes), tfidf vectorizer and the best parameters\n",
    "vec = TfidfVectorizer()\n",
    "\n",
    "pipe_params = {\n",
    "        'vec__max_features': [800],\n",
    "        'vec__min_df': [20],\n",
    "        'vec__max_df': [.7],\n",
    "        'vec__ngram_range': [(1,1)],\n",
    "        'vec__stop_words':['english'],\n",
    "        'mnb__alpha':[1.0]\n",
    "    }\n",
    "\n",
    "# run the pipelin in GridSearch\n",
    "gs = GridSearchCVProgressBar(pipe, param_grid=pipe_params, cv=3, verbose = 1, n_jobs = 4)\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "# save the coefficients of the best model into a list\n",
    "coef_array = gs.best_estimator_.named_steps['mnb'].coef_\n",
    "coef_array.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a data frame that aligns feature names with the coefficient of the feature\n",
    "important_features = pd.DataFrame(zip(df.columns, coef_array.tolist()[0]), columns = ['feature', 'importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>kill</td>\n",
       "      <td>-8.496909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>rant</td>\n",
       "      <td>-8.496909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>alive</td>\n",
       "      <td>-8.314587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>sadness</td>\n",
       "      <td>-8.314587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>miserable</td>\n",
       "      <td>-8.314587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>happiness</td>\n",
       "      <td>-8.314587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>cried</td>\n",
       "      <td>-8.160437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>dead</td>\n",
       "      <td>-8.160437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>sister</td>\n",
       "      <td>-8.160437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>grades</td>\n",
       "      <td>-8.160437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>age</td>\n",
       "      <td>-8.160437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>fucked</td>\n",
       "      <td>-8.026905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>cut</td>\n",
       "      <td>-8.026905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>strong</td>\n",
       "      <td>-8.026905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>motivation</td>\n",
       "      <td>-8.026905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>mood</td>\n",
       "      <td>-7.909122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>suffering</td>\n",
       "      <td>-7.909122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>escape</td>\n",
       "      <td>-7.909122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>numb</td>\n",
       "      <td>-7.909122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>forget</td>\n",
       "      <td>-7.909122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>vent</td>\n",
       "      <td>-7.909122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>lonely</td>\n",
       "      <td>-7.909122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>young</td>\n",
       "      <td>-7.909122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>deserve</td>\n",
       "      <td>-7.909122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>weight</td>\n",
       "      <td>-7.909122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>healthy</td>\n",
       "      <td>-7.909122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>harm</td>\n",
       "      <td>-7.909122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>worth</td>\n",
       "      <td>-7.909122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>harder</td>\n",
       "      <td>-7.909122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>yeah</td>\n",
       "      <td>-7.909122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>good</td>\n",
       "      <td>-5.286065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>thought</td>\n",
       "      <td>-5.238812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>job</td>\n",
       "      <td>-5.223545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>lot</td>\n",
       "      <td>-5.223545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>way</td>\n",
       "      <td>-5.179093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>need</td>\n",
       "      <td>-5.164704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>years</td>\n",
       "      <td>-5.150520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>getting</td>\n",
       "      <td>-5.150520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>school</td>\n",
       "      <td>-5.129613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>help</td>\n",
       "      <td>-5.095711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>make</td>\n",
       "      <td>-5.089067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>bad</td>\n",
       "      <td>-5.089067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>feeling</td>\n",
       "      <td>-5.075909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>started</td>\n",
       "      <td>-5.062922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>got</td>\n",
       "      <td>-5.037443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>anxious</td>\n",
       "      <td>-5.018750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>think</td>\n",
       "      <td>-4.970548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>day</td>\n",
       "      <td>-4.958852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>life</td>\n",
       "      <td>-4.880600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>things</td>\n",
       "      <td>-4.783337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>work</td>\n",
       "      <td>-4.740371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>people</td>\n",
       "      <td>-4.596958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>going</td>\n",
       "      <td>-4.519098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>want</td>\n",
       "      <td>-4.446865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>really</td>\n",
       "      <td>-4.234229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>time</td>\n",
       "      <td>-4.234229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>know</td>\n",
       "      <td>-4.211944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>feel</td>\n",
       "      <td>-3.864123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>like</td>\n",
       "      <td>-3.606560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>anxiety</td>\n",
       "      <td>-3.585726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        feature  importance\n",
       "274        kill   -8.496909\n",
       "411        rant   -8.496909\n",
       "8         alive   -8.314587\n",
       "432     sadness   -8.314587\n",
       "336   miserable   -8.314587\n",
       "222   happiness   -8.314587\n",
       "93        cried   -8.160437\n",
       "107        dead   -8.160437\n",
       "458      sister   -8.160437\n",
       "206      grades   -8.160437\n",
       "6           age   -8.160437\n",
       "184      fucked   -8.026905\n",
       "97          cut   -8.026905\n",
       "492      strong   -8.026905\n",
       "346  motivation   -8.026905\n",
       "343        mood   -7.909122\n",
       "502   suffering   -7.909122\n",
       "141      escape   -7.909122\n",
       "362        numb   -7.909122\n",
       "178      forget   -7.909122\n",
       "563        vent   -7.909122\n",
       "301      lonely   -7.909122\n",
       "607       young   -7.909122\n",
       "117     deserve   -7.909122\n",
       "580      weight   -7.909122\n",
       "230     healthy   -7.909122\n",
       "226        harm   -7.909122\n",
       "598       worth   -7.909122\n",
       "225      harder   -7.909122\n",
       "602        yeah   -7.909122\n",
       "..          ...         ...\n",
       "203        good   -5.286065\n",
       "532     thought   -5.238812\n",
       "268         job   -5.223545\n",
       "310         lot   -5.223545\n",
       "575         way   -5.179093\n",
       "351        need   -5.164704\n",
       "604       years   -5.150520\n",
       "192     getting   -5.150520\n",
       "439      school   -5.129613\n",
       "235        help   -5.095711\n",
       "316        make   -5.089067\n",
       "32          bad   -5.089067\n",
       "167     feeling   -5.075909\n",
       "479     started   -5.062922\n",
       "204         got   -5.037443\n",
       "14      anxious   -5.018750\n",
       "529       think   -4.970548\n",
       "105         day   -4.958852\n",
       "291        life   -4.880600\n",
       "528      things   -4.783337\n",
       "588        work   -4.740371\n",
       "381      people   -4.596958\n",
       "200       going   -4.519098\n",
       "569        want   -4.446865\n",
       "417      really   -4.234229\n",
       "534        time   -4.234229\n",
       "278        know   -4.211944\n",
       "166        feel   -3.864123\n",
       "292        like   -3.606560\n",
       "13      anxiety   -3.585726\n",
       "\n",
       "[608 rows x 2 columns]"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important_features.sort_values(by = 'importance')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
