,0,label
0,"Welcome to this week's entering &amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)  
* Traditional education (e.g. schools, degrees, electives)  
* Alternative education (e.g. online courses, bootcamps)  
* Job search questions (e.g. resumes, applying, career prospects)  
* Elementary questions (e.g. where to start, what next)  

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](https://www.reddit.com/r/datascience/wiki/resources) pages on our wiki.  

[You can also search for past weekly threads here](https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;restrict_sr=1&amp;t=month).

^(Last configured: 2019-02-17 09:32 AM EDT)
",1
1,,1
2,"Hello everyone,

The project is called Deep Learner. This is a project my and my friends worked on during one of the Hackathons I thought it would be appropriate for this sub. The purpose of this project is to allow people prototype Deep Neural networks very very quickly and with writing 0 lines of code. For now you can only build regular dense networks. It also allows for data visualization using Tableau and you can also save models in json format. Please note this is very much work in progress and was made by 4 college students in 24 hours, so there will be bugs. We decided to make this open source, so you are more than welcome to contribute, I have posted a couple issues on github so feel free to contribute.  We are hoping to expand on it in the near future.

[Deep Learner](https://github.com/GioLomia/Deep_Learner)

Let me know if you have any questions &lt;3.",1
3,,1
4,"Currently, I'm working as as a Customer Service Rep at some company. Would love the feedback as I make the transition and can answer any questions regarding my background.

Here is Resume Part 1: https://imgur.com/LJ0fECB

Here is Resume Part 2: https://imgur.com/oJ9MsdZ

Edit: I will upload a Resume Part 3: The One Page Resume By Tomorrow Morning. Thank you for the feedback so far.

Resume Part 3: https://imgur.com/gv21B2P
This resume is 1 page. Thank you for the feedback!",1
5,"A lot of companies are creating new data science departments.
But everyone has their own understanding of data science.

Some think it is a data centric platform (combination of data lakes , data warehouse, Kafka streams), while some others think this is statistics and machine learning .. while there are othersothers who collectively call Data lakes, model programing and big data as data science.

How does your company view a data science department ?",1
6,"My employer, which is a big tech company, just launched a coding challenge for analyzing internal trouble tickets to find a way to reduce costs by reducing the number of unnecessary tickets. The challenge problem is worded in a way that's pretty obvious that they are looking for something along machine learning, though they didn't use the word explicitly.

I spent the last few months learning as much as I could (I have no CS, statistics or math background) about data science, machine learning and text analytics. I came to the conclusion that, machine learning is not cut out for this kind of task without tremendous investment - in time, money and quality training data. I submitted my solution for the challenge using other non-AI techniques, but I'm still wondering whether my assessment of the challenge was ""in the ballpark"".

Basically, the data provided to us for the challenge consists of about 2000 trouble tickets from one particular support department, including all the notes and some slightly higher quality summaries written by the technician at the end of support. 

Without any machine learning, I was able to tell simply by analyzing the n-gram frequency what the most common type of tickets are. Then based on those summary texts and the keywords I categorized the tickets. I suppose if there are enough data (maybe in the tens of thousands), a ML model can be trained to do the same categorization with some 90+% accuracy, but since the data set is way too small, and there's no consistent and reliable tagging on the data, I didn't even attempt it (but perhaps 2000 is not too small?). 

Either way, the real challenge comes after the initial broad classification. The biggest category (including false positives) from my own method contains just over 100 tickets, and under that category, there are a lot of different types of issues (we have a very complex environment). That's not gonna be enough data for any sort of machine learning to properly classify further. Besides, how do we know what are all the types of issues to even create the classes?

So I again used n-gram frequency to find common topics and again used keywords to classify. Was I able to come up with suggestions on how to reduce tickets? Yes, lots of them. Did I use any cutting edge, buzzword technologies? No. Maybe the management is looking for the cutting edge buzzword solutions to help sell out, but I don't think ML, DL, NB or whatever is going to help us here. I have also tried topic modeling, but the output from that was 60% to 80% garbage. I think I know why - trouble tickets note are extremely abstract, with key information hidden in just a couple of words, versus more natural conversations between people which are less abstract (people don't typically talk like dorks). Lastly, I have attempted word association, but the outcome was  pretty much tautology - it just reflects the n-gram frequency analysis.

Of course I want to win the challenge, but my bigger concern is whether the company is heading the right direction - it seems like people are hyped about ML and just want to ride the hype train as far as they can before it runs out of fuel. I believe ML is a wonderful tool on its own, but it's not snake oil. I don't think it can be very helpful in extracting answers to ""why"" from text data of moderate size. With my limited knowledge, it seems like they are asking to first predict whether a ticket can be avoided, and then maybe some unsupervised clustering of all the tickets that can be avoided, it just feels like there's no clarity like the problem of ""recognizing street numbers from photos"".

However I would like to hear your opinion and you experience :) Thank you!",1
7,"I feel like this sub only recommends a degree in statistics or CS for budding data scientists (I literally have not seen a single person on this sub recommend ""get a degree in physics""). But it seems like most tech companies don't really give a crap what the candidate's degree is as long as its quantitative. Some examples of degree requirements for data science roles at top tech companies include:

[Google](https://careers.google.com/jobs/results/6033539515744256-data-scientist-engineering/):

&gt;Master's degree in a quantitative discipline (e.g., Statistics, Operations Research, Bioinformatics, Economics, Computational Biology, Computer Science, Mathematics, Physics, Electrical Engineering, Industrial Engineering)  

[Netflix](https://jobs.netflix.com/jobs/868431):

&gt; Ph.D. in Computer Science, Statistics, Physics, or related quantitative field

[eBay](https://jobs.ebayinc.com/job/-/-/403/11381186):

&gt;Strong quantitative background with Bachelor’s degree in Computer Science, Math, Economics, Physics, Engineering, or related.  

[Amazon](https://www.amazon.jobs/en/jobs/750795/data-scientist):

&gt; MS in a quantitative discipline such as Statistics, Mathematics, Physics, Engineering, Computer Science or Economics 

[Facebook](https://www.facebook.com/careers/jobs/205743826659289/):

&gt; BA/BS in Computer Science, Math, Physics, Engineering, Statistics or other technical field. 

So it seems like in terms of degree, a degree in math, physics, economics or engineering should (at least in theory) be competitive with CS and Stats people. So why do people here automatically say get a degree in CS or statistics for a data science role? Or to put it another way: why do top tech companies not put as much emphasis on a degree in CS or statistics as expected? Seems like they just emphasize the ""quantitative"" part.",1
8,"Hi all.

&amp;#x200B;

I'm here to ask you a question about what should I do regarding my future (hope this is the correct place, if not feel free to tell me where should I post a question like this). Sorry all if my English isn't perfect.

&amp;#x200B;

I'm a student who's going to complete his first degree cycle in Mathematics. Here where I live (Italy), after this first cycle of three years I should go for a second cycle of two more years. I could continue with a course in Mathematics, but I'm starting to think about taking a course in Data science instead. I'm still a lot dubious about this and I would appreciate some help.

&amp;#x200B;

First of all the reason I'm considering the option to change is because of job stability. Continuing with Mathematics would mean trying an academic career, which it happens to be a lot more difficult and less rewarding the more I'm close to it. I definitely love Mathematics and I could also say I'm pretty good at it (not a genius anyway, obviously), but the idea of basing my future upon a risk (you never know if you're actually going to obtain some good results which could open up my way) and of passing a lot of years through not stable jobs, until I can finally become a stable researcher / professor (which is not guaranteed anyway) is starting to make me want to try others ways.

&amp;#x200B;

And so I'm thinking about Data science. I must say that I like Data science, it wouldn't just be for career, statistics has always been something that attracted me. But I like Mathematics more, so choosing Data science would be primary for my future. Still I want to be sure. Obviously I'm looking forward two things: salary and, more importantly, stability. I want to be sure that Data science would actually guarantee me a stable job. If not a stable job at least a stable career, meaning that if I lose my job I wouldn't have many problems finding another one. Moreover I'm planning to move away from my country and I would like to know how much this could be an obstacle.

&amp;#x200B;

In the end is it worth taking a course in Data science regarding the stability of my future? Can I be sure that by studying this subject I could stop worrying about the uncertainty of my job?

&amp;#x200B;

Thank you all for the help.",1
9,"I have a non-quantitative BS and will start a MSCS in the Fall but looking at my program’s curriculum and class syllabi, it does not seem to demand any advanced math. 

Machine learning and Deep learning courses are available but they don’t appear to have a strong theory emphasis. Looks like math is taught in an ad hoc manner. I want to go beyond the scope of my curriculum.

I’d like to be able to understand the average machine learning paper without spending hours on the side trying to learn maths I’ve never seen before. However, I do not need to be able to understand bleeding-edge machine learning papers. 

My current road math:

**Discrete math (propositional/first order logic, relations, mod arithmetic, intro graph theory, mathematical induction and proofs)

**Multivariate calculus

**Applied linear algebra (perpendicular frames, 3D matrices, SVD analysis, matrix diagonalization, Spectal Theorem, Root-Mean Square approximation, etc.)

**Intro to probability (probability spaces, random variables, stochastic independence, special distributions, limit theorems, etc.)

**Statistical theory (estimation, best tests, Rao-Cramer inequality, multivariate normal distribution, nonparametric methods, etc.)

Would this suffice as a good enough mathematical base (i.e. be able to derive new needed math quickly)?

If not, what should I add / topics I need to formally cover?

Real analysis?
More Stat courses?



",1
10,"So my company offered to sponsor me for a Data Science certificate, since I will be the only one without a masters degree in the data science team and they want me to at least have a certification or some sort of qualification.

I am planning on making this job my stepping stone; get enough on job experience and see what happens from there. I want something that will also help my CV in the future (a year or two from now)

My allocated budget for this is around $2500-2700, so any suggestions?",1
11,"Does anyone here have an opinion on using Golang for data science? My engineering department is thinking of changing infrastructure to go. As a Python/R guy, I'm being asked to code final production grade models to be integrated directly in the production code base.

Any thoughts on Golang in data science?",1
12,"Hi,

&amp;#x200B;

Since completing my Masters in Data Science, I have had a number of people contact me asking for my experience with the course and whether it is worth recommending. Therefore, I thought it best to summarise my decision for starting the course, what I have achieved during my studies, and the outcome in the years following. I created this article for Medium but thought it would be good to post it here as well to help discussions as I often see questions about Data Science Masters and whether they are worth it. 

### Why did I choose to study Data Science?

It was the spring of 2016 and I was coming towards the end of a 6 month internship at one of the largest consulting firms in the City of London. I had taken this role to gain experience and figure out whether becoming an Actuary was the correct route for my career. I quickly found passion in the data analytics of the role as I was being pulled into meetings to discuss numbers I had crunched or was able hack together a tool to automate previously manual tasks. However, I also found that the traditional track I would be heading on if I moved onto the graduate scheme no longer interested me due to years of standardised exams and little to no creativity. Furthermore, most of my work at this point was within Excel and I was gaining little to no coding experience.

It was at this point I also started to explore a magical term that kept coming up in my job searches: *Data Science*. I had come from a background in mathematics and, due to the nature of the job market in the UK, had been nudged towards the well-founded traditional roles such as accountancy and actuarial consulting. And yet, here was a new role that defied all the expectations I had set for myself of my future career. Where becoming an Actuary I would be solving problems by learning regulatory standards, Data Scientists are encouraged to creatively find solutions that fit within the commercial environment. Furthermore, the role opportunities were no longer fixed into a few select firms but almost all companies were looking for some variation of a Data Scientist and the idea that I could move into a completely new industry, from fashion to finance, greatly appealed to my interests.

However, as I started to apply for Data Science roles it quickly became apparent that **I was lacking two key skills: applying Machine Learning and coding.**

### What were my options?

The first solution was to simply teach these myself, I had the statistical experience to learn machine learning and had done enough coding in MatLab to feel confident that I could learn Python or R. However, if I was to do these I was unsure if this was enough and how I would clearly demonstrate my newly acquired skills on a CV to employers.

I considered online boot camps but they were often fixed in their content and I was unsure of how repeating someone else’s work would be received by employers. Furthermore, there was no guarantee that these were credible to employers and were expensive to self fund. Today, only three years later, the list of courses supported by universities makes this much more of a viable option and is something that is definitely worth considering but at the time these were lacking. Unfortunately, boot camps were a costly risk that I was uncertain would pay off.

Therefore, I decided to look for the options available at universities. At the time there were two types of courses that fit within my goals; business analysts courses and computer science machine learning. The former focused on applying analytics within commercial environments but, as this was run through business schools, was far more expensive at over £25,000 for one year of studying. The latter provided the teaching through academic research and focused more on teaching the underlying theory than the application. Furthermore, as this was an academic course run through the Computer Science department, the cost was considerably less for the year at £9,000 (for UK citizen).

### What did I choose?

In the end, I decided to play it safe and commit a full year to the academic masters in the hope that I would gain the applied knowledge in machine learning and develop my coding skills through project work.

Therefore, I joined the 2016/17 cohort of the Data Science MSc at City, University of London’s Computer Science department. This was the second year the course was offered at this university and, at the time, was the only university in London that offered a Data Science Masters (though others had some variations of this).

### What did I learn in the course?

The first term consisted of the three main topics of Data Science: fundamentals of data science, machine learning and visualisations. Each module consisted of a coursework component that we were given a choice of any publicly available dataset to apply our newly learned methods on. With these, I was quickly able to improving my coding skills and even built the confidence to start sharing [these projects publicly](https://www.philiposbornedata.com/2017/06/27/test/).

In the second term we had two core modules, Big Data and Neural Computing, and were given the choice of two optional modules. The list of options was comprehensive and enabled us to pick specialisms from computer vision to data architectures. I chose Data Visualisations (a continuation of the first term’s module) and Software Agents (the basics of AI by applying Reinforcement Learning). Again, these modules included coursework and with the fundamentals from the first term, I was really able to expand my applications and think creatively. Big Data also introduced text data and natural language processing.

Over the two terms, I had been given a broad overview of most of the Data Science topics and had a deep knowledge of Machine Learning and Neural Networks from the core modules. As we moved into the first component of the course, the dissertation, we were given the choice to complete this whilst in an internship role (and be provided an extension on the deadline to account for balancing whilst working). I found a suitable role, defined my research topic and over the following months applied all the skills I had gained so far towards [applying AI within business](https://www.philiposbornedata.com/2018/03/09/masters-thesis-summary-constructing-a-narrative-using-markov-decision-processes-applied-to-data-visualisations/).

### Did I gain the skills I needed from the course?

I had two goals to achieve; to demonstrate that I understand machine learning and apply these with coding. The course not only provided a clear ‘box tick’ against these on my CV but enabled me to continue to expand my skills after with more and more interesting projects. Part of any job application is to get past the initial checks and I was now doing this much more consistently. Furthermore, as I moved into interview stages, I had all these project to discuss and truly demonstrate confidence in my understanding far more than I would have achieved on my own.

The Masters opened up all the doors that I had previously been knocking on and even had recruiters contacting me directly following the projects I had posted publicly. In the end, I found that I enjoyed the research aspect of my dissertation and the freedom to pursue the field and have since move onto a PhD in Artificial Intelligence. Ironically, this is the last thing I would have considered back in 2016 but as the field is constantly expanding it is incredible to be at the forefront of this, particularly because many problems require an applied mindset and fit within commercial problems and are not simply theoretical.

### What advice would I give to someone considering moving into Data Science?

This is always a hard question for me to answer as each person’s position is different so will try to offer some advice based on my experience. In short:

1. **Establish** that Data Science is the right route for you and find a topic or detail to motivate this. For me, it was the ability to apply data analytics in a creative way and become a valuable asset in a business to help others improve their decisions.
2. **Evaluate** what the jobs you want are asking for and where your set of skills currently fall short. Although I had the technical background, I had not demonstrated my ability to apply machine learning or code and needed something to achieve this. For others on my course, they had not come from maths or stats backgrounds and so needed these to strengthen their knowledge.
3. **Review** the options available to you to gain these missing skills. For example, boot camps are increasingly more credible in the industry but they are often following a single path (i.e. learn on the same data and apply the same methods). This may work for some but I wanted to demonstrate my abilities in unique ways to stand out to employers. If you are considering a masters, thoroughly research the modules and who is organising the course as variations will exists between different departments, particularly business and academic schools.
4. **Expand and challenge** yourself through the course, don’t simply pick a course that covers topics you are already comfortable with to tick a box. Find something challenging that will encourage you to develop new skills.
5. **Demonstrate** your new skills by publishing your projects online, either through GitHub or Kaggle or your own site. Building a portfolio of project has taken me further in any interview than trying to describe these within the time limit would allow.

&amp;#x200B;

I hope you find this post useful if you are considering how to get into data science and will do my best to answer any questions you have about this. Am UK time so will most likely reply to questions tomorrow morning when I have some time. 

Thanks",1
13,"I work for a small company with a 2 person data science team. The data we use is not massive (largest analysis datasets typically in the millions). At this point we're still using our laptops to train models and so forth.

One of my goals this year is getting us off our laptops. Our DS tech stack is basically a Redshift database and we do analysis/run models in Python (scripts/packages for production stuff, Jupyter for adhoc). Everything is in Github.

Our company uses AWS so we have access to all those tools. We do have some scheduled workflows that run on EC2 instances currently. I am really looking for a solution that allows us to maintain similar flexibility and ease of use as the laptops, but can offer much better computing power. And also can provide Jupyter support for easy development. I want to move a lot of workflows to Airflow as well so something that would work well with all of that would be great.

What would you recommend?",1
14,"Tomorrow I'm interviewing [Anand Mariappan](https://twitter.com/anandraghu?lang=ca) (Reddit's Senior Director of Engineering - Data Science, Search &amp; ML) at a tech festival in Berlin.

I would like to ask him some challenging questions, like how are they using ML to deal with hate content, or why is still better to search ""reddit x"" on Google than to search ""x"" on reddit.

What are some other interesting questions for him? I promise I will update with the answers &amp; main take aways from the conversation!",1
15,"Apologize in advance if this belongs in weekly ask. 

Do you in general care about a candidate's thesis project for master program when hiring? 

&amp;#x200B;

I'm brainstorming thesis topics for MS in applied stats. Ideally I'd like to work on something implementable in the future and I have the following ideas:

1. Anomaly detection - I work in healthcare and often the targeted conditions are rare events
2. Method to ""combat"" imbalanced data - same as above but different approach (maybe combine both?)
3. Method for Generating Measurements and Weighting of each measurement -   
This happens often in business when trying to rank/group something without statistical training. They just come up with a model that take multiple measures. I'm just hoping to study ways to do this in a more scientific way by looking at 1. methods to come up with measures 2. methods to standardize measures so they are comparable 3. weighting them in a scientific method to come up with final model

&amp;#x200B;

Looking for brutally honest comments/criticisms. I'm also not sure if master thesis is about demonstrating my knowledge or about coming up with new methods. I certainly don't believe I can invent new things. 

I feel like #3 is ridiculous, but 1 &amp; 2 have probably be worked on or even ""solved"". 

Thank you so much for your time. I have never done this before so just any kind of direction would be really helpful.",1
16,"Me current: 

32 years old,  BA in Philosophy/Psych, M.Ed Curriculum and Instruction, Certificate in Educational Measurement (some applied ed research stats). 11 years in educational program evaluation, data collection and management. Also woefully never took math past HS precalc. 

I've read every thread on here and r/statistics. I am maybe 75% convinced I couldn't possibly get into a data science role even if I self-studied for a few years while working. I've been applying for analyst roles at a paycut and I'm having a terrible time- I get some calls but no bites. Now, people talk about portfolios and experience, but I'm pretty certain there is no way I could get a FANG job without more formal education.

But now I'm reading things that make me think even if took the dive and I spent 2-3 years studying full time for a dual MS in computer science and statistics would still leave me with a relatively low % shot of getting the kind of job I want.

Can someone give me some tough love and/or hope before I start thinking seriously about putting myself 40k in the hole going back to grad school?

&amp;#x200B;

&amp;#x200B;

&amp;#x200B;",1
17,"As a novice Data Scientists with alot of ambition and questions i thought it might be a useful idea to pitch an idea of a mentor mentee scheme for us data scientists. If youre an experienced data scientists who wants to help a beginner out you'd be making alot of people ecstatic.

That being said. 

I live in london, been working in Data Science for a year and a half, looking to do a masters in machine learning and hopefully envision a career in ML.

If you think you can help feel free to message me.

I hope this becomes a thing, lets better the Data Science community !",1
18,"Not sure if this is the right place to post, but here we go. So I graduated from college 4 months ago and I'm still searching for a job as a data scientist/analyst. A few days ago I got rejected from a job I **really** wanted (after the final round) and it crushed me, but I've been applying to other jobs, hoping I can get some interviews. Being unemployed is driving me crazy, especially since all my friends are either in school or have jobs and I'm in this limbo, still waiting for something to happen. Anyway, I could really use some words of encouragement/advice to keep me going. Thanks!",1
19,"Hi I'm hank and I'm an aspiring data scientist. I'm starting my transition into the field. I've taken a few courses on python, r, ml, and dl at nycdsa and wanted to continue my studying but found it hard on my own. 

I'm looking to see if there were any other aspiring dscientists in my position and wanted to essentially study together and keep each other accountable! 

",1
20,"I'm looking to break into the Data Science field and currently interviewing with a few companies, but I feel I lack certain edge because I don't have much to showcase (very little work exp). So I decided to start by working on mini-projects and putting them up on Github. I started with something really simple but I feel like I could do a lot better than that just Excel charts. So here are some of my questions about github projects.

* **The data part:** Do you (1) think of a problem and then find relevant data-sets or (2) look through a list of available data sets and pick one that piques your interest? So far I have tried method (1) but often I don't find data in a desirable formats or anything close. 
In this case, are there tools I can leverage that can collect data from websites and convert them into CSV or something (guess this is called scraping)? 
If method (2) is ideal for a newbie like me, where's the best place to find data to work on. 

* **The visualization part:** While creating killer visuals using R and Tableau is my goal, I'd like to, in the short run, be able to use online tools to quickly show, say, a pie chart or a bar graph (or maybe a combo of both) of an interesting trend I found. Any advice here?

Not entirely sure if these questions are valid or if the expectations are realistic, but feel free to put me in my place, if required. I'm here to learn. Any other advice you'd like to give me about getting some projects off the ground, feel free to comment or PM me. Thanks in advance!",1
21,,1
22,"Hi all, I'm a data science student working on various projects using biometric data. I've recently decided to start a blog to 1) get better at communicating findings effectively 2) give people a little bit of a look into data science and 3)have a platform in which I can discuss and share things I learn, problems I run into, and findings.   


Anybody have some tips for how to keep it interesting and/or manageable? Any advice is appreciated!   


I'll link it here if anyone is interested; but right now I just have an introductory post.  
 [https://blogs.valpo.edu/datadays/](https://blogs.valpo.edu/datadays/)   


Thanks!",1
23,,1
24,"My dad runs a small/medium business (about 50-100 employees) which handles payments for construction workers. I'm a statistics master's student and constantly telling him how data is revolutionising how businesses are run but besides obvious examples like Facebook, Netflix, Amazon etc., I'm finding it hard to come up with answers to his questions about how exactly data can be so revolutionary (especially given I have no business experience myself).

&amp;#x200B;

What are some low hanging fruit for utilising data for small businesses? And is it worth suggesting he look into hiring a data consultant?",1
25,"The first question we had for the panel came courtesy of /u/RyBread7:

**""What are the qualities or traits which differentiate good data scientists from the best data scientists? How, if at all, can these traits be learned or acquired?""**


Panelist Answers:
_______________________________________________________
/u/creampuffcrusader:

The best data scientists I've worked with had these two traits:

**A deeply rooted paranoia about data quality.**

Starting out a project by trying to replicate KPIs and current domain knowledge before jumping into the new and exciting work. Talking to stewards of the data about any quirks they ran into and taking the time to understand the data generating process. This can be learned either from mentor-ship or from experience. For me personally - it was combination of both mentorship and collecting battle scars.

**Holding themselves to the scientific method***

I had a mentor who was a data scientist before it was cool. He started the quantitative supply chain practice at the firm I work in back when the data scientist equivalent position was called Principal Analyst. He had this motto when interviewing stakeholders:

Tribal knowledge is a hypothesis unless there is evidence.
He had this uncanny ability of organizing knowledge by what has been verified, what can be verified, and what is interesting but maybe out of scope or not testable. And using this categorization to efficiently guide us to a quality analysis or product. Really - he was just very strictly holding himself and his team to the scientific method. It was remarkable.

This trait can definitely be learned. But it takes patience and experience.

_______________________________________________________
/u/amadeusmagrabi:

In my experience, the best data scientists are the ones who have **an intrinsic drive to deliver value for the business** and are **able to think outside the box to make sure that the whole team has the highest impact.**

Good data scientists ask their manager what the project requirements are, do their research, deliver a clean and thorough analysis, communicate their most important findings clearly and then ask what they should work on next.

Great data scientists take a more active approach and think about their work with more context. They ask what the larger goal of the project is and challenge the core assumptions. They have ideas for how a project could also benefit other parts of the company or raise awareness for potential conflicts that could occur down the line. They are informed about new frameworks or techniques that come out and suggest innovative ways how they could be used to improve a process. They are genuinely interested in how the business as a whole works and actively talk to people to understand their perspectives. They are full of ideas of what they should work on next. They pride themselves on how many people they helped and not on how complicated the technique they used was.

Importantly, they do all of this because they care about the impact of their work and not because they want the attention or boost their career. They do not start a discussion just for the sake of having a discussion and they are able to step back when their opinions did not resonate with others.

*As to how to acquire these skills:* 

If you do not have a data science job yet, this is hard to prepare. But it helps to read blog posts in which companies from different industries share how they get value out of their data (there are plenty of those on Medium).

Once you have a job, ask as many questions as possible without being too annoying and talk to everyone in the company. Do not be shy and just sit in front of your data. Constantly ask yourself why you are doing what you are doing, if it still makes sense or if there is a better way. Get involved, be curious and let others know about your thoughts. The more feedback you get on your thoughts, the better you can fine-tune your work to the business context.

_______________________________________________________
/u/tsutomu45
 
This depends on the role of the data scientist and the company.

In a tech company where seconds (and milliseconds) matter, then your knowledge of algorithms, statistical learning, and programming matters a lot.

However, if you're in a non-tech company, where data scientists tend to be more ""decision scientists"", and the transactions happen across days or weeks (think buying a car), then the ""soft-skills"" tend to dominate...things like understanding the business, iterating rapidly, and explaining results to non-math/non-engineering executives.

Both are learn-able. However, in my experience the latter (soft skills) are harder to teach.
_______________________________________________________
/u/dfphd:

There are three things that come to mind:

* **They are driven by outcomes and not methods - but can do either well.** 

The best data scientists I've met are the people that are willing to put their ego aside and cobble together a less elegant answer in two days than a more elegant answer in a week because that's what's right for the project. That's not to say that they cannot put together a complex, elegant solution to a problem - when the problem/project calls for it, they can roll their sleeves up and make that happen. But their bias is for getting results, not getting methodologies.

* **They say ""yes"" more often than ""no""**

It's really easy to say no. We can't do that, that can't be done, that won't work, no, no, no. Really good data scientists say yes - knowing that they may need to change the question for it to work, but understanding that they can likely figure something productive out.

* **They build strong relationships based on work credibility**

These people tend to do more than just be good at their job - they seem to always manage to leverage the quality of their work into really strong relationships at work, which in turn helps them be even more effective by having a lot of people who are willing to go to bat for them when needed. I think the first two attributes tend to help in building these relationships, but there is extra effort and time that they dedicate to cultivate these relationships over time.

Learning these skills, in my opinion, is largely driven by introspection, i.e., identifying that your objective should be to become as effective and efficient as possible, and that you may need to modify your behaviors, your habits, your comfort zone in order to become that person. Once you can legitimately convince yourself that these are skills worth developing, the rest becomes an exercise in keeping yourself honest - in constantly call yourself out when you are being a method-diva, when you're being a naysayer, and when you're marginalizing your relationships at work.",1
26,"We have written a Medium post explaining our work on applying deep neural networks to breast cancer screening.

https://medium.com/@jasonphang/deep-neural-networks-improve-radiologists-performance-in-breast-cancer-screening-565eb2bd3c9f

* We created a large dataset of mammograms, consisting of over 1,000,000 mammographic images (a.k.a the NYU Breast Cancer Screening Dataset), with accompanying cancer labels and lesion segmentations where applicable.
* We designed and trained a novel two-phase model for breast cancer screening that performs on par with expert radiologists in identifying breast cancer using screening mammograms.
* We are making publicly available our [paper](https://arxiv.org/abs/1903.08297), [tech report explaining our data](https://cs.nyu.edu/~kgeras/reports/datav1.0.pdf) and [code and trained models](https://github.com/nyukat/breast_cancer_classifier).
",1
27,"Why does the company need to know what happends in the algorithm, and what are the factors that affect the decision making? Or rather why do this at the cost of model performance?",1
28,"I started working as a Data Scientist a few months ago, and on the occasion I would receive messages on LinkedIn from people in my area asking for advice and mentorship, often over coffee. These are often college students or people trying to transition into the industry. 

I know the power of networking is pretty strong, but since these guys are pretty green, is it worth my time to invest? I do like helping people, and I think that my own journey to become a Data Scientist was filled with good and bad advice, however I don't want to be taken advantage of in terms of effort and time.",1
29,"I've ended up in more project management type roles as of late due to my company hiring more PhDs and less business analysts. 

Still adjusting, but constantly bothered by the fact I'm losing the skills that made me special in the first place.",1
30,"I am writing my dissertation which is in Political Science but basically just using machine learning to test the predictive abilities of political science theories. I am trying to transition into data science. I am proficient in R, but know that the machine learning toolkits in Python are unmatched. Thus, I am doing my dissertation in Python. I want to keep something similar to an Rmarkdown workflow, and Jupyter is that for Python as far as I can tell. Is it feasible or worthwhile to leave Rstudio behind and do both in Jupyter? What about using reticulate in Rstudio, is that functional or practical to use for Python? ",1
31,"What is the coolest data science thing you've done, at work or as a personal project?",1
32,April Fools!,1
33,,1
34,"Do you all have any best practices in structuring projects (i.e. directory structures for storing data, scripts, exploratory notebooks, etc.; naming schemes; breaking questions/tasks into pieces for teams to tackle in parallel)? This is a little ambiguous and certainly dependent on the specific project and/or field, but I want it to be open ended. Interpret it as you will.

Personally, I am sort of a ""hobbyist"" data scientist (I am a biologist; my ""data science"" type work is all on my own time), so all of the ""data science"" type things I do are exploration of open source biological data (RNA seq, protein-protein interaction databases, anything on the Allen Brain Institute's website; i.e. ""data-science-lite""). I'm usually testing out one-off ideas, looking for interesting ways to combine open source data, and seeing if I can gain any insight into my own project. 

I generally have separate directories for raw and transformed/joined data. I keep scripts in the directory in which they were applied to make it easier to keep track of what I did at each step of the process, and I keep exploratory/debugging notebooks in the parent directory. I also try to keep metadata files in each raw and transformed directory, but to be overly honest I am the only person working with any of it, so I tend to slack quite a bit on creating the metadata.

I haven't come up with any naming schemes that seem to work for me consistently, and since it's just me exploring data to see if I can use it for my own projects, I generally have no need to break it into smaller pieces to be executed by a team.

My approach has a lot of short-comings. In particular, I end up with data files haphazardly named and scripts spread chaotically throughout the whole directory structure. I can usually trace my way back to what I did, but it takes some time. This is particularly problematic when I try to return to a project with a new idea; I spend as much time remembering what I did previously as I do executing the new idea.

I'm just curious what you all do to structure your projects. I've not seen much here in the way of describing best practices in organizing personal or professional projects, so I thought I'd toss the question out to the community.",1
35,"I lead a (small) team of data scientists, roughly split into two. Analytics, and Machine Learning. Everyone in the team is either in the Analytics ladder, or the Machine Learning ladder (though movement between the two is definitely possible).

I'm currently in the process of putting together a competency framework for the Analytics ladder. The goal of the framework is to lay out what competencies are expected of analysts at different levels. This will then be used to help build career growth plans for analysts on this ladder.

Whilst I want to build a framework that is custom for our organisation, I'm aware that 80% of what makes a great analyst probably doesn't need to be custom, and would love to ""steal with pride"" from somewhere else.

Has anyone seen a good (public) framework that they could point me to? Any other thoughts or feedback welcome too.

If you're not sure what I mean by analyst, I think this post does a great job of articulating the Analyst role as I view it: https://hbr.org/2018/12/what-great-data-analysts-do-and-why-every-organization-needs-them",1
36,"Sometimes when I'm doing machine learning experiments or research for my lab, I often end up collecting my own data- image, audio, video, etc. Would other people find an app that lets you collect and label image/audio/video data right from your phone useful? Auto-export CSVs, labeled folders, etc.

&amp;#x200B;

I often find it pretty cumbersome to build custom apps every time I want to collect relatively simple data from a smartphone.",1
37,,1
38,,1
39," I am a software engineer looking to go into data science field. I was thinking of data analyst position to improve my data analysis skills.

I did some research and I found this article [http://nadbordrozd.github.io/blog/2017/12/10/what-they-dont-tell-you-about-data-science-2-data-analyst-roles-are-poison/](http://nadbordrozd.github.io/blog/2017/12/10/what-they-dont-tell-you-about-data-science-2-data-analyst-roles-are-poison/) .

Article's TL;DR:

1. data analyst is more manual job, you work with business, produce reports, presentation not software;
2. you will not gain right coding practices and you will not be learning about modern machine learning/statistical techniques. Also the code you may produce most of the time will be one-off, throwaway scripts, code that only you will ever see, manually operated sequence of scripts, clicking through GUIs etc.

So overall I understand the main idea of this article and it does make sense, is it really true? Is the code data analyst writes ""one-off, throwaway scripts""?

Also if I am coming from software engineer and I do have decent programming background, I am already familiar with coding best practices, wouldn't the skills I would improve in data analysis role be more valuable in becoming data scientist than staying in software engineering?",1
40,"Hi all!

Recently I discovered that Facebook did a super cool thing and made public their package for time series forecasting (yay open source!). As such, I took a crack at trying to use it, and the results are pretty neat.

[Check out this vignette I wrote and put on GitHub](https://github.com/pmaji/data-science-toolkit/blob/master/time-series/forecasting_with_prophet.ipynb) that explores the basic functionalities of Facebook's time series forecasting package called ""Prophet."" Would love know your thoughts and hope that many of you try your hands at building a forecast of your own! To entice you, here's one of the plots that resulted from the forecast, showing how well the model performs (metric = MAPE)  over different forecast horizons.

For those on mobile -- [here is a mobile friendly link to the write-up](https://nbviewer.jupyter.org/github/pmaji/data-science-toolkit/blob/master/time-series/forecasting_with_prophet.ipynb).

P.S. -- if you like what you see, consider starring the repo on GitHub. It's a part of [a larger repo](https://github.com/pmaji/data-science-toolkit/blob/master/README.md) I'm focusing most of my free time on right now that aims to provide easy-to-understand vignettes on the main subjects in data science with the goal of empowering people to expand their data science toolkit :)

&amp;#x200B;

https://i.redd.it/2iotz3r2kcp21.jpg

Happy forecasting!",1
41,,1
42,"I've been working in an image processing contractor job for the past year and a half. For the past 3 months, I've applied to around 500+ jobs with titles such as Data Scientist, Data Engineer, ML Engineer, Deep Learning, etc and have gotten only around 30 phone interviews, 3 on-site interviews, and no offers. I've probably applied to slightly more small companies than large ones, but the only on-sites were with small companies

I've already gotten feedback for my resume numerous times, and the main problems people bring up are that I have lots of gaps in my resume and my recent work have only been contractor or freelance roles. This was also why I had alot of problems getting a job before I landed my current contractor role. 

Although I've worked on personal projects with ML in the past, in my current job I mostly have worked on only image processing with a little bit of deep learning also. I'm not sure if I'm failing the business/product metrics case study questions because I don't really have any experience with that (my current job is more of a research role so I don't really deal with translating business problems into mathematical ones). In a recent on-site interview (after I passed the phone screen in which I was asked technical questions about ML and business/product metrics), the manager directly told me he would only consider me for a Jr. ML Engineer role (I don't remember what caused him to say that. Maybe because I apparently got some technical question wrong or I admitted I don't have experience using ML with dealing with APIs?) 

How can I makeup for the gaps in my resume? Am I better off working on more personal projects? Or just getting really good at knowing the theory behind ML? Because I don't have any non-academic work experience with ML (other than the brief freelance work and the brief DL work in my current job), should I not bother applying for DS/ML jobs and instead focus on image processing/computer vision/DL?",1
43,Data is often involved with a lot of ethical implications. But what are some good examples of win win scenarios? ,1
44,What's the difference between these two positions?,1
45,"This is a follow-on post to [Ed-Fi Alternatives](https://www.reddit.com/r/datascience/comments/93s53e/edfi_alternatives/). I'm not OP.

In that post OP was looking for alternates to Ed-Fi, and I'm guessing didn't find any (there was no followup). But in the comments, a developer/admin/arch? for a larger educational system was looking into using postgres for Ed-Fi. *Neato.*

I'm curious if anyone else is doing something similar, if it's working, and what choices have been made to get your project to where it is today.",1
46,"I'm confident in my technical skills, and I'm able to communicate my findings in a way the business folks at my company can understand, but I'm not good at identifying business opportunities where data science could be useful. If someone came up to me and said ""I'd like to understand X more, because that will allow us to Y"", I could turn that into a data science problem and work towards a solution, but I wouldn't have thought of ""understanding X allows us to Y"" on my own.

What can I do to improve my business acumen as it relates to data science? Any books you would recommend, for example?",1
47,"Hey Everyone, 

So I’ve been using Python ( and a tiny bit of R) for most of my DS projects, but I saw a really interesting YouTube video on Julia. I’d like to know what this community thinks of it as a language, seeing as how it was made for DS essentially, compared to the other more popular languages used currently. 

Will it end up supplanting Python/R?
Does it have any obvious advantage over the other languages other than speed? 
Is it useful/worth it to know?
Anyone here use it regularly?
I know it’s only in version 1.x but I think it has potential!
",1
48,"The last two might seem unrelated but I've heard epidemiologists are also data analysts, same for biostatisticians. I understand the that epidemiologists and biostatisticians may work in the healthcare sector, but how are they similar to a data scientist and data analyst? Are data scientist and data analyst just a broad terms?",1
49,,1
50,"I am a software engineer and have been offered the chance to become a data engineer. I am currently trying to sharpen my skills and become a data science (I am working on my masters part time while working) and I am wondering if this is a step in the right direction. The role would mainly be supporting models using hadoop, spark, and various other technologies. Have any of the data scientists started in data engineering and transitioned into their current roles? If it helps I am also very early in my career (early 20s).",1
51,"I used mainly R in college but a lot of the jobs out there requires that you know Excel, Python, and SQL...I'm having trouble learning everything or building a foundation for the other without feeling like a light switch.",1
52,"hey all - how do you show your ""projects"", data science problems you've worked on? Do you have a portfolio of sorts - something you show beyond your resume/linkedin? 

&amp;#x200B;

Thanks!",1
53,"I’m finishing up my analytics degree in December. I was thinking of getting an internship in the summer, but just wanted to know how important it was or is there something more worthwhile I can spend time in, such as learning new skills and software or building my own projects. 

Is it a make or break for getting a job right after graduation?",1
54,"Does anyone know of resources showing ML models deployed in a production environment? In class and at work (as an analyst), it's one thing to run scripts ad-hoc, sit and wait for the model to run, and then use results in some way. But as with everything in programming, it's a whole nother matter to have it deployed to a product out in the wild! Speed would obviously be an issue, are trained models saved and reloaded in some way?

Edit: Wow, thanks for all the responses! This was really more of just a general wonderment from someone who’s only been doing data science in a narrowly focused business environment.",1
55,"I'm a contracts manager (legal work/deal-making) with 8+ years of experience. I know a teeny bit of programming, I love spreadsheets, and I've always been interested in data. I'm not new to the workforce; I'm looking to make a mid-career change after 10 years and I'm hoping that my extensive work history, combined with newly acquired data analysis/visualization skills, will help me find a new, more dynamic career path. Unfortunately, I'm overwhelmed by the amount of questionable resources and promises (i.e. boot camps claiming $95k starting salaries after 10 weeks) and can't figure out what I actually need to be doing. 

I've been doing some online courses and self-study in statistics and Python for the last 3 months, but I feel nowhere near ready to start working on my own projects (still can't figure out Kaggle or Github), and I'm wondering if I'm even going down the right path. I'm seeing ads for bootcamps left and right, and wonder whether there is any merit to any of them. Basically, I have no idea if I'm wasting my time or going in the right direction. No idea how long it will take for me to gain marketable, meaningful skills. No idea of the breadth of knowledge or experience I need to have. 

Can anyone recommend a good way to find a mentor, someone to guide me through this process? I am not opposed to spending money (either on a mentorship or, an online course or a legitimate post-graduate degree)... I'm just struggling to figure out what is worth my time. ",1
56,"I’ve see a few “Data Science, Risk” jobs, but they all have standard job descriptions. Is this the same as enterprise risk? How is data science &amp; predictive modeling used in this space? ",1
57,"What are best practices for executing series of SQL commands in Python without interfering too much with other users sharing database access?

Some context: I run around 20 queries daily on a single DB. Right now those queries are spaced five minutes apart but I think that's quite clunky and would ideally start the next query if no other queries are executed at that time so I have my full results quicker. It's not ok to execute all queries one after the other and potentially lock the db until all queries are finished executing.

Edit: MSSQL DB, queries that are designed to select from all users their outsstanding payments, product types, etc. So often locking records for several seconds (10 max). ",1
58,"TL;DR: I did a performance analysis of my production classifier and would like to know what's the method that you guys use, and whether there are any flaws to my idea.

&amp;#x200B;

I work with text mining and the most important model that I have is a document classifier. It classifies if a particular document is a contract or not.

&amp;#x200B;

My team created a pipeline that fetches documents, OCR them, classify them and make them available in a web application, so that our users can find them way faster than by using the other methods.

&amp;#x200B;

The classifier was trained with 1K documents and deployed with &gt; 90% F-score to production (I did the training, testing and validation stuff to prevent overfitting). We then needed to tell the stakeholders our classification accuracy, because of that, I sampled 1K from the 33K classified documents and we manually annotated the sample so that we could calculate the number of contracts labeled as not contracts (false negatives) and the number of documents that were not contracts but were classified as contracts (false positives).

&amp;#x200B;

I then looked at the false positives and false negatives for patterns, after finding patterns in the errors, I created regular expressions that reduced the error for some patterns, and re-trained the models for the other patterns that came from new documents that were entirely different from the samples we had in the initial dataset. After updating the model, the F-score went up to &gt; 90% again, and we got better results when looking in the web application, so the problem of performance was solved. BUT, I think my approach to this problem was very intuitive and not very science-y, so I figured out another way of doing this, a more statistical way.

&amp;#x200B;

What I'm thinking about doing in the next time, is to make a [sample size calculation](https://www.surveysystem.com/sscalc.htm) using the total of documents in production as the population, confidence level of 95% percent and confidence interval of 3%. Then do a random sample of N documents, annotate them and calculate the F-score.

&amp;#x200B;

Now, my fellow data scientists, I would like to know how you do this kind of performance monitoring for classifiers. Also, do you think that my idea has any flaw ?

&amp;#x200B;

Another thing, my new idea will use a confidence interval of 3%, does that imply that the score that I calculate after annotating documents from my random sampling will have a range of +- 3% ? For example if I calculate a F-score of 94%, does it mean that my F-score, actually is 91-97%, because I did a sample of the population ? Or am I oversimplifying things and this is not how confidence intervals actually work ?

&amp;#x200B;

Thanks in advance for the input, I really appreciate it. Statistics is my weakness, since I entered data science from software engineering field.

&amp;#x200B;

EDIT: Edited sample size calculator link",1
59,,1
60,"I recently accepted a position where I have access to a really nice Linux server (56 threads 256G Ram) and we are currently in the process of getting access to an even larger server (100+ threads with 2TB Ram) -- we have a lot of heavy lifting to do. At my previous position I used a server with remote desktop and it was clunky so I'm trying spend some time getting familiar with a good setup early in order to increase my productivity and workflow later. I'm looking for recommendations on workflow. Here is my current workflow setup:

* Jupyter-lab server
* Rstudio server
* ssh tunnel from server to localhost on a Macbook Air or Fedora Workstation desktop through Chrome
* localhost:8000 to load up Jupyter-lab
* localhost:8001 to load up Rstudio

I generally write scripts in Jupyter-lab or Rstudio and once testing is complete I open up a tmux shell on the server and run code straight from the command line -- I use tmux so I can monitor it throughout without the need for being connected to the VPN. This has worked well so far but it still feels a bit clunky. Ultimately, I think a vim-python in one tmux pane and ipython in another would be ideal where I can Ctrl+enter send commands using vim-slime. I've tried this setup and it works, but the config is somewhat of a hassle and I need access to quick plotting to check data processing commands and model run outputs, which is not possible with ipython in the command line. An `ssh -X` would solve this, but now I'm adding things that seem excessive.

This setup is certainly better than my previous workflow. I'd like to see what other data science workflows look like when using a remote server. 

So, does this seem like a reasonable setup? What is your programming setup and workflow when using a remote server?

",1
61,"Is something upsetting you about your career, school, or job hunt? The daily grind can get frustrating, but a full thread is too high visibility for some folks. This thread is a good place to keep things low key and to find solidarity among our peers. 

We’ll try it out this week. We’ll make it a recurring thing if sufficient people show interest. ",1
62,"I can’t be too specific because I work in a really niche industry, but just over a year ago I got what I thought was my dream job as a data scientist in a scientific industry.  I retrained specifically for this and was super excited to get offered the position.  A year later, the position has not lived up to expectations and I am deeply unhappy.  Having never worked elsewhere as a data scientist I’m not sure if it’s just my company though.

For most of the time I’ve been here I have not had any work to do.  I feel like I’m massively underutilised, and I do nothing of value.  When I actually have a project to work on, I spend most of my time aimlessly trying to create ML models when in reality the data I have does not fully explain the values I’m trying to predict.  I have no deadlines, so I have no pressure to model quickly.  Nothing I’ve done goes into production.  I’ve stretched what should be week to fortnight-long projects into months because I have nothing to do.  I’ve literally had only 6 half-projects since I’ve been here.  I feel like I’m trying to find things to pass the time with, and it’s really starting to affect my mental health.  I like to be kept busy.

Also, none of the data scientists collaborate on projects, we’re all assigned our own work, which I feel is possibly not the norm.  It's really lonely, and I feel projects would get done a lot more quickly if we worked together.  We also never have code or project reviews, so I have no idea if what I’m doing is correct or not.  I taught myself to code in the language we use so honestly my code is probably horrendous.

I’ve tried to find my own projects, but it’s such a large and global company that it’s difficult to know where to start.  When I have managed to create my own projects, it’s taken MONTHS to get the data, so I just sit around waiting.  In the absence of anything else to do, I've been teaching myself web development.

It’s got to the point where I’m really considering changing to a software engineering/developer role as I really enjoy coding, and I feel like software engineering is an inherently more interesting and collaborative role.  Is it?

Is my experience typical for a Data Scientist, or is it just my company?  Should I try moving to a data science position elsewhere before abandoning it completely?

**tldr: data science job is really boring, involves a lot of waiting, no code reviews, and there is no team collaboration.  Is this typical for a data scientist or just my company?**",1
63,"[https://github.com/minimaxir/automl-gs](https://github.com/minimaxir/automl-gs)

Not just that, but it supports TPUs when using TensorFlow in Colaboratory and metric tracking at every epoch, allowing to you visualize *everything* during the experiment.

This was a convoluted experiment to test out ML code generation using Jinja, and things worked surprisingly well! Hopefully you all will find it useful!

(I asked the mods ahead of time about the self-promotion and they said it was OK for this use case.)",1
64,"Dear fellow redditors,

I've heard and read that soft skills are quite important as a data scientist (and professional life in general) – communicating results, understanding customer needs, navigating company politics etc.

But how do you cultivate and consciously improve these skills? Do you have practial advice, or can you point me to some good resources?

Thanks a lot!",1
65,"

I've always been interested in computer science, especially with ML and AI. I read many books about it our of pure interest. 

I'm also strongly interested in statistics, especially probability theory.

Here's the thing. I have the opportunity to do a masters in computer science OR a masters in applied statistics. I cant decide which one since I'm interested in both. 

My friend suggested that I do a data science masters because he said its basically statistics + computer science. 
However, It seems there's a stigma attatched to data science as a degree. 

Could someone explain why data science has this stigma and whether it is or isn't good to study?",1
66,"So I recently had some interviews with consultancies. I’m interested in working as a consultant because I think I would be able to gain a lot of experience - I just graduated as a M.Sc biostats and I think that working as a consultant would help me get interesting projects on my resume - as opposed to working one job, especially as a (bio) statistician where juniors often only get to program tables, figures and listings. But a friend of mine (software architect)  tells me that a consultancy is just a temp firm, that pay is low and that I should look for something else. I’m still interested in becoming a consultant but I’d like to hear what you experience as a consultant and what made you choose that path! ",1
67,"Sometimes, I feel like I'm about to lose it with this DS MSc! :' (

**From**:

1. Non-responsive/ blunder from team members for assignments and projects : (
2. Office work, and work - did I mention about the office work clashing with the MSc work timeline ....   :' (
3. My own personal weakness (e.g. impatient, stubbornness, etc.) - yes I will admit this : /

&amp;#x200B;

Yesterday I found out one of the team members met the Analytics professor on campus ***but he forgot*** to show him the project dataset we proposed together as a team. Instead he was just talking about HIS assignments with him - this basically drags our time-line and I was so about to lose it that day but keep my mouth shut, fortunately.

&amp;#x200B;

For DS MS students, please, I need your advice - what would you do if you're about to lose it given any circumstances you faced whilst doing this MS? : (",1
68,"People claim that coders are night owls. Now this may be true for some people...but here’s what they don’t tell you

Meetings at work and filling out various forms about progress checks, reading requests for bugs to get fixed, etc disrupt a coder’s attention to solving a particular problem the coder was assigned before. 

Some of these challenges require some dedicated focus and the only times you get that are evenings, weekends, and early mornings. ",1
69,"Hi, Data lovers D\_D  
I'm posting here, because i could not find it in the internet. :D  


Q.  What is **FinStudio / FinArch** ? ( i know it's software or tool for DW / Analyse  )   
A.  
Q. Dose anyone have experience with this software ? and If you can compare it with other similar software ? witch \_\_\_\_  
A.   
Q. Where can i get copy of it ? ( for Learning purposes )  


Thanks. ",1
70,"It feels like SV alone has created a 1000 AI/ML startups in the past year. 

We all know AI/ML is just statistics. There are numerous articles showing that the shortage in DS is huge simply because...almost nobody studies statistics in college. 

How can it be that all these people are up to something if they don't have the skills in their workforce?

""Forty percent of ‘AI startups’ in Europe don’t actually use AI, claims report"" https://www.theverge.com/2019/3/5/18251326/ai-startups-europe-fake-40-percent-mmc-report

What's going on in your opinion? ",1
71,"My friend, who is a data scientist at a major firm, said they just got license for a data ""robot"" that can do data cleaning and go thru many different models along with cross validation quiet well.

He thinks data science will be dead in a couple of years. What's your take?",1
72,"Does anyone here use Stitch Data for their ETL processes? If so, how's it working out for you and your organization?

We are looking into Stitch Data to see if we can automate pulling data from a variety of ticketing systems (later branching out into other databases) into our centralized GCP environment dedicated for enriched data. We ran into a problem and realized that it really only Extracts &amp; Loads, the Transformation is non-existent (contrary to what it advertises). This forces us to write our own programs (usually in Python) to do a secondary ETL. My opinion is that if we're writing our own transformations, then paying for a third party extract &amp; load is too much for, essentially, the easiest part in the ETL process.

Are there any alternatives that you would recommend? ",1
73,"I'm a neurobiologist and I would like to enter in the data science field. Mostly all the jobs I've looked at recquired an infromatic/mathematic/engineering background, although I may land some internship if I have the right tools.

I've started learning Python, but I have all day free so I'd like to study two programs, one in the morning one in the afternoon/evening. Which one would you advise that is absolutely worth it? Sas? R? SQL? Spark? Scala?",1
74,"I am seeing more and more lengthy assignments to ""test abilities"" given to candidates that require a significant portion of time to complete for consideration for Data Science and Data Analyst roles. Are these assignments truly necessary to test abilities as professionals? And after spending potentially hours of time on doing the work and submitting it, no feedback is given-the recruiter just disappears. 

&amp;#x200B;",1
75,"Release from #GoogleAI: general #tensorflow framework  for #NLP. 

#Lingvo is a deep learning framework used for sequence modeling tasks like machine translation, speech recognition, and speech synthesis. 

Link: https://medium.com/tensorflow/lingvo-a-tensorflow-framework-for-sequence-modeling-8b1d6ffba5bb


Github: https://github.com/tensorflow/lingvo",1
76,"Welcome to this week's entering &amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)  
* Traditional education (e.g. schools, degrees, electives)  
* Alternative education (e.g. online courses, bootcamps)  
* Job search questions (e.g. resumes, applying, career prospects)  
* Elementary questions (e.g. where to start, what next)  

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](https://www.reddit.com/r/datascience/wiki/resources) pages on our wiki.  

[You can also search for past weekly threads here](https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;restrict_sr=1&amp;t=month).

^(Last configured: 2019-02-17 09:32 AM EDT)
",1
77,I'm current a Data Scientist (ML &amp; Deployment) for a Fin Tech &amp; my significant other has asked that I come talk to her class for career day. How would you explain data science to an 8 year old? ,1
78,"Shiny App:

[https://zksmith.shinyapps.io/NCAAMB2019/](https://zksmith.shinyapps.io/NCAAMB2019/)

Github repo:

[https://github.com/smthzch/NCAAMB2019](https://github.com/smthzch/NCAAMB2019)

&amp;#x200B;

Quick little shiny app that allows you to view the predictions of my NCAA men's basketball model. Gives predictions for today's games as well as allows you to pick matchups of your own. I also included a short write up of the model which was fit using Stan.

&amp;#x200B;

Probably going to run out of hours on my free shiny account, but let me know what you think.",1
79,"Hello everyone, 

Long story short: I am a Data Scientist that works for a fortune 500 company in Brazil, and wants to relocate to Europe, but would need sponsorship because I only have Brazilian citizenship. Was a software engineer that transitioned to DS and I work with text mining right now. 

I would like to have some advice on what I should focus on next to maximize my chances of getting a Data Scientist position to relocate to Europe. There are a lot of different fields to work on and I feel kind of lost on how to proceed. 

Since Europe is very big, the options that I envision are:

- The Netherlands
- Germany
- UK
- Ireland
- Switzerland
- Belgium looks good as well, but I would need to study this country a little more to decide. 

Any one of them would be good, since I know that relocating inside Europe is easier once you're there, in case I'm not compatible with my first option. Also, I'm not picky about salary, having enough to pay the bills and eating out two times a week is enough for me, I know I can build upon my opportunity with time. 

I think it's important to give you details about my background, so that you have more information to work with. 

### My background

What I can do:

3+ years experience with software engineering before switching to Data Science so the programming, SQL, NoSQL and ETL stuff is a no brainer to me. I know how to deploy math models using Python and also know infrastructure, docker, Linux, Kubernetes, scalability, networking, etc etc. (I worked as a sysadmin for a year)

I am working with document classification for 1 year already, using TF-IDF + SVM + regex rules. I also do metadata extraction from the text (client name, document id, etc). I have hands-on experience with random forests, logistic regression, NaiveBayes, etc, the standard stuff for text mining. Classification is one of my strengths. 

I know how to explain these complicated concepts to business people, one of my presentations to a C-level executive on how word vectors could be used for a problem made me receive very good feedback from him. 

I am responsible for understanding the problem with the business people so that I can know which problem to be solved first to have better results to then solve it using ML/DL/whatever solves it, I also make the decisions on how the problem will be approached. 

I also know quite a bit about sentiment analysis, since it's what I do in my spare time. 

What I cannot do:

I don't know R (it would be easy to learn R, but I got lazy in that part, Python looks way simpler)

I just have very basic and  theoretic knowledge of regression, that part of DS is not used in my job because I do classification, so I never got past that famous real estate dataset.

I also have very basic and theoretic knowledge of clustering, I know it is very useful for profiling customers, recommendation and all that, but didn't get past KNN and K-Means examples, just the basics. 

My statistics kinda suck. I'm working on that right now by learning on online courses and trying to apply it to hypothesis testing in my work. But I still struggle with how to use random sampling, the exact meaning of confidence interval, p-value, F-test, T-test, etc etc. This is one area that I don't feel confident about. 

My math is not that strong as well, I struggle to understand the underlying maths on state of the art papers. But I don't know if knowing the obscure details of CNNs helps more than being good at using them in a practical setting (avoid overfitting, for example). 

My question is, based on my strengths and weaknesses, what skills should I focus on to have a bigger chance of getting a DS position in Europe? Customer clustering, A/B testing? Financial stuff? Object detection using CNN? Time series forecasting ? Should I stay in text mining and be VERY GOOD at it and search for positions in that field? Or should I know a little bit about everything and pray that it is enough to land the job, to then get very good at something ? 

Will a masters in science help me on getting a sponsored visa position? Or is it more about what I can / cannot do in practice, instead of academic success? 

I have a B.Sc in Computer Science BTW. 

My favorite area of study is computer vision, but I don't see a lot of job postings about it.  ",1
80,"I see a lot of job postings asking for experience creating, maintaining, and modifying data lakes and pipelines.

I've also heard a LOT about pipelines, and a little bit about lakes (mostly in passing), but I don't think I've ever seen someone actually talk about them in depth. What are they exactly? How do you build them? Do you need something like Spark or Hadoop? What about Azure? Where can you go to learn this power?! 

If anyone here works with these concepts, can you shed some light on this topic please? And perhaps drop some resources to study? Please?

[What does it mean?! WHAT DOES IT MEAN?!](https://i.redd.it/h7hw96tmqsn21.png)",1
81,"Hi guys, looking to speed up our routine DS/ML model exploration analyses and was directed to h2o. Post data preparation, we largely do exploratory work in r or python notebooks. It seems like the sort of thing we need but I wanted to get some opinions and other options too from the community. I have also tried knime. 
Many thanks in advance, ",1
82,"Hi All. I'm having a first world problem dilemma... and would love some advice from people who have been in a similar situation.

I am currently very privileged to be living the ""data science dream"". I work as a product data scientist for a big tech company in Silicon Valley, my work is appreciated by my stakeholders and peers, I am well paid (TC = $160k for 3yoe + stock), and I feel like I am constantly learning new things at work.

I am not originally from the US, I relocated from France where I am from, and would like to move back at some point, to reconnect with family and friends. My original plan was to stay 3 more years from today, and continue saving as much as possible to move back with some savings, with the prospect of retiring early.

However I am realizing that not only salaries will be significantly lower in France (we're talking 3x lower), but the prospects do not look so exciting from a DS perspective (e.g. archaic corporations who look for data analysts, or startups who use words like ""neural networks"" in every sentence).

Anyone has been in a similar situation and would be able to provide some guidance?",1
83,"Do any of you work as data analysts/scientists for law firms or in that field? What kind of work do you do, what do you like/dislike about it, and what advice do you have for getting into that field of data science?",1
84,"So you want a coveted internship? This answer is mainly geared towards software, but can be applicable to any industry.

I have some tips that helped me get my first software engineering internship in Silicon Valley, right out of my coding bootcamp. I break down some of the best ways to get an internship as quickly as possible, as easily as possible.

Whether you studied computer science in college, went to a coding bootcamp, or are self-taught, these tips will help you through.

If you prefer video format, here’s a video I made covering these topics:

[https://youtu.be/eyzKYYwB0ng](https://youtu.be/eyzKYYwB0ng)

The first main tip is to start as early as possible. Bigger companies who have the most internships available start early in August, September, an October with posting their internships. The earlier you start, the higher chance you have at beating the competition.

The second tip, and probably the most crucial one is to use your network. Using the back door to get your foot in is much easier than using the door that thousands of people are using (the automated online job portal). You can use LinkedIn, Facebook, and word of mouth to find people who worked at specific companies. On LinkedIn, you can use search queries like \[Insert college here\], and then use people filters such as 1st /2nd-degree connection, location, and company. This helps hyper-target your audience.

The best people in your network to reach out to are:

\- College / coding bootcamp alumni who work at the company you want to work at

\- Friends / classmates who interned at that company

\- Professors / mentors who might have connections with that company

\- Friends of friends who work there (use Facebook to search this - “friends of friends who worked at \[X company\]

The next tip (this is crucial, and will save you a ton of time). Don’t send your resume off into a black hole (such as Indeed, Glassdoor, etc) and do nothing else. My rule is for every job app you send into an online portal, you need to connect with one real person as well. There are a handful of ways to connect with a real person at this company - use a Gmail plugin like Clearbit Connect, or Hunter io to find peoples’ work emails by company search (give them a quick Google - you’ll see what I mean). These are extremely powerful tools. Then, send them a quick note:

\~\~\~

Hi \[person’s name\]!

My name is \[your name\], and I’m an \[type of engineer\] in \[location\].

I’m reaching out because I applied to \[company\] regarding your \[position\].

I have experience with \[this technology, skill, etc\]

Following up, I've provided my resume and cover attached letter below.

Would someone on your team be open to chatting more about this role by \[insert date to add time pressure\]?

Thanks so much!

\[Your name\]

\[Phone number\]

\~\~\~

Following up after they’ve responded:

Would you be willing to connect me to the hiring manager for this position per chance? I'd greatly appreciate it!

Thanks so much!

\[Your name\]

\~\~\~

The most important thing is to not be annoying. If they don’t respond after following up once or twice, try another person at the company.

If you’ve used the last 2 tips (network, reaching out) and have finally connected with a real person, you can ask them “How can I stand out in the intern application process for \[X\] company?”, or even better, ask to buy them a coffee and pick their brain about their experience working at the company, the company culture, and to see if you’d be a good fit.

Another way to stand out is to have an amazing portfolio. This isn’t absolutely necessary (at least for Software Engineers), but will help you stand out above the crowd. My tips here:

\- Host your projects on Github (clean up code, add ReadMe, etc)

\- Add your projects, with screenshots and descriptions, to your LinkedIn experience/projects section

\- Create a video outlining your design decisions, tech choices, etc (I did this when applying, and it definitely helped)

\- Deploy your projects to the web, and have a landing page which can direct people towards them

The next tip is to prepare for the technical interview. If you’ve gotten this far but fail the technical portion, chances are you won’t make it further. They can give you any question, but your goal is to be familiar enough with basic concepts, so you can adapt on the spot. Using sites like LeetCode can help improve your technical ability. It also helps if you’ve seen similar questions to the interview ones - LeetCode will help you with this. Sites like Pramp help you practice interview skills live, which is another surefire way to get feedback and improve your chances at doing well. Take a few deep breaths before you walk into the interview, and you’re ready to go because you know you prepared!

The final tip I have (and one that sped up my job search tenfold) is to track EVERYTHING. There’s a Gmail plugin called streak that allows you to track your job search in a funnel. Streak also allows to send template snippet emails, and you can see if someone has viewed your email. So handy!

I customized the funnel by tracking:

1. Company Name
2. Position Name
3. Contact Name
4. Contact Email
5. Contact LinkedIn
6. Date of Last Contact
7. Job Source
8. Job Posting URL

If you’re not a fan of Gmail plugins, you can also use a spreadsheet like Excel, Google Sheets, and my favorite (spreadsheet/database mix) Airtable! Airtable is a solid option, because it allows you to link different tables, attach documents, and organize things with ease. An Airtable tutorial would take a whole other post, but I encourage you to check it out!

The job search is ultimately a game of failure, persistence, and triumph. You ultimately need to create your own luck, and this happens by widening your pool. Start applying to as many places as possible! These tips I shared above allowed me to apply to 150 jobs in 3 days! Most of the time I ignored the cover letter (do they really matter, anyway?) and focused completely on connecting with a real person. That’s what will ultimately start you on your journey.",1
85,"I'm in the process of interviewing at a company and they sent me essentially a customer retention problem, asked me to explore the data, create a model, and evaluate it. Then make suggestions on what different models you might use, pros/cons, etc. I've done what I can with the data, and the logistic regression model is legitimately poor. I'm just wondering what managers are looking at when they look over the assessment. I'm already doing this in a language that is not my strong suit at their request. So though I know the theory and the process I'm using seems sound, I'm not sure if that's going to come across in an unfamiliar language under time constraints. Any advice?",1
86,"My firm is really not investing in quality control and infrastructure. I deal with it but have to essentially lay the foundation for many projects at the data collection level. I'm looking at new positions and wondering what the signs of a more robust and mature infrastructure are. Similarly, the signs of weak plumbing and quality control. ",1
87,"For those who tried to be data scientists and failed but still have the skillset of a shitty data scientist (Python, SQL, building not that great models)... what are those roles?",1
88,"My question is in reference to Kaggle competitions but in some contexts can apply to the professional world. 

What are the roles when **developing** a machine learning model within a team?

&amp;#x200B;

I could envision each team member independently coming up with a good model and than the team creating an ensemble of all of those models perhaps? Or perhaps there are different team members that focus on model creation / communicating the results?

&amp;#x200B;

I was tempted to enter a competition solo, but if having team members will provide a benefit, I may go for it. 

&amp;#x200B;

&amp;#x200B;",1
89,"/r/CollegeBasketball's runs a Men's [college basketball challenge](https://www.reddit.com/r/CollegeBasketball/comments/b2hznx/the_eighth_annual_rcollegebasketball_bracket/), they score various  the various subreddits by how accurate they are. Any interest in getting a group together for datascience? You can change your group at any time for this.

For our own DS twist, you can post your bracket picking methodology. I use a modified ELO weighted by Vegas odds. 


**Boring explanation for people who've never watched**

For the Non-US among us, March Madness is an annual basketball tournament similar to the knockout stages of football (single-elimination) that is used to determine the best college basketball team in the country  (think of it like UEFA Champions league but much more compressed in terms of timeframe). Since college basketball teams play in separate conferences (think domestic leagues), there is no way to claim bragging rights of the best team in the country. It's referred to as madness because the tournament takes place over 2 weeks and anything can happen (like giant-slayers in the FA cup if you're a Brit).

538 usually has a great writeup of the odds and their models (https://projects.fivethirtyeight.com/2019-march-madness-predictions/)",1
90,"I am in a  , BI , analytics , biostatistics, data science type of role  . Lots of stats comes my way but no one is a statistician that I can go to with questions . There are projects where some predictive modeling would be great but once again I don’t have enough experience to know with certainty that my approach is feasible or correct 

Where does one go when there is no one at work that understands what you are trying to do?
How do you find a mentoring of this type ?

(Industry is healthcare, hospital ) 

",1
91,Last thing I want to do when I get home from a full work day is more work. What keeps you going?,1
92,": (

Tough enough to do an MS whilst working, now, we're dealing with this!

There are a few types I found (you can add them if you want):

1. MIA due to their own commitments (as if some of us don't have one!) so can't contribute or contribute at the last minute! :' (
2. Wants to contribute but are either intimidated (by the work) or have no clue what to contribute (but genuinely want to do some thing) - ok, this is fair but of course, more work for you : /
3. Non-responsive team member - as in they won't respond to messages or email - only during meet ups, like in classroom only ... Jesus ... : / 
4. Hyper-active types that want to constantly meet the lecturer for consultations or discussions but not all team members feel like there's a need to meet the lecturer for the most rudimentary question : |

&amp;#x200B;

I am not too sure if I'm stressed out with the above situations or just a combination of the MS and work, thus not being able to see the bigger picture.

Any advice is really appreciated : (

&amp;#x200B;

&amp;#x200B;",1
93,"Hey guys.

I want to discuss about something that is itching me right now.

I recently posted in the weekly Entering thread. I am a student in mathematics and computer science who is studying to become a data scientist. I am currently learning C++ by myself and was told to transition to Python ASAP. I was reading a Data Structures and Algorithms book (in C++) during that time (and still am, spoiler!)

So I did my DD and told myself why not learn that subject in Python to learn the language at the same time? There's where it became more problematic. I understand fully that for someone who wants to become a data scientist, Python is mandatory since it has these beautiful libraries for machine learning &amp; co. But the problem I faced is that when I wanted to implement my own data structures in Python, I realized that so much is done under the hood that it's pretty much impossible to get an in-depth understanding on what is happening, and to optimize stuff on ""my way"".

So my question goes as follow : Since optimizing is a huge part in a data scientist job, and playing with data structures/optimizing algorithms is also so important, why is it not pushed more to get a core undestanding of it? I understand you can use stuff that you don't understand completely, but for someone who's JOB is to use it, shouldn't he understand at least the fundamentals?

I want to hear your opinions!

PS: Just to be sure, I am not ranting on Python, I am saying it's hader to get a grasp on the core because it's all done out of sight. I am not saying C++ is better either, I am asking why people do not recommend to learn a lower level language (any!) before learning Python.

Thank you guys.

T.",1
94,,1
95,"(Sorry for such a long post; main question is at very end.)

I have finally received an acceptance letter for a Statistics grad program (yay!), and plan on leaving my company in late summer to go back to school full time.  I currently work as a data analyst for an automotive supplier, and my boss is aware that I will be leaving the company, and he will be working with HR soon to start the process of finding (and potentially using me in part to train) a replacement.  Thankfully, everyone is very supportive.

I was the first person in the company, so far as I am aware of, who does ""data analysis"" and has a statistical background, novice as I am on paper in that matter.  I am not very happy with the way my job is currently structured and would have planned on leaving anyway if I had not gotten an acceptance.  My work is not very well defined; there are data management issues (like storage, access, standardization across sites) which slow work; and I do not have anyone in my company who is able to double check my work from a statistical POV—or even more preferably, elevate it to (and appreciate) a higher sophistication.  While officially on a team, I am not on a team of people who do what I do, and am very independent anyway.

I have been asked to help craft a job description for my replacement.  However, while I can easily regurgitate my current responsibilities onto paper and list what skills I have found useful for executing them, I would like to expand this task to communicate back to my employer how best to structure such a job, from hierarchy of needs they should be considering in order to streamline the data analysis process (instead of merely filling roles I have been haphazardly shoehorned into, and ignoring needs which subsume them), to better establishing specific duties to achieve those ends (instead of giving the next person as much autonomy as I have).

I would like to do this, and have come to this community for feedback on how to do so, for two main reasons: (1) I myself need to grow and manage my expectations for what a better data analysis or data science job looks like, and (2) I would like my successor(s) to experience that better if I have some latitude to reform it.

To give a rough outline for what I would like to learn and communicate back to my company, posed as questions:

- **What are the standard vertical and horizontal structures surrounding a technical job like an analyst?**  Right now, I receive work not only directly from my boss, but also often directly from different people in the company (some high up) who are aware of me and the statistical skills I provide.  Sometimes these projects do not have established timelines or well-defined metrics or goals, and this creates disorganization and workload/expectation problems.  After working like this for some time, it seems to me that a wiser system would be for projects to be administered through management, and interactions between groups (such as, a chemical test lab group and my group (myself)) to ultimately start and end from above.  Is this misguided?  How do project management and team interactions work in well-functioning systems?

- With deference to some of the prior considerations, **what sort of environment (have you found) works best for a data analyst to thrive in?**  For instance, I feel that I would have liked to have another person on my team who does what I do so I could bounce ideas off them and assert my own expectations better.  I also feel that the rest of the company isn't very good at managing their own expectations for what a single data analyst can do, and my position as an almost independent service provider within the company speaks to that.  How are data analysis teams organized and how do they manage the request-result cycle?

- **What functions often go underserved in a company starting to sophisticate its data analysis process, and what skills should it seek out to fill those?**  As I mentioned above, there are non-homogeneities in how data is collected and stored and made accessible between different manufacturing or test sites that we have, and some projects that they would want to work on in the foreseeable future will involve more sharing of this data between sites.  Data is often dumped into a ""vault"" specific to each site (with very limited read access), and can be made available in a hodge-podge way on a network we have.  It doesn't seem conducive to accessibility.  I am also woefully underinformed on the full extent of data management at our company, so the problem may just be my level of knowledge; but the prescription nonetheless may be bringing in someone with the skills required to interact with the data we have, even if vaulting and networks are enough.  Who works behind the scenes that a data analyst depends on?  What skills should that person have?

- Finally, **How can I combine the above into job description(s), for employer and prospective employee alike?**  How many people make a good team?  What should they each bring to the table?

These are the things about which I will likely ask more follow up questions.  That may come when I have done some more thorough investigation into what expectations and gaps people in my company find for data analysis.  I also may not be asking the right questions, and I may have different ones depending on the feedback I get here.

Right now though, I think this is my question for this post:

How would you characterize a ""good"" and functional data analyst role and what does their team look like?",1
96,"I've collected the snippets that I developed during my last 6-months, intensive MRes project. Almost every piece is my own code and most of these hacks were not published before. Hope it will help some researchers with their work.

[https://medium.com/@krassowski.michal/productivity-tips-for-jupyter-python-a3614d70c770](https://medium.com/@krassowski.michal/productivity-tips-for-jupyter-python-a3614d70c770)

One click less:

1. [Play a sound once the computations have finished (or failed)](https://medium.com/@krassowski.michal/productivity-tips-for-jupyter-python-a3614d70c770#3b5a)
2. [Integrate the notifications with your OS (ready for GNOME shell)](https://medium.com/@krassowski.michal/productivity-tips-for-jupyter-python-a3614d70c770#ad45)
3. [Jump to definition of a variable, function or class](https://medium.com/@krassowski.michal/productivity-tips-for-jupyter-python-a3614d70c770#3424)
4. [Enable auto-completion for rpy2 (great for ggplot2)](https://medium.com/@krassowski.michal/productivity-tips-for-jupyter-python-a3614d70c770#7a8a)
5. [Summarize dictionaries and other structures in a nice table](https://medium.com/@krassowski.michal/productivity-tips-for-jupyter-python-a3614d70c770#2c78)
6. [Selectively import from other notebooks](https://medium.com/@krassowski.michal/productivity-tips-for-jupyter-python-a3614d70c770#8dd4)
7. [Scroll to the recently executed cell on error or when opening the notebook](https://medium.com/@krassowski.michal/productivity-tips-for-jupyter-python-a3614d70c770#68cb)
8. [Interactive (following) tail for long outputs](https://medium.com/@krassowski.michal/productivity-tips-for-jupyter-python-a3614d70c770#8313)

*Processing gif ryp1i29gsum21...*

&amp;#x200B;

If you want to go straight to the code: [https://github.com/krassowski/jupyter-helpers](https://github.com/krassowski/jupyter-helpers)

Do you have your own, not so well-known tips as well?",1
97,"I released a new version of my Debian packaging for JupyterHub (https://github.com/1and1/debianized-jupyterhub#jupyterhub-debian-packaging). It makes the installation of a fully working hub on a Debian or Ubuntu server easy, with everything already installed and compiled (no build tools needed).

The package comes with a fully equipped Python3 kernel – the scientific Python stack and common visualization frameworks are built in. All additional packages beyond the JupyterHub core are organized into setuptools ‘extras‘. You can select them for inclusion (many are added by default), or remove unneeded ones to reduce the package size, by changing the “debian/rules” file.

On an Ubuntu / Debian workstation, using this package you get readily available notebooks for personal use, without the need to start a notebook server on the command line every time you want to edit a notebook.

Technically, this is a self-contained Python3 venv wrapped into a Debian package (an ""omnibus"" package, all passengers on board). You can build the package in a Docker container, so that you don't need to worry about installing build dependencies – the Dockerfile does that for you, without affecting your workstation or build host.

For more details, check out the GitHub README (see link above).


Changes since 0.9.4-3:

  * Extras: Added 'docker', 'nlp', 'ml', 'utils', and 'vizjs' (included by default)
  * Extras: Added 'arrow', 'nltk', and 'parquet' (optional)
  * notebook: update to 5.7.6 (CVE-2019–9644); also updated other explicit requirements
  * Tornado: kept at 5.x because of compatibility problems
  * Packaging: Switched to built-in Python3 venv",1
98,"[https://towardsdatascience.com/build-a-corporate-r-package-for-pleasure-and-profit-78b73ce4ff4b](https://towardsdatascience.com/build-a-corporate-r-package-for-pleasure-and-profit-78b73ce4ff4b)

&amp;#x200B;

I wrote an in-depth tutorial on the art of building a ""corporate"" R package, that is, a package with built-in ggplot themes, common data sets, templates, etc. Hope it's helpful to you!

https://i.redd.it/tnd67bafivm21.png

&amp;#x200B;

&amp;#x200B;",1
99,"We were able to get 4 members of the subreddit to volunteer to participate as part of the panel - hopefully if we get some good content and discussion going we can add more people to the panel moving forward.

**How does this work?**

Post any questions that you are interested in the panel answering.
Upvote/downvote any questions that you think would be good/bad for the panel to answer.
At the end of the week, we'll choose the top voted answer.

Caveats:
Any questions that are answered in the wiki and/or we don't feel would benefit from multiple points of view will be ignored. The idea is to focus on topics where 4 different professionals may have 4 different opinions/viewpoints.

Thanks everyone who has volunteered to participate, and let's get some questions going!",1
100,"With how inconsistent titling is among data science roles, I wanted to get a feel for how people perceive titles. How would you rank these titles (in terms of highest to lowest in the org), assuming ties are allowed and all other things equal (i.e., same company):

* Data Scientist
* Lead Data Scientist
* Principal Data Scientist
* Chief Data Scientist
* Associate Data Scientist
* Head of Data Science
* Data Scientist I
* Data Scientist II
* Senior Data Scientist
* Director of Data Science
* Manager of Data Science
* Sr. Manager of Data Science
* Sr. Director of Data Science
* VP of Data Science
* Data Science Specialist",1
101,"I was offered a data scientist job at a unicorn fintech firm with an established data sciences team. It was my first interview for a data scientist role and I had to interview with over a dozen people including multiple leaders within the company. Even before I was invited for a face to face interview, I underwent a coding assessment (timed). I usually do not do well in timed challenges as they make me nervous and I can get flustered easily. They rejected me after the assignment (I received the news while I was waiting in the lounge of another company getting ready for my final interviews with the second firm for a Developer role). 

&amp;#x200B;

&amp;#x200B;

But after the rejection, I decided that it wasn't the best assessment of my performance and I took all the feedback the team had for me and re-did the challenge over the course of next week. I reached out to the company again with my results and asked them to reconsider my work (with little expectation). I think the company liked my initiative and they invited me for onsite interviews. I said yes to this since I had another offer for a different role from a startup. My onsite interviews were average at best and shitty at worst. I felt I did not do well and went to bed at 5 in the evening. I could not answer questions from past since most of these questions were from five years ago. During the technical interview, the interviewers were looking for a very specific answer, but I had zero clue on what exactly they were looking for. I felt comfortable defending my work, but that's about it.

&amp;#x200B;

&amp;#x200B;

By next noon, I got the dreaded call from the recruiter and she tells me that they really liked me (very puzzling). They wanted me to do a few more interviews with the team since the team wanted to be sure that I knew my shit. Now, to give you a quick idea about my background, I don't have much data science experience outside of some projects I did while on my free time and my startup which focuses on visual data. So I was pleasantly surprised that the company gave me an offer in like two hours after I finished my final interviews.

&amp;#x200B;

&amp;#x200B;

I want to thank this community since it would have been pretty difficult to prepare for the interview without some of the posts here. My only advice is, if you have the grit, you can be anything you want.",1
102,"I’m considering changing industries and something that sounds interesting is video game analytics. Has anyone out there worked as a data scientist in the video game industry? If so, can you share your experience? What’s it like?",1
103,,1
104,"Welcome to this week's entering &amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)  
* Traditional education (e.g. schools, degrees, electives)  
* Alternative education (e.g. online courses, bootcamps)  
* Job search questions (e.g. resumes, applying, career prospects)  
* Elementary questions (e.g. where to start, what next)  

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](https://www.reddit.com/r/datascience/wiki/resources) pages on our wiki.  

[You can also search for past weekly threads here](https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;restrict_sr=1&amp;t=month).

^(Last configured: 2019-02-17 09:32 AM EDT)
",1
105,"I'm currently a senior data scientist in a small startup in Boston. I'm looking to change companies in the next year and want to begin getting experience leading a team. My current startup is very small and flat organizationally. I basically own the production machine learning pipeline and don't work closely with other team members on it, so no opportunities to manage juniors, etc.

My goal is to eventually be in a VP/Director of Data Science position and recognize I need experience leading a team. Our engineering group uses Agile (loosely) and believe this is common for many companies.

Given that I am looking to make a job change in the next year, should I pay out of pocket to get the Certified ScrumMaster designation ($1K USD and two days of classes)? Would this be a differentiator when interviewing? I'm thinking it may provide signal that I'm committed to developing as a project manager/leader, and also be valuable in its own right. 

And before this gets raised, yes, I understand that my chief value will be based on my core technical skills as a data scientist. I am already heavily invested there. FWIW, my background is PhD in engineering from a great school, 4 years experience in risk consulting for nuclear/defense industries, 4 years data science/machine learning experience.

Thank you for the input!",1
106,"Hello all!

I’m currently working on transitioning into the data science field. Former quant research associate and have a solid stats background. One thing I can’t really stop thinking is that, am I preparing to transition into a field that might not exist? It seems like no one really has a strong handle on what’s going to happen in the field, so I am wondering if I’m transitioning into a field just to transition back out, if I should focus on a more specified job (ML engineer, data engineer, etc.) or how to navigate things. Advice would be greatly appreciated!",1
107,"For those of you working in the field and have experience seeing the process of new employees being hired, 

How much value do you put in verified certificates from online courses? 

I’ve logged a healthy amount of hours and completed courses from various MOOC platforms (EdX, Udemy, Coursera, Datacamp), but have never paid for a verified certificate. Do you think for somebody pursuing employment that it would be worth it to pay for verified certificates? 

Thanks in advance for any insight ",1
108,,1
109,"I currently work as a data scientist at a Biotech company, that has no established data science team, leadership or infrastructure.  I have a Master's in CS  (specialization in data science) from a top 5 CS college and and undergrad from a top 5 engineering college in India. I joined the company right after college because that's the only job I got and there seemed like a big scope for introducing the company to some data science. However, after 2.5 years of coaxing and trying, my colleagues, management and leadership don't consider data science to be a priority and hence I've only been working on exploratory projects  (that use a little bit of Deep Learning) that have never made it into a product. I spend majority of my time doing data engineering and just vanilla scripting on Python and Matlab to automate otherwise labor-intensive  manual analyses. My skills and resume have suffered deeply over the last 2.5 years and I am clueless as to how to explain to recruiters and companies what I've done in the last 2.5 years at this company. I have interviewed with a bunch of companies and it CLEARLY shows that my data science skills have taken a deep hit when I'm not able to answer simple questions. I have taken multiple online courses and professional development programs, but that doesn't seem to be helping. I personally think I would make a great data scientist at any company. I would really appreciate any ideas on how to go about improving my current state of affairs.",1
110,"Hi Everybody,

&amp;#x200B;

I'm not sure if this is the exact right sub for this question--I posted it over in r/jobs as well but I was hoping to get some feedback from people in my field if possible.  

&amp;#x200B;

I was wondering how much flexibility telecommuting employees have as far as where they work from. For some context, I currently live in New York (In Data Science / Analytics) but my SO may be doing a degree program in England. I don't want to fully give up my NY residence if I don't have to, so I'm looking for remote opportunities which would allow me to work from either the US or the UK. My ideal situation is one where I could spend 2 or 3 months at a time in either country, while working remotely full time. Is this possible? Most Remote Data Science opportunities I've seen say something like ""Work from anywhere in the US"" but I'm not sure if this means you can't work outside the country, or just that you need to be based in the US (citizenship, resident, paying taxes etc). I'm born and raised in the US so that wouldn't be an issue.

&amp;#x200B;

So for anybody here with experience in a remote analytics role, were you free to work from wherever you wanted, provided you had a good internet connection and made yourself available during business hours?  

&amp;#x200B;

Thanks in advance!",1
111,,1
112,"Incompetent interviewers are so frustrating. Companies really need to do a better job of screening the people they allow to conduct interviews. 

So the situation was that I was in an interview process with big company that has a big AI group. I finished my second phone screen two days ago. The first one went really well. I really liked the person. I answered all of their technical questions and I received an email that they wanted to move forward.

The second guy was pretty weird. He didn't introduce himself, and I had to stop him to ask his name. He then proceeds to ask me about the one non machine learning project on my resume. I start to tell him about it, and he asks 

""Well do you have any ML experience? Because we do a lot of that here.""

Well then maybe you should ask me about the three other ML projects on my resume which you clearly didn't read until you asked me that question. I then started to tell him about one of the ML projects on my resume. He asks a few questions in that annoying way, where interviewers try to poke holes in your work to try to through you off balance. I'm thinking ""Dude I worked on this for a year. I know what I'm talking about."" I answer his questions and he seems satisfied.

He then asks me a few basic ML questions (e.g. explain linear regression and SVMs). I easily answer those. He asks me a coding question, which I also easily answer. Throughout this whole time he's challenging me by asking questions on things that he clearly doesn't understand that well. He tried poking holes in my solutions, usually by saying things that we're just wrong, which led me having correct his understanding of basic things (e.g. What is a random variable). I try my best to do it politely as possible.

He then says that he doesn't have anymore questions and if there's anything I want to ask him. I ask a few basic questions about the company, and we call it a day.

I get feedback today that they're not moving forward because of my lack of knowledge of NLP. Dude didn't even ask me about NLP. If he did he would know I'm pretty freaking knowledgable about it. We ended the interview 15 minutes early, which I don't maybe he could have used to ask me about NLP if it's so important. 

What's really frustrating to me about this is the AI group there is really large and the fact that I had a problem with this interviewer doesn't mean I wouldn't fit. In other situations I would just say ""Well at least I don't have to work with him."" But from talking to the other guy, I think I would have actually fit in really well there, and I just had bad luck by getting this one guy as an interviewer.

Anyway I guess there's not much I can do. Rant over.",1
113,"This is kind of a rant, but I see so many people who parrot the sentiment that ""data science"" degrees are a joke, or that it's ""just applied statistics"" and that there's a stigma. 

I don't have a degree in data science so I don't really have a skin in the game but to me, such arguments seem like a mix of gatekeeping and ""no true Scotsman."" I come from a pure math background and I've seen mathematicians say very similar things about statistics or physics or CS: ""oh that's really just applied math"" or ""they are not really rigorous like math"". And I found that incredibly annoying and I guess the reason why I get annoyed by this sub's hate for data science too.

I see people coming from data science or business analytics degrees from schools like MIT, NYU, Carnegie Mellon that do just fine. Obviously these are good programs and there are countless other shitty data science programs not worth their salt. But it's the same thing with degrees in statistics or CS, innit? Yes, the popularity of statistics and CS means these master's programs have been sprouting like rabbits too. It's not just data science. Crappy schools that hastily create these programs for more money will be crappy. It's true of any degree, really.

So I'm not sure why people keep shitting on data science degrees, other than to make themselves feel better and superior.",1
114,"I’ve talked a few data scientist and it seems that the model the model that’s often used in implementation is Random Forest. I’m wondering outside of an implementation environment, how can machine learning models be used to inform decision making in a non production environment? ",1
115,,1
116,"I’m looking to hear from those with in experience on both sides of the pond or with some reference point to compare the two. 

I’m thinking along the lines of 

- job market competition and mobility
- tradeoff between salary vs benefits
- education requirements
- career outlook
- career &amp; social status

Any thoughts? I’m happy to hear about regional differences too. ",1
117,"I was like one of you folks once, trying to think how to write a resume before I started working as a full-stack dev at a place I love. Over the years I have obsessed about how to make it easy for every one to build their resume. Using some AI magic, I ended up creating a site (a side project) that allows you to create a resume for free. Here’s the link: [https://thisresumedoesnotexist.com/](https://thisresumedoesnotexist.com/)

I've used [https://github.com/minimaxir/textgenrnn/tree/master/textgenrnn](https://github.com/minimaxir/textgenrnn/tree/master/textgenrnn) to generate the text by feeding it data scraped from various resources. My script runs in a ""while true"" loop and generates a new resume every 3-4 seconds. Resume is then saved to S3 and the same resume is loaded via CloudFront for all users.

I plan to make it more and more awesome, like you add your name and designation and it fills up your resume. But, I thought it would be nice to get a feedback from you folks and see if I can add the to my to-do for the side project.

I’d the following thoughts on why I started working on it:

\- I knew a guy who got a job at Google, who previously couldn’t get a job at an IT agency just cause his resume wasn’t good enough

\- Not all of us have the skills required to write creatively and organize it. That doesn’t mean you don’t qualify for a job

Things like these are weirdly still a hurdle for many (it is going to be 2020 next year!). I want them not to be a hurdle anymore :slightly\_smiling\_face:

So, pitchfork me if you hate what I built, but if you loved it or have any suggestions do share your thoughts with me. Appreciation will make my day, critique will help me shape it.

Thanks,

Alex",1
118,"Hello everyone. I’m currently in my last two semesters of graduate school earning my MSc in Data Science. Does anyone have experience being asked to pay for your own ticket to fly out to an interview for an internship? I have some friends claiming it’s complete BS for a fortune 100 company to ask me to pay for my airfare while others are calling me entitled for even asking them to pay. I feel that the company asking me to book airfare the week of is not very considerate of the financial situation most students are in. If anyone could just share their experience I sure would feel much better regardless. I have an open mind and don’t really know if I’m in the right or wrong here.


Edit:
Asked for skype interview, been ghosted the last 24 hours. I think I dodged a giant bullet. If anyone else has a similar experience with New York Life I would love to hear it.",1
119,"I recently read [this article](https://www.bain.com/insights/advanced-analytics-global-private-equity-report-2019/) from Bain’s Private Equity practice, and I’m curious if anyone has any experience with this kind of work. (I’m also interested in how this might relate to Bain’s [Macro Trends](https://www.bain.com/insights/topics/macro-trends/) practice.)

&gt;At a time when private equity firms face soaring asset prices and heavy competition for deals, advanced analytics can help them derive the kinds of proprietary insights that give them an essential edge against rivals. These emerging technologies can offer fund managers rapid access to deep information about a target company and its competitive position, significantly improving the firm’s ability to assess opportunities and threats. That improves the firm’s confidence in bidding aggressively for companies it believes in—or walking away from a target with underlying issues.

**Questions:** Does anyone here use their data science skills for private equity research or economics for a consulting firm like Bain? What is that work like? What tools do you use, and how would you recommend someone interested in making a switch to that field? Any recommended resources to learn more about that career path?

**Background:** I currently work as a marketing strategist, I’m starting a dual-degree MBA/MS in Business Analytics in the fall with elementary programming and math experience (though I do have an MA in humanities). Yet I can’t decide if the Data Science or Financial Analytics track would be better for me getting further into my research and strategy career.

Any advice or wisdom is welcome.",1
120,"Yes, *it's superficial* and the person enrolling or (even, say, recruiters) would need to see the content of the programme e.g. individual coursework/ structure/ research *to get an idea of the package*. 

e.g.:

* MSc. in Data Science
* MSc. in Business Intelligence 
* MSc. in Predictive Analytics 
* MSc. in Business Analytics and Data Science
* etc. 

Some of these can be very different (content  or even field wise), but upon inspection of their structure, they would or could overlap considerably to the point their difference is moot, to both enrollees and recruiters. 

&amp;#x200B;

But, from a personal or professional-level, would the title of a Masters programme influence your decision for enrollment or even recruitment? ",1
121,Did the MSPH prepare you well for the job?,1
122,"Hey everyone, I'm considering switching my major from CS to Statistics &amp; Data Science with a minor in CS. I would be transferring to a different school for this, however. I am currently studying at Washington University in St. Louis and would be transferring to the University of Arizona.

My dad is against me transferring because of the drop in prestige. WashU is a top 20 school and U of A is a decent state school. He says that the name of your school will make a big difference when it comes to landing a good job. However, he is in the medical field so I feel like the impact of university ranking is much different when it comes to doctors. I know for engineering, outside of the powerhouses like MIT, Stanford, Cal, CMU, etc the name of your college doesn't make a huge difference.

I wanted to ask people in the field, how did the name of your university affect your job prospects? Would I be really worse off in my career by transferring? Thanks",1
123,"Dear fellow DS-Redditors,

in our company, my Data Science team is currently struggling with the 'last mile', i.e. have our insights and predictions bring about actual change.

We have sufficiently mastered the technical aspects, with APIs and platform at our disposal and available to others. Also, we've established trust with senior management executives.

What remains is to convince coworkers from other departments, e.g. sales, to work with us. Many hesitate to cooperate or to make use of our results and our work, and I feel like this boils down to a couple of human reasons:

* The generally resist change, especially when initiated by others
* Their division manager might have a long-standing rivalry with our division manager
* They see us and our suggestions/results as 'invading their territory'
* They view us as young and snobbish know-it-alls

How would you approach this problem? 

As a last measure, we could make our case with the executive level and have them pressure their guys to cooperate. However, we'd really like to solve this problem 'bottom-up' instead of 'top-down'.

Cheers and thank you!
Derek




PS: I found some resources describing similar problems, but I feel like they don't exactly match our situation:

* https://hbr.org/2019/01/data-science-and-the-art-of-persuasion
* https://www2.deloitte.com/insights/us/en/deloitte-review/issue-16/behavioral-economics-predictive-analytics.html",1
124,"Hello all, I’ve searched for an answer to this question but I am not satisfied with some of the answers I’ve found. I’m sure Python and R probably have a lot of custom features/libraries and you could probably design some very unique visuals OR handle massive amounts of data; however, a tool like Power BI just seems so much better for everyday business needs.

I guess I’d sum up my question as: “why write lines of code in Python to create a plot, change the width of the line, add a title, and make the bars of the values red and some blue, when you could just drag and drop? 

Finally in reporting using Python and R visualization, how do you distribute the results to customers? Export the charts to Excel? Can they be hosted on a cloud platform? I’m completely ignorant of how reporting works using Python and R visualization and I’m curious on hearing some explanations. 

Thank you! ",1
125,"As mentioned in an earlier thread, we know that there are several contributors to this subreddit that are in data science leadership positions, and we'd like to leverage that to help answer questions for the subreddit from the perspective of those in positions of (some level of) power.

For the sake of having some objective definition, we are defining data science leadership as professionals that fall in one of two buckets:

**Senior Management Data Scientists:**

* Supervise a team of data scientists
* Responsible for defining overall data science strategy for company (e.g., defining career paths, building capabilities, growing the footprint of data science within the company)
* Title expected to be Director level or higher (though not a hard rule as some companies brutally undertitle their people).
* Not necessarily expected to be most technical person in the organization

**Higher-level individual contributors:**

* May or may not supervise a team of data scientists
* Responsible for identifying emerging trends and their feasibility for your company, and to own the technical development of data science initiatives for your company/major function (e.g., Finance, Sales, etc.)
* Expected to be most technical person in the organization, and serve as subject matter expert for both junior data scientists and senior business leadership.
* Title expected to be Principal Data Scientist or higher (though, again, not a hard rule as some companies call their most senior data scientists just Senior Data Scientists).

**What we are asking from you:**

Once a month, we will post a thread for users to propose a question for the panel. The question with the most votes will be shared with the members of the panel through a direct message. You will then have one week to provide your answer to the question - we are expecting this to be a 2-3 paragraph exercise, so not something that requires an essay. Once you have submitted your answer, I will compile all the answers and post them to a new thread, referencing each user and their respective answer. We will the open the thread for additional commentary from the sub.

&amp;#x200B;

**If you believe you meet the criteria and want to participate:**

\- Send me a PM with a brief outline of your qualifications (doesn't need to be much more than what is included in your flair, would be helpful to include years of experience)

OR

\- Post your qualifications on this thread (same as above)

I will compile the list manually and then begin the process once we have a critical mass of people to answer questions. I don't expect to get an overwhelming number of sign-ups, but if we do, we may change up the panel on a month-to-month basis to get everyone involved and not end up with too many answers to the same question.

If you have any questions, feel free to ask them!

&amp;#x200B;",1
126,Wondering how people here store all information they need for their job. For example how-to's to clean data in Pandas or important Tableau tutorials.,1
127,,1
128,"[**Knitty**](https://github.com/kiwi0fruit/knitty) is a Pandoc filter and [Atom/Hydrogen](https://atom.io/packages/hydrogen)-friendly reproducible report generation tool via Jupyter, Pandoc and Markdown (fork of the [Stitch](https://github.com/kiwi0fruit/knitty/blob/master/docs/stitch.md) that is a [Knitr](http://yihui.name/knitr/)-[RMarkdown](http://rmarkdown.rstudio.com)-like library in Python). Insert python code (or other Jupyter kernel code) *to the Markdown document* **or write in plain Python/Julia/R with block-commented Markdown** and have code's results in the Pandoc output document.

Knitty is an important part of the [Best Python/Jupyter/PyCharm experience + report generation with Pandoc filters](https://github.com/kiwi0fruit/pandoctools/blob/master/docs/best_python_jupyter_pycharm_experience.md) (see there why writing in plain Python/Julia/R is great) but actually

Knitty is language agnostic and can be used with any Jupyter kernel. Can be used independently of Pandoctools and with any IDE of choise. So I guess it deserves a separate post. By the way: Atom/Hydrogen is also language agnostic. You can also try **VS Code** interface to Jupyter from [**vscode-python**](https://github.com/Microsoft/vscode-python) instead of Atom/Hydrogen. I highly recommend to try to think about ipynb as merely an output format like pdf instead of main format or intermediate format (albeit ipynb is great for presenting narrative interactively and it can even [be much more](https://github.com/kiwi0fruit/misc/blob/master/src/pdf_and_word_killer.md)). 

[**knitty repo**](https://github.com/kiwi0fruit/knitty).


### P.S.

[Knitty vs. Knitpy](https://github.com/kiwi0fruit/knitty/issues/1) joke.",1
129,"I have been working on a model for a few months, and I've added a new feature that made it jump from 94% to 99% accuracy.

&amp;#x200B;

I thought it was overfitting, but even with 10 folds of cross validation I'm still seeing on average \~99% accuracy with each fold of results.

&amp;#x200B;

Is this even possible in your experience? Can I validate overfitting with another technique besides cross validation?",1
130,"My company started having company-wide data competition. One thing that bugs me is that the expectations are to find ways to improve existing models or gain insights from the data (that supposedly weren't known before).

I just don't know if it makes sense to say your average data personnel (like myself) sprinkled across the company can beat our in-house research team that came up with the model.

So just curious about the possible motivation. Is it a low impact project that needs to be done but they don't have resource for it? Is it that they're looking for someone to go through the hassle of ensembling 100 different models to improve accuracy by .003? Or do they really believe in shooting in the dark hoping to hit something big?",1
131,"Hi everyone, first time posting here. I know Tableau isn't exactly ""Data Science"" per se but hoping some of you may have some experience using Tableau or other BI tools to share your thoughts.

Would love to get your thoughts/expertise on the best way to structure a Tableau team within an organization. Our team recently prototyped building reports using Tableau and management absolutely loved it. However, our concern is the amount of business partners that might come to us going forward to help build dashboards for them, which would be overwhelming.

Few Questions:

1. What do you think works better? A centralized or decentralized model? 
2. As a business unit, we are by no way ""IT"" and would want not want to maintain every single dashboard we build going forward.
3. Do you guys have a Tableau ""center of excellence"" to train other users in the organization on Tableau?

Thanks for your time!",1
132,"So I have a question regarding deep learning and more ""traditional"" machine learning usages in industry. My understanding is that deep learning is ""less transparent,"" in how it works, whereas ""traditional machine learning,"" is more transparent. This leads me to believe that for business use cases, such as for marketing, would prefer ""traditional machine learning,"" because the models can easily explain how they derived their results, whereas for a ""deep learning model,"" is less helpful if we're trying to explain why a prediction is off.

&amp;#x200B;

\^ Does anybody have insights on this? Has anybody (from industry) experienced less of a desire to use deep learning, because of not being able to ""justify"" the answers generated?",1
133,"Hi all,

&amp;#x200B;

Domain expert here, converted over to doing predictive modeling. My software engineering skills are poor, at best. I want to learn how to write production grade code that is versioned etc., and simulate putting models into production. Best way to do this would obviously be on the job, but unfortunately that is not a possibility right now.

&amp;#x200B;

What MOOCs, resources, tutorials would you recommend to start?  What about setting up pipelines and putting a model into production in miniature? The goal would be to get some background knowledge and to actually use it to do some projects at home that I can have in my portfolio.

&amp;#x200B;

There is no Kaggle or Datacamp for this stuff, so any advice is really appreciated!

&amp;#x200B;

Edit: Wow everyone, thanks for the suggestions! There is more than enough here to get me started. Hope other people interested in these topics find this useful as well.

&amp;#x200B;

&amp;#x200B;",1
134,"I'm currently looking into a career change and I've got my eye on big data. I've found 2 certificates from the university of Toronto and I was wondering about the differences between the two. 

Here's the first one -

https://learn.utoronto.ca/programs-courses/certificates/data-science

Now here's the second one -

https://bootcamp.learn.utoronto.ca/data/

What I've noticed is that the first one is more statistics heavy while the second one has a much stronger focus on programming. But why? What is really the difference between data science and data analytics?",1
135,"Welcome to this week's entering &amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)  
* Traditional education (e.g. schools, degrees, electives)  
* Alternative education (e.g. online courses, bootcamps)  
* Job search questions (e.g. resumes, applying, career prospects)  
* Elementary questions (e.g. where to start, what next)  

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](https://www.reddit.com/r/datascience/wiki/resources) pages on our wiki.  

[You can also search for past weekly threads here](https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;restrict_sr=1&amp;t=month).

^(Last configured: 2019-02-17 09:32 AM EDT)
",1
136,"I've noticed that across the sub we have at least a handful of members that are a bit further in their careers - Directors of Data Science or Principal Data Scientists (or equivalent).

Would there be value in trying to identify the people that are in these roles and having a weekly feature were these people are asked a question and we post the answers? I think it would be good to get some more substantial answers to questions that are popular, and also to be able to compare and contrast answers based on role and experience.

Thoughts?",1
137,"Hi, i am what in the industry is called a data scientist. I have a master's degree in statistics and for the past 3 years i worked with 2 companies, doing modelling, data cleaning, feature engineering, reporting, presentations... A bit of everything, really.

At the end of 2018 i have left my company: i wasn't feeling well overall, as the environment there wasn't really good. Now i am searching for another position, always as a data scientist. It seems impossible to me to get employed. I pass the first interview, they give me a take-home test and then I can't seem to pass to the following stages. The tests are always a variation of:

* Work that the company tries to outsource to the people applying, so they can reuse the code for themselves.

* Kaggle-like ""competitions"", where you have been given some data to clean and model... Without a clear purpose.

* Live questions on things i have studied 3 or more years ago (like what is the domain of tanh)

* Software engineer work

Like, what happened to business understanding? How am i able to do a good work without knowledge of the company? How can i know what to expect? How can I show my thinking process on a standardized test? I mean, i won't be the best coder ever, but being able to solve a business problem with data science is not just ""code on this data and see what happens"".

Most importantly, i feel like my studies and experiences aren't worth anything. 

This may be just a rant, but i believe that this whole interview process is wrong. Data science is not just about programming and these kind of interviews just cut out who can think out of the box.",1
138,"I recently got my first job as a data scientist and wanted to share some thoughts about the job hunt process and tips I found helpful for landing a first gig in the field.

&amp;#x200B;

Some background (without giving away too much PI): I had a varied education and career path to this point. Both my BSc, MSc, and PhD were in STEM fields. I decided to make the switch to data science after seeing some friends have success in the area.

&amp;#x200B;

I had no formal experience in data science/AI, although I had much coding experience (mainly python and matlab) from my degrees. So I decided to self teach data science and then apply for jobs. There were many ups and downs in the process as a whole, and a lot of lessons I learned as I went along in the job hunt.

&amp;#x200B;

To form a solid understanding of the machine learning field, I started by going through a machine learning primer on [pythonprogramming.net](https://pythonprogramming.net). I found a nice mix of math theory (low level) and code. The course covered all of the main algorithms used in machine learning by first explaining the behind the scenes idea and then coding a algorithm from scratch and then (in some cases) using it on a dataset. Towardsdatascience also is great (for the right author) for getting a quick easy overview of something.

&amp;#x200B;

After this I applied to my first round of jobs, and found that this is probly not enough to get in the field. I got a few interviews, but response rate was about 7% of my applications (applied for about 50 jobs). I applied for all jobs online, via indeed, glassdoor, etc. While applying I started an excel file listing all applications and dates applied. This gave me a way to measure response rates and see what helped increase this.

&amp;#x200B;

So, after realizing I needed something more, I took on a new undertaking. I reworked through in depth math of the popular algorithms using Elements of Statistical Learning (textbook freely available online). Then, I found some data sets online (either off kaggle or the UCI repository) and went through an entire in depth project on these sets. Data cleaning, exploratory analysis, predictive. I mean really clean out the problem, I read publications about the dataset, established baselines, interpreted results, etc. I then made a github account and made a data science portfolio and posted a couple of projects on there. Then I reopened the application process and applied to about 50 more jobs. IF YOU TAKE AWAY ANY ADVICE TAKE THIS: make a porfolio and post a project. Choose a project that is socially relevant and any layman could see why its interesting (ie healthcare, not Gaussian data distributions). This astronomically increased my responses. I would estimate that, per 20 applications, I got interviews for 5-6 jobs. After much interviewing I finally got a good offer which I accepted.

&amp;#x200B;

Interviews follow the same basic structure everywhere, and here's what I learned going through them:

1. The HR screen. After bungling a couple of these I finally figured them out; after an HR screen now I would say I have a near 100% conversion rate to a second round interview. They don't know technical stuff, they want to get an idea of who you are and make sure you aren't a weirdo and can articulate yourself. So here's how to ace them: find a project you worked on and explain the technical concepts to them in VERY easy to understand ways. I found explaining algorithms using sports analogies very effective. Relate the project to someone who doesn't care about data science; why is the problem interesting, what are implications of your results. Besides that be prepared to answer the basics like ""why are you interested in this company"", ""how do you face challenges"", etc.
2. 2) the technical interview. The contents of this stage really varies. Most times, I would be asked to explain technical aspects of my DS projects. They would start off with ""explain a project youve worked on and how you solved it"". Why did I use this algorithm and not another, why did I do a dimensional reduction, how did I clean the data, etc. Then, I would get asked to explain the workings of a particular algo I had used. Some would ask that I explain it to someone who didn't know about computers, and some would ask I explain the math and algorithm structure. If you paid attention to my first point you'll be ready for the layman explanation. So be prepared for both. I would really prepare a nice ""lecture"" about an algo, because some would just say ""explain your favorite algorithm"".  Some will go through your resume and ask you to explain buzzwords, so be prepared for that.
3. 3) the coding challenge. These are annoying. They are generally easy, most I got were binary classification problems. A couple I got were just data sets and they said ""do something interesting"". If you've done a DS project it shouldn't be hard. The annoying part is that most would say ""this should take about 4 hours, heres 5 days to turn it in"". So what I imagine happens, is some candidates spend 4 hours and get some interesting insights and send it off, and others spend 5 days straight doing a crazy analysis of it. One company arranged a time I would like the challenge to be sent to me, and I had to submit results within 4 hours. I think this is the best format, as it really puts everyone on the same playing field. I would suggest doing a very simple practice classification problem from a common dataset (the UCI wine thing for example) and just get a ""template"" ready that isn't too difficult to change between basic datasets. Also, some jobs that blasted me a dataset without a phone call or email first I found quite rude and didn't pursue.

&amp;#x200B;

Final tips: I know many people on this sub complain about buzzword resumes; but Ill offer a different take. The people who get a giant pile of resumes to sort through are the HR people; I had a friend who is an HR rep for a DS company look over my resume. These HR people don't know DS; they have a job description for a role that has buzzwords in it (candidate should know regression, tensorflow, blah blah) and they match your resume to that. So I found that by including buzzwords  (listed algorithms I knew, math I knew)  I increased my response rate.

&amp;#x200B;

Also I added a section in my resume explaining the DS projects I had done and tools I used to do them (bold font the tools for fast reading), this also increases response rate (link to your github portfolio too). All in all, the job hunt process is a meat grinder and sucks. I sent out a total of about 100 job applications, got a couple cheapo offers that I declined, and accepted a solid one. I completed about 30 interviews. The whole process took about 3 months. The jobs I didn't get interviews for I think is because I didn't match the description exactly or didn't match the experience requirement, lots of them want big data framework experience which I didn't have (hadoop, apache etc). This would be easy to learn, but the screeners don't know this really so probly tossed my resume. I would've learned it myself but getting 4 coding challenges a week bogs you down a bit :P.

&amp;#x200B;

Remember, the increase in interview requests and inceased knowledge is not just a correlation, it's a causation. As you're applying, learn something new everyday.",1
139,"What are your thoughts? Are you going to switch, have you switched? ",1
140,"My company currently has a bunch of disparate marketing data sources coming from places like google AdWords, Facebook ads, Bing ads, commission junction, and many others. The company currently accesses each source using their respective webportals, which obviously is very limiting when it comes to analysis and multi attribution touch point modeling. 

We don't have a data engineer on deck that can build a pipeline from these sources, so I'm seeing this as an opportunity to learn how to do this myself. Google (praise thy name) has led me to some Medium articles on using fb apis to access marketing campaign data, but I haven't had much luck searching for Google AdWords (Google shopping) API tutorials for data pipelines, Bing, or others. I typically end up at websites selling prebuilt connectors, which is a bit frustrating.

Has anyone had experience doing this that can provide me with some links to useful guide, lessons, etc where I can start learning how to do this using Python? I'm looking to extract data from the apis, put it into a pandas dataframe and then write it into our SQL database...is this the right approach?",1
141,Google just released Tensorflow2.0 alpha!,1
142,"Hey guys, 

We're two friend who met in college and learned Python together, we co-created a package which can provide an estimate for the training time of scikit-learn algorithms.

Here is our idea of the use case for this tool:When you are in the process of building a machine learning model or deploying your code to production, knowledge of how long your algorithm can help you validate and test that there are no errors in your code without wasting precious time.

As far as we know there was no practical automated way of evaluating the runtime of an algo before running it. This tries to solve this problem. It especially helps in the case of heavy models when you want to keep your sklearn.fit under control.

Let’s say you wanted to train a kmeans clustering for example, given an input matrix X. Here’s how you would compute the runtime estimate:

    From sklearn.clusters import KMeans
    from scitime import Estimator 
    kmeans = KMeans() 
    estimator = Estimator(verbose=3) 
    #Run the estimation 
    estimation, lower_bound, upper_bound = estimator.time(kmeans, X)

Check it out! [https://github.com/nathan-toubiana/scitime](https://github.com/nathan-toubiana/scitime)

Any feedback is greatly appreciated.

&amp;#x200B;

edit: Code formatting",1
143,"I'm releasing Dequindre to the open source community under an MIT license. Checkout the project if you'd like, but I'm going to talk about Dequindre as an idea that became a full solution in the OP. Here are the links if you're interested:

[PyPI Project](https://pypi.org/project/dequindre/0.10.0) | [GitHub Repo](https://github.com/vogt4nick/dequindre/tree/0.10.0) | [Read The Docs](https://dequindre.readthedocs.io/en/0.10.0/)

---

### Why build ""a minimalist scheduler""?

A few months ago [I asked what the sub thought about current data pipeline technologies](https://www.reddit.com/r/datascience/comments/9uz05o/whats_your_opinion_on_current_data_pipeline/). The consensus was that Airflow was the best option, but every popular option requires significant resources to learn and implement.

I'm a data scientist working on a young product. I made that post at a time when we were unsure how to automate our data pipeline. Airflow is free, sure, but things weren't breaking yet and the time investment made Airflow an expensive option for us. We decided to point CRON jobs to shell scripts instead. It was fast, cheap, and easy to debug in the rare event of failure. It wasn't a permanent solution; it was a good-enough-for-now solution.

I revisited the problem a couple months later, and I realized there must be hundreds of teams like mine in this limbo: still unable to justify the cost of Airflow and growing too fast to rely on CRON and shell scripts. Clearly there's a need, yet there was no such scheduler that I could find. 

I started engineering my own solution. I didn't need all of Airflow's features. I thought, ""What can I take away from Airflow to make scheduling more accessible?"" I took away the UI. I took away the sqlite database. I took away asynchronous scheduling, bash operator, and triggers. I kept the scheduling, dynamic configuration, python operators. I even added some functionality to support virtualenv, pipenv, and conda environments. 

What remained was Dequindre: a minimalist scheduler I could setup in minutes. It's production-capable too. We're migrating to use Dequindre on my team at work. 

### What's Next?  

Dequindre v0.10 marks the start of ""public beta testing,"" which means I'll be answering public bugs, questions, and feature requests. I'll release Dequindre v1.0 when I'm confident the core functionality is tight. Right now I guess that might be April or June. There might be a v2.0 and beyond, but Dequindre is minimalist by design; there's only so many features I'll consider adding before recommending something more full-featured like Airflow. ",1
144,"When you are dealing with large data, how can we make sure, our system is still process it. I am dealing with 1555394 rows, 14 col data frame. My algo work fine on small chunk. But how can i make sure it is working on , because my system showing processing for about half an hour. And is there any way we can get intermediate result.. generally speaking . How can i know, if my system is not gone out of memory?",1
145,"If so, a couple questions:

* how'd you do it? 
* did your total comp go down when you did? 
* was it worth it?",1
146,"Background: 

I'm a few weeks into a new role at a startup as Data Analyst.  My team onboarding experience has basically consisted of ""ask the other data staff members anything, but don't expect anything proactive from them.  Documentation? What's that?""  I'm a career changer from a non-technical field in my early 30s.  The company is your classic tech startup - most employees 26 years old, move fast and break things culture, perpetual state of ""Series B funding deal should close any week now"".  Learning the company data structures has been basically consisted of pulling the teeth of my teammates, piecemeal.  It's been a difficult experience, to say the least. I want to be proactive at making things better for the next person, as well as teaching myself the ropes.

&amp;#x200B;

My questions:

\- What are your favourite strategies for introducing new employees to company-specific data knowledge?

\- Any tips for starting from scratch creating documentation for vast existing data structures with new tables emerging every week? Enforcing the docs' maintenance?

\- Success strategies for adaptable, willing newbies for what questions to ask to make everyone's life easier?  This includes stakeholders such as those who consume reports, managers, rest of data science team, and of course me.

&amp;#x200B;

I'm flailing right now - any guidance appreciated!",1
147,"Background:
I work as a lead project manager for a very large company. I am good at my job (or at least my yearly performance reviews say that) but I honestly don't like my job. I am regularly given failing projects and tasked with replanning the project. The stress is wearing me out. I want to work in data science - I'll have my MSc in data analytics within the year and I'm working on creating a portfolio and getting my first data science job. I incorporate data science techniques into what I do and I credit that with what makes me successful.


Situation: 
My company is very antiquated and slow to adopt new technologies. At the end of last year they announced they were going to start embedding data analysts within teams and hire some data scientists. I thought great, here's my chance to get into the field. 


I cannot get an interview to be a data analyst because, according to the hiring manager, I don't have experience. It's frustrating because I regularly demonstrate the application of the needed skills and knowledge, but okay fine.


Fast forward a few weeks a newly hired data analyst is imbeded with my team. I try to make the best of it and think, hey, I can talk data science with this guy.


The person hired doesn't have a background in data science. He doesn't know statistics or any programming languages. He had to ask me for help writing a simple SQL query so he could put the data into Excel and make a pivot chart. The hiring managers are business people who don't know anything about data science. The data analysts are being used as Excel jockies.


I don't fault the people hired as data analysts but it frustrates me that the managers have no idea what they are doing in regards to hiring and utilizing data analysts. I feel like within my company they are devaluing data science by having people not in the field doing the hiring and management of the analysts. It's looking more and more like I'll have to leave the company to work in my desired field. That will be difficult because I'll likely have to take a pay cut to get a job elsewhere.


This rant sounds a bit gatekeeper-ish and makes me sound conceited, but I'm just frustrated with the managers trying their best to use as many data science buzzwords as possible while not actually doing anything data science related.",1
148,"Hey folks,

I’m a sole Data Analyst at a small to medium company in the Upper Cumberland region of Tennessee. 

I’d love to join any groups / meetups / online geo-specific message boards etc.

If anyone knows of groups within this area, Nashville, Chattanooga, Knoxville, that would be awesome!

Thanks ahead of time. 

",1
149,I'm a data scientist for a Fortune 500 company in Bay area for almost a year and a half. I still get like 5-6 messages at least from LinkedIn every week about possible opportunities mostly at companies like startups. I don't want to waste their time since I'd not consider joining startups at this point of my career (also due to visa issues) but I feel like my interview skills will get rusty over time if I don't keep practicing them. Is it a bad idea to take their calls and take the interview even if I probably stay where I am anyways?,1
150,"Suppose you discovered a strong link between sunny days and apple's share price over the last 6 years, is it reasonable to act on that correlation going forward based on the longevity of the correlation or would you still want a logical reason to explain the correlation? Are there any systematic ways to eliminiate spurious correlations? If it cannot be explained, is there a minimum amount of time passed that can be used as confirmation? ie, if the same correlation has existed for 10 years or 20 years. ",1
151,"To be more specific, I am talking about the situation where you have deployed a binary classifier (could be multiclass) into production where you are taking actions on people based on the predicted outcome score from the classifier. One thing I have been thinking about is what kind of metrics to use to validate the confidence of the actual score outputted by the model. e.g. If a model outputs a score ('probability') of 0.74, what is the expected chance that the predicted event will actually occur?

&amp;#x200B;

The initial assumption might be that there is a 74% chance but that seems to be confusing the model's score with a confident probability which doesn't seem right. I've also looked into MC DropOut as a method of estimating confidence, but I'm curious about situations where Neural Networks aren't in play. My initial guess on how to approach this would be to deploy the classifier for a while and collect data on it's predictions and the actual future outcomes. Then, taking all of the predicted scores (that we take no action on), I would bin them up so that there's a bin for all the predicted scores in \[0.7, 0.75\] and a bin for predicted scores of \[.85, .9\], and so on. Then, I would calculate the average proportion of people that had the event occur, and would expect roughly 72.5% of the people to have the event occur in the first bin, etc.

&amp;#x200B;

But, I'm wondering if there is any way to quantify this better? I'm guessing research has probably been done on this and I just haven't come across it. Any ideas on good lines of research to look into, or maybe examples where this is already being done?

&amp;#x200B;

TL;DR: I've heard of Bayesian deep learning methods like MC Dropout that let you estimate how confident the model is in it's prediction. However, are there any techniques that generalize to more types of models that will let you estimate how confident you can be in your models predicted scores?",1
152,"Hey guys! My first post here and I hope you can understand my English!

**tl:dr:** Offered position as IT Audit, what is the relationship of that position with DS and would it be beneficial to take such position if my ultimate goal is to be a DS? (I still need to work more on myself to be able to apply for DS jobs). I guess the company just messed up positions and they just need people.

&amp;#x200B;

I applied for a job described as Data Scientist / Data Analyst in a big company somewhere in Europe. This big company has a new department in data analytics and they are hiring  new people as thing have been going well and they are understaffed.

 I go to the interview, I do a project, bla bla, you know the process. Now the thing is, before the last interview they told me my profile wouldn't fit one of Data Scientist, as I don't have the coding experience they are looking for.

Anyway, I understood that if I wasn't not becoming a DS I would be a DA ( From my research these are two different things, right?) . Now the thing is, the offer came something like an IT Audit position.

My background is in Finance and I have a  Master in Micro Data analysis.

What does my background has to do with IT Audit, and how is IT Audit related with data analysis and so forth?

My ultimate goal would be to be a Data Scientist, and I would like to know how (and if) being a IT Audit brings me closer to this goal.

My feeling is that they confused DS/DA and they just sold me the IT Audit because they need people.

Anyway, I am kinda confused right now about the whole thing.  
Wondering if someone could share their thoughs.",1
153,"I have been an analyst for several years, and recently moved into data science. Some of my roles have not always been terribly technical, because the employer was unwilling to provide tools. I have made do and practiced data science at home on my own time to improve or gain skills. 

I left my last job for what I thought was a long term data scientist role (government clearance!). It took 3 weeks to gain access to the data and once I finally did, it was incredibly messy and unstructured. I was told there will be significant and ample time for ramp up. I literally began building an NLP model yesterday and was looking to deploy it soon. 

I got the call from the staffing agency to not return to the facility due to lack of performance. They felt I made zero progress even though I was fleshing out issues and creating data science documentation for the team. Even when I asked, there were no clear details of what the organization was looking for. I had a path forward and expressed what I was working on to add value. If they wanted/needed something else, no one said a word. 

At 6 weeks, fired. Back to the drawing board again. I was told TODAY when I was being terminated they needed someone to lead the team and hit the ground running asap. When I interviewed with this company, none of these expectations were expressed otherwise I would have not taken the role. ",1
154,"I hope this is the right place to post my question. Quick facts: 

- We’re making an offer to our first data scientist tomorrow. 
- I’ve never worked with a data scientist before. 
- She’s a senior data scientist, if that means anything.
- Our product is an internal web app to help salespeople track down leads and make bigger deals. 
- We’re bringing her on to research ways to increase sales. 
- We run agile. 

I’ve never worked with a data scientist before. How do I define goals with her? How much should I be involved should I be in her workflow? How much slack do I give her to do research with no definite return?",1
155,"In my current job my title is Data Scientist but really I do a lot of dev work building prototypes for different ML/Statistics-based features. For me it feels so incredibly rewarding to see your prototype baby grow into a full fledged feature. 

However, in the last year several seniors left the team due to disagreements with management and I decided to start interviewing as well.

This is when I truly realized how data science really wasn't for me. I came into contact with several DS teams from different companies who develop purely in notebooks, spend all day writing SQL queries or spend more time in excel in a day than I have my whole life.

Nobody I met asked me a single programming question or even a question about system design. It really bummed me out until I started applying for SEng jobs with focus on ML/AI and realized this was my real title all along. 

Anyone else who struggled to find their true role in this sea of data science inflation?",1
156,"I have a Bachelor's Degree in Mathematics, and was accepted into a sixth month mentorship program under a data scientist with 7 years experience. Let's say I get 3 years experience as a Data analyst / Associate Data Scientist after my mentorship, then consider becoming a commissioned officer in the US military for 4 years to get the GI bill to help pay for Graduate School.

From your past United States Military experience, do you know if any Data Analyst or Data Scientist positions were available in the Military for officer personel that would count as authentic job experience on your resume?

Did you try to study Data Science while in the military? How hard was it, and how well did you improve your Data Science skills while completing your Military Service Obligation?

Did your service help you get experience and projects completed for certifications like 6-Sigma Black Belt?",1
157,"I am currently the manager of BI within a data team. One of my primary responsibilities is to help DS projects make it to production. Typically ""productionalize"" a project means make sure it continues to bear fruit in some kind of updated report. Typically a dashboard etc. I have completed the SCRUM master program and have been applying it within the team with the blessing of the chief data officer. He is asking me if I want to move into a BI architect role where I don't do development any longer and instead just help design it all and be the scrum master for the team (15 growing to 20). What are your thoughts on a data science SCRUM master? I have not seen anywhere where this role exist in a DS team. ",1
158,,1
159,"I’m a junior in my school’s data science program and have been having problems with some of my assignments, my laptop has 8gb of RAM and recently, with my bigger assignments and projects, my laptop can’t really handle it.  I am planning on getting a new laptop soon and was just wondering if it’s worth it to splurge for 32gb or if 16 will be enough for a career in Data science career. ",1
160,Anyone here create a DS team from scratch and have any advice to give? I took one of those jobs that most websites tell you to avoid; where you are hire number one for a DS team and where the company doesn't really have an understanding of DS. I am optimistic about the future and seem to get buyin for what I want but am hoping to learn from successes and pitfalls of others. ,1
161,"I recently had an interview for an entry level data scientist position. At one point the interviewer scoffed at using sklearn or other similar packages because: 1. he didn't ""trust it"" and 2. his data ""wasn't the kind you could just plug into a [model.fit](https://model.fit)()"" but was more ""nuanced and complex"".  For those reasons he instead builds all of his machine learning models from scratch. In my opinion it stuck me as a bit arrogant to think that an open source software is to be trusted less than something one or two people have fully reviewed.  But I'm also not sure of how many situations there are in which there is no available library or prepackaged model, or it is more advantageous to DIY.

Few questions here:

1. Does anyone else here find standard machine learning libraries such as sklearn untrustable? If so why? Are these models not to be used in production for some reason I'm not aware of?
2. How often does a data scientist really need to build these models themselves? Or put another way how big a project does it need to be before meriting a self-built approach? e.g. I can imagine prebuilt models being the go to for quick analyses but when company's core product is centered around a machine learning algorithm it may make sense to build it from scratch. I'm wondering what it looks like between those two extremes.
3. In what scenarios is it preferred to build a model from scratch? I can understand the situation where a library or language isn't available in a production environment, or the model needs to be written in a different programming language. I'm more interested in cases where this is a decision from the model builder and not imposed by infrastructure requirements.

Also throwaway account because interview specifics. and edited for clarity.

&amp;#x200B;",1
162,"I've been speaking to a PhD recruiter about data science positions at Google, and I wanted to see if anyone on here works/worked (or know about) as a data scientist at Google and can give some insight. What does your day to day life look like? How much coding do you do? Do you code in high performance languages (e.g., C++) or mostly in interpreted languages (e.g., Python)? How much does your position involve ML?

&amp;#x200B;

Ideally, I want to be in a position where I can focus on machine learning and software engineering, and from speaking with the recruiter, it seems the data science positions at Google is very applied stats heavy. She sent me a study guide for the phone screening, and it's very stats heavy, a lot of stuff, which I have learned from previous stats courses many years ago that I have forgotten. So I'd probably need to put in a lot of time to study stuff related to that just for a phone screen..

&amp;#x200B;

I'm trying to decide if this is something I'm interested in pursuing and/or if it fits my background. She made me aware that for PhD applicants at Google, you can only do a single-track interview process, meaning that I wouldn't be able to simultaneously be in the interview process for a data science, software engineering, ML position. She said she could put me in touch with the recruiter for the PhD ML software engineering positions, so I'm curious to find some information about the positions labeled as ""ML software engineer"" before deciding which track to pursue. The title ""ML software engineering"" sounds much more aligned with my background and interest but I was always under the impression that ML and DS positions have a lot of overlap and are pretty much the same positions?

&amp;#x200B;

&amp;#x200B;",1
163,"When you start a new project at work that is public facing in some way, does your project manager ever bring up ethical issues or outcomes?

We have regular racial awareness trainings and other equality workshops and I really appreciate that we do discuss these things even if we cannot always solve it. But at the same time, we don’t discuss how our products could have unwanted impacts. It’s the we do as we told situation. 

While the title of the article is a little dramatic it was an interesting read.

https://medium.com/s/story/data-violence-and-how-bad-engineering-choices-can-damage-society-39e44150e1d4",1
164,"I'm a big fan of python pandas. 
When dealing with bigger datasets I had to resort on Spark, which is cool but I don't really enjoy as much as pandas.

I'm searching for something in the middle, and found Modin and Dask. They are both subset of pandas but way more scalable.

What's your experience on this tools? Which do you prefer and why?

https://modin.readthedocs.io/en/latest/
https://dask.org/

Thank you! ",1
165,,1
166,"Wanted to get this community's thoughts around this latest news article (also included a response):

[https://www.bbc.com/news/science-environment-47267081](https://www.bbc.com/news/science-environment-47267081)

&amp;#x200B;

Quote from the article (please read the full article as it's short):

&gt;“Often these studies are not found out to be inaccurate until there's another real big dataset that someone applies these techniques to and says ‘oh my goodness, the results of these two studies don't overlap‘,"" she said.  
&gt;  
&gt;“There is general recognition of a reproducibility crisis in science right now. I would venture to argue that a huge part of that does come from the use of machine learning techniques in science.”

&amp;#x200B;

I also found this respectful response from Favio Vasquez -

[https://towardsdatascience.com/a-quick-response-to-genevera-allen-about-machine-learning-causing-science-crisis-8465bbf9da82](https://towardsdatascience.com/a-quick-response-to-genevera-allen-about-machine-learning-causing-science-crisis-8465bbf9da82)",1
167,"Hi all,
I’ve lurked here for a while since I’ve been working part-time on a Masters in Predictive Analytics at Northwestern. I recently accepted an offer as a Data Scientist at a consulting firm, so I’ll be jumping from a business analyst job into this vast world of data science. 

My question is whether anyone here has found ways to shortcut the learning curve being new-ish to the field? Are there practical things I can do or habits to acquire so that when I start I’ll be set up for success?

As an aside I’m documenting my job search process so I can help those just behind me in the process of becoming a DS. Will post on that thread once I’ve finished. ",1
168,Everyone at my office uses Excel. I want to use what I'm learning in DS at work so I can practice and implement it. The problem is that everyone at work uses Excel and no one uses SQL/Python in their usual workflow. How can I make this adjustment work?,1
169,"[https://www.coursera.org/specializations/deep-learning](https://www.coursera.org/specializations/deep-learning)

&amp;#x200B;

I would really like to know if anyone found this specialization valuable and worthwhile?  I have taken some courses on Coursera that were not always great, just wanting to get feedback before making this investment of my time. ",1
170,,1
171,"I've been a professional 'data scientist' for nearing on 4 years now, and as I'm sure many others have noticed, the term can mean wildly different things depending on where you are employed. After being in industry for a while I've observed there tends to be about 4 main different flavours of 'data scientist':

**Data Analyst**

5 or 10 years ago, these people would've just been called BI analysts or data analysts- just doing basic data viz, reporting, dashboards and SQL querying. Then companies started to try and sex up these positions by giving them a new buzzword title 'data scientist'. There may be a few of these people who do some basic ML and stats but in my experience this is uncommon. Usually good with tools like Tableau etc

**Statistician**

Again, 5 or 10 years ago, these people would've just been called statisticians or mathematicians. They focus mainly on inferential modelling or if they do predictive it's using traditional statistical techniques like linear regression. These guys are highly skilled in stats theory and some in ML as well, but they tend not to have great CS/software engineering skills, and usually their work consists of ad hoc analyses that they aren't responsible for delivering to production. Typically program in R, or in more old school organizations maybe something like SPSS.

**Machine Learning Engineer**

This is where the major growth area in 'data science' has been in the past 5-10 years IMO. These people typically have good CS/Software Engineering skills and are involved in deploying models to production. They tend to focus mainly on predictive models and most will be in strong in more 'modern' ML techniques, but some (not all) may be weaker in 'traditional stats' models. Work mainly in Python but may drop down to lower level languages when required.

**Data Engineer**

These people range from plain old DBAs rebranded to Big Data Engineers who work with Spark/Hadoop/Cassandra etc and work in Scala or Python or maybe even Java. The Big Data Engineers might also be proficient in the ML libraries specific to their particular big data architecture.
 
---

To me, all of this begs the question, should we just ditch the terms 'data science' and 'data scientist'? In my opinion, they are vague, generic buzzwords that do nothing but confuse people. Be interested to hear other people's thoughts though.

It'd also be great to have a little bit of discussion about my classification system, do people think I've missed some categories, got some things wrong? Which types of 'data scientist' do you think are most in demand, attract the best salaries? What proportions of the 'data science' industry are employed in each area? What qualifications do you need for each subtype?",1
172,"As a data scientist, it’s important that you lead data evangelism efforts at your company.

The effort you put into these initiatives can lead to increased trust and credibility for you and your team. Without these two things, no matter how great your technical abilities are, your ability to impact your company will be limited.

In this article, I explore six initiatives that can help you achieve this goal. Let me know your thoughts/if you have other data evangelism efforts worth looking into!

https://towardsdatascience.com/why-data-scientists-need-to-lead-data-evangelism-efforts-f433f7fac936",1
173,"Hi friends,

I'm currently looking for a budding data science teammate to build out and expand on the analytics for an app I'm working on. What's a good place to look for budding data scientists looking to grow the resume/portfolio?

**Background**:

Last year, I spent several months studying data science in hopes of working in behavioral health analytics. I loved it, but grew tired of analyzing random datasets for my portfolio; I really wanted to analyze my own data, but wanted to automate the process as much as possible. I switched over to web &amp; mobile dev and began work on the app in React Native. After several months, I finally launched the app in December. I was proud of the product, but also recognize that it needs some love, especially on the analytics side. Soon after launch, I landed a mobile dev gig at a startup and haven't had time to sit down and do everything solo like I used to. It has a (very) modest user base and I want to continue development on the side. It's obviously just volunteer work - the app is currently free - but I'd be happy to chat about options if it goes somewhere!

Anyway, many thanks. If this isn't the sub to look, my apologies. If you do know where I might find interested souls, please let me know!",1
174,,1
175,"Sure is an exciting time to be in data science! Particularly so with the magic of machine learning (ML). Why it’s so exciting that it’s attracting millions of highly intelligent and deeply trained future professionals. Hence, I think we should reflect on the future of data science. Here are my predictions…

Blog post: [What does a Principal Data Scientist look like in 2025?](https://medium.com/@matthagy/what-does-a-principal-data-scientist-look-like-in-2025-545a571ec89f)

&amp;#x200B;

Let me know what you think. Personally, I may be focusing more on my software engineering skills going forward.

&amp;#x200B;",1
176,,1
177,"Does anyone have any experience organizing large data analysis projects? It seems that the majority of project organization tools for data science (DVC, datmo, mlflow, etc) assume a very model-centric approach.

On the other hand, I am currently dealing with a project that doesn't need any predictive models, but contains lots and lots of data to be explored, analyzed, summarized, and re-organized (rich geographic datasets can be quite multidimensional and messy). As the result the project directory looks approximately like this:

    ./DS-project
    |
    |__ data/
    |
    |__notebooks/
    |    |
    |    |__thing_to_analyze_1/
    |    |    |
    |    |    |__01_aa_analysis1.ipynb
    |    |    |__01.1_aa_analysis1.ipynb
    |    |    |__02_aa_analysis2.ipynb
    |    |    ...
    |    |
    |    |__thing_to_analyze_2/
    |    ...
    |
    |__src/
    |    |
    |    |__utility_package_1/
    |    |    |
    |    |    |__README.rst
    |    |    |__setup.py
    |    |    ...
    |    |
    |    |__utility_package_2/
    |    ...
    |
    |__README.md
    |__environement.yml

Currently the biggest pain is caused by the notebooks. We are following notebook naming convention suggested [here](http://drivendata.github.io/cookiecutter-data-science/), but due to the sheer number of `thing_to_analyze_x` folders and the number of notebooks in them, it can be quite hard to find previous research (even when notebook summaries are documented in some sort of README file).

Does anyone have experience dealing with such projects? Date based project/notebook naming seems quite interesting (e.g.: `2019-03-05_thing-to-analyze-1`), but I'm afraid it might make it harder to understand which stuff is old and which stuff has been recently revisited.

",1
178,I am about to complete my B.COMM in Finance &amp; Analytics and would like to go the analytics route and work towards becoming a data scientist. Will Datacamp be useful for me in pursuing that career path? I have knowledge in C and Python already to work with. ,1
179,"Not sure if this is the right subreddit for this but I’m running out of ideas.

I’m trying to do a report on some lesser-known data services. Does anyone know of a ‘data service’ that would fit a company who’s service portfolio includes Data Enrichment and Data Cleansing services atm?",1
180,"There is a interesting question in the Python community about standartizing API that exports and accepts fast functions so that computation utilizing multiple packages can happen outside of the Python interpreter. Unfortunately it's not that popular question. Sometimes it turns into [Cython/Numba/C/C++ battles](https://github.com/pydata/sparse/issues/126).

There is a discussion of this issue: [Why Julia? Will Python/Numba and Python/Cython lose to Julia?](https://github.com/numba/numba/issues/3814). And I cannot foresee any solution to this disarray except maybe [interop at the C level](https://numba.pydata.org/numba-doc/dev/user/cfunc.html#example). If there would be a PEP specification for such API then it would be even better. But I guess the solution to this should be as pythonic as possible (mentioned Numba tools to create C functions in a pythonic way are really good).

But I'm not sure how scalable is interop at the C level approach (it's merely my lack of knowledge). Can there be compositions of compositions?

## Python to Julia transpiler

In contrast to Python Julia language doesn't suffer from lack of unified API and it constantly enriches packages ecosystem that can be easily combined. Now it even has a stable release. This actually brings another possibility to fix the problem mentioned.

It would be nice to have Transpiler from subset of Python with special module named like ""Juthon"" to feature-complete subset of Julia (sometimes there are more than one way to do something in Julia).

And a idea looks like it should both be:

1. Standalone transpiler so that the user can write ""Juthon"" package and contribute it to the Julia ecosystem by transpiling.
2. Runtime decorator style transpiler (with interface like Numba has) that calls Julia (or compiled python library in the future) from Python. So that a small piece of code can be added right in the Python app written in Python.

I wonder if 2. possible though... If not then something like [enaml import](https://github.com/nucleic/enaml) can be tried that wraps transpiling and wrapping of Julia call. This can even be preferable approach.

A good example of a transipiler from Python is [Transcrypt](https://github.com/QQuick/Transcrypt/issues/619) that is a valid Python prior transpiling. But to achieve 1. this should be more like Julia in Python syntax than attempt to implement Python's standard library.

I guess it should be done via IDE friendly mapping and juthon module with source to source mapping for Julia autocompletion and lynting passthrough as it seems that automatic creating of typed and documented python stubs would require more work than source mapping; for example Julia to python transpiling for other modules inspection. That would mean lack of type inspection inside IDE - errors should be displayed by jit transpiler and later julia compiler.

[GitHub issue for this](https://github.com/kiwi0fruit/misc/issues/6).",1
181,"I ask this question because whenever I job searched, employers didn't really seem to care too much that I had background in the same industry as their company.

I've also met a lot of data scientists who ""industry-hopped"" from all kind of fields from pharma to finance to tech to online retail, etc. It seems to me that either companies don't really care that much about domain knowledge, or that domain knowledge is typically very easy to learn on the job. Would this be fair to say? 

If not, then when is domain knowledge helpful, and how can companies benefit from having data scientists that are very knowledgeable about the ins and outs of their domain?",1
182,"Hi guys,  


For a research project I need to make a data set out of film/movie clips. Obviously those clips are copyrighted. I am wondering could, splitting such clips into the individual frames that are then labeled be classed as fair use? It is purely for educational/research purposes and isn't going to be used to make money.  
",1
183,,1
184,"... What are your favorite tools for extracting/exploring DBs that don't require you to write SQL?

DISCLAIMER: I know SQL really well, so please no posts here about how everyone needs to learn SQL. I just get sad whenever I have to write a SQL query because the syntax is so redundant and painful.

My current go-to is to use dbplyr and DBI, although it does require some hacks/workarounds to do basic things with MS SQL Server, or else just to hook Tableau up to my DB and go to town.",1
185,"Welcome to this week's entering &amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)  
* Traditional education (e.g. schools, degrees, electives)  
* Alternative education (e.g. online courses, bootcamps)  
* Job search questions (e.g. resumes, applying, career prospects)  
* Elementary questions (e.g. where to start, what next)  

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](https://www.reddit.com/r/datascience/wiki/resources) pages on our wiki.  

[You can also search for past weekly threads here](https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;restrict_sr=1&amp;t=month).

^(Last configured: 2019-02-17 09:32 AM EDT)
",1
186,"Hi people! 

&amp;#x200B;

I am a data scientist fond of R programming and visualization.

I mainly use R, python, sql.

What are your essential tools and softwares you use for your daily work? 

&amp;#x200B;

My basic set up:

* Rstudio (must have)
* Sublime text 
* Atom
* Jupyter lab (as an alternative for jupyter notebook basic) 
* Notion (for documentation) 
* Pg admin (for sql queries... and I am looking for an alternative!)
* Orange (for quick visualizations and modeling) 
* Looker (as a tool for dashboard and analytics) 
* Heap Analytics (for even tracking on website = in my case - ecommerce)

Curious to get some new inspiration to make my workdlow smoother! 

&amp;#x200B;

Chhers :) ",1
187,"I work 50-55 hour weeks on average, but I’ve worked 60-70 occasionally. I wish I could work 35-40.

What’s typical in data science? How much do you work? Does this differ between industries, specialties (data engineer, analyst, scientist, manager role)?",1
188,"I'm Data Scientist for 4 months now and in our DS/DE team I am the only one left with a Windows notebook. Everyone else is using a Mac or a Linux system. I'm thinking about switching to one them because whenever I my colleagues try to teach me something no one knows how to do it on a Windows machine. With a Mac or Linux machine this would not occur.

So which OS are you using and where are the pros and cons especially when it comes to working in a DS team?

Thanks!",1
189,"I listed some questions I have. Take what you like and leave what you don’t:

- What questions did you choose to ask? Why? Did you change your mind about anything? 

- If there was a project, how much weight did it have in your decision to hire or reject the candidate?

- Did you learn about any non-obvious red flags? 

- Have you ever made a bad hire? Why were they a bad hire? What would you do to avoid it in hindsight? 

- Did you make a good hire? What made them a good hire? What stood out about the candidate in hindsight? 

I’d appreciate any other noteworthy experience too. ",1
190,"According to the [Bureau of Labor Statistics](https://www.bls.gov/ooh/mobile/fastest-growing.htm),  Statistician, Software Developer, and Mathematician are ranked #7, #9, and #10, respectively, on the list of fastest growing careers. Everything ranked higher than these careers are either in the field of renewable energy (solar panel installer) or healthcare (home health aid, physicians assistant).

So my question is why do so many people complain about the job market in Data Science when it's pretty much a mix of these 3 fast growing fields?

Is it because the industry has a higher barrier of entry than others and people are trying to get a DS job with just a BS? Would having an MS in Stats or CS (or both) make getting a job much easier? Or is this not the case? ",1
191,"I'm already knowledgeable on Python (pandas, numpy, etc) and SQL but I am interested in learning to map and visualize geospatial data. I know this is possible with Python using libraries such as geopandas, osmnx, and folium but I'm wondering whether Python is industry standard for working with geospatial data. I know ArcMap/ArcGIS exist so maybe those are so dominant it isn't worth spending the time to learn how to work with geo data in Python.

Any thoughts are much appreciated.",1
192,"Hi, we've recently had a new starter in our team. I get to work directly with her on projects. I'm pretty excited to be working with someone else, though I'm used to largely working solo.

Any practcal tips for working together, I'm thinking mainly from a coding perspective but open to whatever. I don't have a CS background, we're both pretty new to DS so I'm learning this stuff as I go.

To give an example, I have one file which runs all my functions, so they can run it and not have to remember which function gets called first (they came mid way thru a project I've been working on so I did the bulk of the work). The inputs/variables I've stored in a csv file I list in .gitignore because then they can play around with my code/ input variables without version control detecting a change.

Thanks.",1
193,"Trying to become a better all around data scientist/machine learning engineer candidate. I have never deployed a machine learning model outside of calling sci-kit learn in a flask app. I came across a blog post that shows a more realistic way to deploy models: [https://towardsdatascience.com/how-to-deploy-machine-learning-models-with-tensorflow-part-1-make-your-model-ready-for-serving-776a14ec3198](https://towardsdatascience.com/how-to-deploy-machine-learning-models-with-tensorflow-part-1-make-your-model-ready-for-serving-776a14ec3198).   


Can the sub recommend any books or video series to learn more about doing this? ",1
194,"I am looking to make interactive dashboards from data in a SQL database on a Linux machine. I have bit experience with data visualization packages in Python (plotly,matplotlib, seaboarn) but i feel these  aren't as  intutive and quick to build full dashboards as tableau and spotfire, but these programs (desktop verisons) seem to be only on Windows. 

Is there any good tools like these out there for Linux or has anyone gotten good results from using wine with some Windows data visualization tools?


Really looking for a tool for data visualization on Linux that I can quickly design a dashboard or a chart data quickly through a GUI as well as expansion to add functionality with Python through interactions on the dashboard (like in spotfire), finally as well would like to eventually be able to host the dashboard as a website while still including the Python functionality

Also has anyone used Google's online dashboard tool? Seems Interesting but haven't properly checked it out yet",1
195,"Recently I read an article: [Why Numba and Cython are not substitutes for Julia](http://www.stochasticlifestyle.com/why-numba-and-cython-are-not-substitutes-for-julia/). As I understood the main benefit from Julia is packages and math algorithms ecosystem that can be combined and reused. But they are put together during JIT compilation when in Python packages are put together during interpretation. So there is less bottlenecks and it's actually much more convenient to combine math algorithm this way.

The convenience matters a lot.

So I'm curious if I understood the main idea right and is there a really big deal about combining this way instead of another? If so then why there is no Numba specific packages ecosystem in development that can also be combined JIT compilation way? Or there is actually such Numba packages ecosystem being built and I'm simply not aware of it?

[Further discussion](https://github.com/numba/numba/issues/3814).
",1
196,"I want to start a data science business for (legally) collecting, analyzing and selling data from apps and wherever I can scrape but I'm either scared to ask about it or don't know how to do so without raising a flag on NSA, CIA, or whatever. ",1
197,"I work at a small startup with a fair amount of VC backing which has its ups and downs. I knew the deal going in since I've worked exclusively in startups for the last 10 years as a developer or data scientist. We all wear different hats, take on different roles, and no one person is assigned just one job. All of that is fine with me when it's within my realm of knowledge.

&amp;#x200B;

Lately, I've been asked to do shittier and shittier tasks. I've written so many powerpoints/slidedecks for our presentations and sales meetings that it's making me want to leave. I don't enjoy writing sales decks, I'm not good at it, and when I do them there's typically a lot of revision. The founders see this as ""professional development"" and enhancing my ""professional communication"". When I pressed them on my professional communication being lackluster they said no, that it was great for communicating with our clients and within the office. I asked them why they felt I needed further development, and their response was that I should know how to sell our product and services so that I could give presentations to clients. I told them I have no interest in learning how to be a salesman, attending sales meetings, or being involved with the sales side of the business.

  
They're still having me do these tasks because I have the greatest knowledge of what we do and the vast majority of the services/products are my work. Has anyone else been in a similar position and how did you get yourself out of it other than quitting? I'd rather not quit, I love the actual work we do, but this continued push for me to be more tied in with the front of the business is wearing me down.",1
198,"I'm a data scientist at a medium sized fintech company in Chicago, and I'm trying to convince my skeptical boss to start an internship program. He reluctantly agreed as long as I was mainly responsible for the day-to-day running of the program. 

I was actually never an intern myself in college, so I have no idea where to begin. I'm thinking a part time semester long internship may be best to begin with so I have a little time solo to work on my own job and have some time to figure out tasks to give the intern. 

If you've been a DS intern in the past, how did it go? Did you end up accepting a FT offer from the company afterward? Were you ever bored or didn't feel like you had enough to do, or did you feel overwhelmed? How were tasks delegated? I also want to include a career mentorship component, so if you had any experience with that, I'd love to hear about it.

If you've run a DS internship before, how did you balance your own work and mentoring the intern? Did you give them a single project to work on or just random tasks from other projects? Did you offer them a FT job afterwards? ",1
199,"I am a soon to be graduate in economics with a minor in data analytics and working on writing a program that simply pulls data and does some basic analysis. 


Unfortunately the BLS and most other primary sources don't allow scraping on their websites. I'm looking for inflation, unemployment, larger index fund (DOW, S&amp;P, etc), and maybe housing price data. Ideally from a couple reputable sources that I can crawl with some regularity. Does anyone have any good leads or ideas?

Apologies if this question is a bit 'below' this sub, Im really not sure of a better sub to ask lol.",1
200,"So I've been looking into [shorthand writing](https://en.m.wikipedia.org/wiki/Shorthand) systems which are what reporters and stenographers use to transcribe conversations. It's basically creating a reduced writing system and including use of symbols to write faster, and it will generally require some expertise to ""decode"". Experts in shorthand can apparently write over 200 words per minute.  
  

Naturally from here I started thinking about what the digital equivalent to shorthand would be and I've thought of some random ideas that may have a place in a similar system:  
   
  

- Text expansion, if you went crazy with this then there would likely be a huge learning curve.  
- Using a typed shorthand system like [keyscript](http://keyscript.wikifoundry-mobile.com/m/page/Alpha+Shorthand+Systems), then decode it with some ML system, although I'd imagine that this would have a lot of challenges.   
- Predictive text
",1
201,,1
202,,1
203,"So, I didn't get any comments on this elsewhere and I thought I'd try this subreddit: I've only just started reading about ML and have come across [this paper about composing melodies from (Chinese) lyrics](https://arxiv.org/abs/1809.04318); earlier I saw [this paper](https://arxiv.org/abs/1612.01058), which is apparently the basis for a new iOS app. The first approach, using RNN, seems to get much better results than the second (random forest), but, as you can imagine, it's way more sophisticated. So I'm wondering how difficult it is to implement something like the RNN approach--with GRU, encoder/decoder, and so on--given the description the authors have provided (and a boatload of MIDI tunes with lyrics). Thanks for any input.",1
204,,1
205,"I'm an experienced data scientist (I actually lead a large team) and am reasonably literate about computers, though I am not a developer or IT professional. My organization is split roughly 50/50 between Python users and R users (and a few unicorns who are proficient in both). The general consensus, with which I don't disagree, is that R is generally better for data analysis/exploration/visualization because of dplyr and 
ggplot2 (tidyverse), and Python is generally better for machine learning because of sklearn, Keras, and Tensorflow. And yet, R is good enough for machine learning (mlr, caret) and Python good enough for data analysis/exploration/visualization (pandas, matplotlib) that you don't \*really\* need to learn the other unless you stumble upon some problem for which there is no library in your preferred language.

I started out using R when I got into data science because the guy who was showing me the ropes was an R guy. I was able to quickly and easily get RStudio installed on my machine, load up the packages I need, and start learning the language. R has plenty of quirks, but it has served me well over the years and I am able to do pretty much anything I need to do with it short of really complicated deep learning, which isn't really a requirement at the company I'm at anyway. For nearly all of our ML problems, some combination of linear regression, random forests, or XGBoost will get the job done. And mxnet actually works pretty well for deep learning in R.

However, I always want to expand my skillset, and I have tried several times to work in Python. The first time, a friend showed me how to set up a Jupyter Notebook and I was able to get some basic things working in that after several hours of trying to set it up. The biggest pain was realizing that I had to install Python on a path without any spaces in it and then go set my Windows path variable to get it to work. I eventually decided that R tools suited me better and went back to R. I tried again a year later when I wanted to play around with deep learning and was able to get TensorFlow working after **several** **days** of wading through their never-correct documentation, scraping message boards for help, and eventually finding a blog post that solved the rest of my problem. Then I decided that the syntax was way more complicated than it needed to be (I wasn't aware of Keras yet), and went back to using mxnet in R.

The other day, I discovered the reticulate package for R and have been trying to get it to work, with no success. I have read through all the documentation, tried using conda\_install() and use\_python() to create a virtual environment with all the libraries I need, but it is failing to find numpy. On the reticulate page, my exact situation exists as an open issue and there has been a long chain of discussion but no resolution. Several hours down the drain.

My point is, RStudio installed just fine on the first try. All the packages load and work pretty much right away. I've never had to worry about keeping several version of R on my machine or changing any environment variables. I haven't had to spend endless hours digging through message boards just to get R to *run*. I really want to learn to like Python, but it *really makes itself hard to love*. I'm too busy to spend days and days setting it up and tweaking things. Why hasn't one of the most popular programming languages in the world been able to get some *basic* things right such as, ""You can run this installer on Windows 10 and it will work out of the box""?",1
206,"Out of curiosity, if you have a vision that you are about to code, can you just sit there for a while and write it? I feel like I’m a dummy for having to lookup the syntax and inputs for every other line. Idk what the standard is though, I’m a math geek who taught himself. So I get it if it would be unusual for a C++ expert to know the kurtosis of a lognormal distribution. Idk.. thoughts on the topic would be nice. ",1
207,"I feel like the ultimate goal would be to be your own boss and just cooperate with companies when they need help interpreting data. 

Would anyone here categorize themselves as this and how did you become it ?",1
208,"The python post was great. Best package I learned about was shap. Defiantly diving into that. However I prefer to work in R. We all know about keras, tidyverse, caret, etc 

So what are some other packages you find useful?

For me getting back into DS after long gap, I am rediscovering a huge set of new libraries so I don't know how well these are known but I have been amazed with [https://rstudio.github.io/reticulate/](https://rstudio.github.io/reticulate/) and [https://www.rplumber.io/](https://www.rplumber.io/)

&amp;#x200B;

&amp;#x200B;

&amp;#x200B;",1
209,"I’ve seen several people mention (on this sub and in other places) that they use both R and Python for data projects. As someone who’s still relatively new to the field, I’ve had a tough time picturing a workday in which someone uses R for one thing, then Python for something else, then switching back to R. Does that happen? Or does each office environment dictate which language you use? 

Asked another way: is there a reason for me to have both languages on my machine at work when my organization doesn’t have an established preference for either? (Aside from the benefits of learning both for my own professional development) If so, which tasks should I be doing with R and which ones should I be doing with Python?",1
210,,1
211,"I have a PhD in statistics and I've been in a few academic postdoc positions for the past 4 years. These positions have involved statistics, machine learning and deep learning. I've been trying to move to industry and I have finally secured a *data scientist* position at a mid-size startup company that isn't very well-known. I am looking forward to using this position to gain industry experience that would greatly enhance my chances of landing a  *senior data scientist* position. However, I am worried about how much data scientist experience counts when it's from an obscure and not very well-known company. Coming from academia, I know that having a degree or postdoc from a top-tier university makes you stand out from the pack. Is this also the case out in industry? Would *data scientist* experience from a top-tier company like Google, Facebook, etc. (or even mid-tier company) be considered more valuable than similar experience (in terms of scope and duration) from a relatively unknown startup?",1
212,,1
213,"I'm about to begin formally mentoring a junior peer.  I'm old and can't remember what it was like joining the workforce in the early days of the GWB administration.  Young data scientists of Reddit, what would you like to get out of a mentoring relationship?",1
214,"[https://research.fb.com/category/data-science/](https://research.fb.com/category/data-science/)  
[https://research.netflix.com/](https://research.netflix.com/)  
[https://www.aboutamazon.com/research](https://www.aboutamazon.com/research)  
",1
215,"I am very new to Autoencoders and anomaly detection, and am currently working on a credit card fraud dataset to understand how Autoencoders can serve in fraud detection. Please correct me if I am mistaken in my logic.

&amp;#x200B;

Objective: Binary classification of whether transaction is fraud (1) or non fraud (0). 

&amp;#x200B;

After loading the dataset in, I have done some basic feature engineering (normalization \[-1,1\] etc). Next, I separate the non fraud class (0) from the fraud class (1) (values as well as target variable).

&amp;#x200B;

After doing this, I feed only the non fraud data/target as my training data into the autoencoder using Mean Squared Error as my metric of evaluation. From my understanding, this is what will serve as the Reconstruction Error that is being used to compare the classes.

&amp;#x200B;

Finally, I predict using the autoencoder on the fraud class (1) data and calculate the Reconstruction Error on that data.

&amp;#x200B;

At this point, I have the Reconstruction Error from both classes. From my understanding, we use this Reconstructor Error to differentiate between data that is of the class Fraud and Non Fraud.

&amp;#x200B;

Suppose that I want to feed in a user input into my Autoencoder model that I have built to classify whether that data is fraud or not. How would I go about doing this from the point that I am at now? Would I just call ""[autoencoder.fit](https://autoencoder.fit)(userdata)""? Would that essentially give me a Reconstructor Error value to compare?

&amp;#x200B;

Any help would be great as I am very new to this concept!",1
216,,1
217,"Every article I can find just list the essentials like numpy, keras, pandas.

What are some lesser known libraries that are useful?

I'm thinking of things liem [great-expectations](https://github.com/great-expectations/great_expectations) and [pandas-profiling](https://github.com/pandas-profiling/pandas-profiling).",1
218,"I notice more and more recently that there seems to be quite a handful of data scientists with poli sci backgrounds. Drew Conway (the creator of the famous data science Venn Diagram) has PhD in political science. So does Chris Albon, who used to host the popular data science podcast Partially Derivative. Stanford literally has a data science track for their undergraduate political science curriculum: [https://politicalscience.stanford.edu/undergraduate-program/tracks/data-science-track](https://politicalscience.stanford.edu/undergraduate-program/tracks/data-science-track). In addition, a simple LinkedIn search of political science and data science will return a suite of profiles of data scientists with poli sci backgrounds.

When did political science become so data driven? My impression was that it used to be mostly about reading Hobbes, Locke, or Fukuyama and the like. So how is data science used in the academic discipline of political science? What tools or methods that are used in political science are transferable to data science exactly?",1
219,"Hello everyone! 

I am a budding data scientist working for a major municipality. In 2018 we started as a small data science team of 4, working from our laptops. Eventually, we got a linux server where we could host our work and deploy our first model on. However, this server is hosted outside of our company's architecture.

During this time, our municipality is making a hard push to become data driven, including automation of data entry, storage, and an overhaul of our IT architecture. I feel this is an excellent opportunity to take our data science team to the next level, and try to push for a small but complete architecture that can help us deploy our models internally. This would be a major help since we could directly connect to the existing databases (where now we have to use manual extracts to feed our models).

However, this is where my knowledge gets stuck. I have been reading up on things like linux, spark, docker, etc. But it's difficult for me to form a comprehensive overview of what architecture is standard for data scientists, and (maybe more important since I have to defend and push for this) why we would need this. 

For example: I try to push for docker implementation in order to shorten the gap between our new engineering team and the end product of data scientists (since the engineers want to use docker too). However, I don't know exactly why docker works so well for this and why it is better than other tools. However, I need to know this in order to defend our choices.

Any help with a comprehensive overview providing me with a structure regarding architecture and deployment would help greatly! (or anyone chiming to provide their knowledge from experience).

thanks in advance!",1
220,"As a part of a Data Science Team, visualizing our findings and results is crucial for making our work accessible to other colleagues in our team as well as other teams.  Until now I have used almost exclusively the python library matplotlib where I have become pretty proficient. In the past few weeks I have experimented with bokeh and holoviews for interactive charts and I really want to make those charts visible to other people than just me with my Jupyter Notebook. 

So I guess my first question would be wether you also use interactive charts?

My second question is about publishing those plots. I would need a running python process in the background when having the plots exposed because with a pure HTML file the browser can only interpret the javascript code embedded in the plot. As I understand it a bokeh server seems to be a practical idea. And then? The guys at bokeh - I think - are working with AWS and Elastic Beanstalk to show there demo plots. What do you think of this solution? Is it practical for a Data Science Team to publish these plots through an AWS Python Web App? Our Engineers are AWS Pros so the knowledge in our team is there. 

Thanks for your help!

Bokeh Demo Plots: https://demo.bokeh.org/movies
AWS Beanstalk: https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/create-deploy-python-apps.html",1
221,"Hi,

I was wondering what your experiences are when it comes to Segregation of Duties.
I am working in financial industry and quite often I find the role of data scientist a bit problematic with regards to the standard Business/IT/Operations setup that is enforced. 

Just to clarify - in essence it comes down to a point where one should not be allowed to keep production data on development servers, having write rights on development servers is allowed only for IT developers, developers cannot have access to production data... I think you get the point. 

I can hardly imagine the work of a data scientist without the possibility of trying out various algorightms on production (non-scrambled) data.

How do you guys deal with that? Anyone feeling like sharing their experiences?",1
222,"I saw they made a crappy implementation of FP-Growth. That's one of the slowest algorithms for FIM and using Java for HPC is the dumbest idea ever. IT GIVES YOU UP TO 100X SLOW DOWN OVER PROPER C++ CODE. If you're using Java/Hadoop for anything you should change career, because you are a fraud.",1
223,"I'm a recent convert to the Scala programming language and I'd like to show other data scientists just how powerful basic Scala can be. The most recent article in the series is particularly fun because we get to analyze actual reddit data by writing and running Scala code in our browser. See the blog post, [Interactively exploring Reddit posts using basic Scala in your browser](https://medium.com/@matthagy/interactively-exploring-reddit-posts-using-basic-scala-in-your-browsers-f394843069de). Learning some interesting things about Redditors...

&amp;#x200B;

What do you think? Does this article demonstrate the power and simplicity of basic Scala? Do you find it interesting to analyze Reddit posts and therefore find the article more engaging than something that just shows off the language?

&amp;#x200B;

Are any parts of the article and examples unclear? If so, let me know and I'll improve them. In general, I'd appreciate any critical feedback because I'd like to get better at developing such educational resources.

&amp;#x200B;

Lastly, any thoughts for other data exercises that would be even more interesting? Hoping to soon show people how to spin up a small ad hoc Hadoop cluster in 15 minutes using Databricks so people can work through big data exercises using basic Scala within Spark. Any particularly big data sets that you think people would like to explore in programming exercises?

&amp;#x200B;

Thanks!",1
224,"I heard that Stitch Fix has 50+ data scientists (not data analysts that they just call data scientists, I think). Does anyone know of other companies with such a large DS department?",1
225,"Hey, I'm interested in running my first multi armed bandit (instead of an AB test) but I'm struggling to find info on how long to run the experiment for,or how to tell significance. Normally in an AB, we would calculate the statistical power and significance needed to detect a minimum change. But I was wondering if this was the case with a MAB.

Is it as simple as seeing when your success metric starts to level off and then perform a t test or chi squared test on the variants? ",1
226,,1
227,"I'm a little confused, maybe I just read wrong info.

But are the typical data scientists supposed to code for machine learning ? 

I thought the first and foremost important knowledge &amp; skill is on stats/math &amp; business.  And programming is the least expected.",1
228,"A few days ago I began to think about how a company could implement a data science process, understanding that this type of implementation is transversal to all areas since it involves data collection to the delivery of results. For a process of this nature to be successful, it also implies a change in the mindset of managers and executives. Moreover, for that, we need to show what are the main benefits of making such a profound change in any company.

It also involves looking for the appropriate profiles according to the type of company, so that they support the necessary daily tasks.

&amp;#x200B;

This article deals with: what is data science, its benefits for a company, what a company needs to implement them and the necessary profiles.

&amp;#x200B;

I would like to hear some feedback about the points expressed here: [http://www.thinkingondata.com/implementing-data-science-process-in-your-company/](http://www.thinkingondata.com/implementing-data-science-process-in-your-company/)

&amp;#x200B;

Thank you!

&amp;#x200B;",1
229,"I’ve been working on a project for client that involves risk analytics. I was brought in to help with alternative modeling, but the client is proving difficult to work with as they’re expecting me to interpret the model results for them at a higher granularity than I am comfortable with. 

When working on joint projects like these, where do you draw the line on where your expertise ends and where theirs begins?  I’ve been trying to get the client to work with me on interpreting the results, but they’re not being very cooperative, instead leaving it to me to interpret the output. I have a surface-level understanding of risk, but I feel this isn’t enough to make concrete recommendations.",1
230,"I'm working on a project to assess FAIR policy of different knowledge graphs already in existence and was wondering which has the worst FAIR implementation and needs work to make it better.
Can be anything, but It'd be better if the topics is not super complex and something I can get right into without any proper background. ",1
231,"Welcome to this week's entering &amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)  
* Traditional education (e.g. schools, degrees, electives)  
* Alternative education (e.g. online courses, bootcamps)  
* Job search questions (e.g. resumes, applying, career prospects)  
* Elementary questions (e.g. where to start, what next)  

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](https://www.reddit.com/r/datascience/wiki/resources) pages on our wiki.  

[You can also search for past weekly threads here](https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;restrict_sr=1&amp;t=month).

^(Last configured: 2019-02-17 09:32 AM EDT)
",1
232,"I have read with great interest on this thread, especially (this thread)\[[https://www.reddit.com/r/datascience/comments/ats06d/im\_a\_data\_scientist\_starterpack/](https://www.reddit.com/r/datascience/comments/ats06d/im_a_data_scientist_starterpack/)\], as we all seem to have different perspectives on what constitutes a data scientist, and what core skills, so I thought I'd try something, which is to crowdsource a collective view within this subreddit of the key skillsets required.

&amp;#x200B;

Approach:

1. I will start off by posting top level comments as generic skill sets that are either business, technical, statistics and mathematics related.
2. Upvote the ones you believe are important core skill sets, but DO NOT downvote any other skills if you disagree/don't know is key. If you don't agree with a skill set not being core, simply don't upvote.
3. Leave your comments as second level comments so the top comments are always relating to the skills in question.
4. Add skills you think are important but you don't find them in top level comments.
5. By the end of the whole exercise, with enough votes, I believe we should then be able to see our crowdsourced key skills for this profession that are sought after and are important to being a good data scientist/analyst (note: my methodology may have loopholes, so please feel free to suggest some changes, I have a research methodology and statistics background but don't profess to be an expert, so comments welcomed)

&amp;#x200B;

If this whole approach sucks, heck, at least I tried!

&amp;#x200B;

&amp;#x200B;",1
233,,1
234,"Every time I finish a project or report, I get this overwhelming sense that I made a huge glaring mistake somewhere that I can’t see. This leads me to compulsively check, re-check, triple check my work, my math, my code, my assumptions and conclusions, wondering if something in the underlying data may have screwed me over somehow. I know having a healthy dose of skepticism is good but... I guess I’m looking for strategies/advice on how to keep that in check.

Edit: typo",1
235,"This is a little lengthy but I hope you find the story interesting and would greatly appreciate any feedback.

Some history that brought me to this point:

* Transitioned from a Software Engineer to Data Scientist role \~5 years ago, while working at a mid-sized software company in an extremely niche market in a smallish city.
* Got the opportunity to work on some run-of-the-mill problems (data analysis, classification, forecasting) and not so run-of-the-mill problems (rebate optimization for cooperative purchasing / buying groups).
* The business was interested in the results but never interested in moving our data science initiative forward as they weren't really forward thinking.
* My role slowly transitioned to managing the development and implementation of a new reporting solution using a software problem plagued with bugs, affording me less time to maintain existing models and continue to innovate; less time to practice data science.

As a result of the last event, I decided to look for another job with the constraint that I wouldn't be able to leave the city. Since there isn't a huge tech presence here, the frequency of data scientist job postings is about 0-1 times per quarter. Lucky for me, one popped up and I jumped on it, I was getting pretty miserable going back to managing a dev team at the company I'd been working for for 7 years and felt like the move was long overdue.

Not only was I desperate to get out of my current role, but the context and scope of the posting appealed to me - a data science role at a multinational company within a large (\~150 person) finance team (finance as in cost and management accounting and internal audit). Within the team I would be data scientist #1.

I haven't come across any literature on data scientists embedded within finance teams so I thought this would be a challenging albeit rewarding opportunity if I could innovate in the accounting space. The organization has a dedicated data science team focussed on innovation and run-of-the-mill user experience and revenue problems which admittedly sounded a little sexier but the team is located in another city.

My concerns:

* I accepted a slightly lower salary though it could be more if I'm awarded a discretionary bonus, based on overall company performance, and maximize my retirement savings investment matching plan.
* I have left a software company that was starting to embrace modern technologies (Azure, Docker, Angular, more reliance on web services) which would pave the way for the adoption of ML / AI in some of their products though we were probably 2-3 years away from it.
* The company I have accepted a job at seems very focussed on a small subset of problems which mostly could benefit from some data mining at best as they feel that opportunity exist but we need to discover it. For example, my first task is to complete a project that the previous person who was in my role had got to about 80% completion with. One of my short-term responsibilities is to establish KPIs, build some dashboards for users in operational and strategic roles, and help converge on a change management strategy since analytics is foreign to a lot of people at the org. Once the project is complete, they want to keep trying to extract insights for the particular problem, rather than exploring new use cases.
* I'm going to spend a tremendous amount of time trying to integrate data from a very heterogeneous set of sources from different providers (lots of time on the phone and exchanging emails), rather than have an eng team work on it.
* In line with above, I'm afraid that the organization will become obsessed with pumping out reports or that I will spend the next two years bringing them up to a basic level of analytics maturity.
* When I say ""predictive models"" they think ""financial forecasting"" rather than classification models for e.g. expense categories and feel that even financial forecasting is something ""we are a long ways away from"".
* I'm starting to fear there are limited problems in accounting on which the full breadth of data science can be brought to bear, leaving me with irrelevant experience and ""behind the times"".
* **My future job opportunities at technology companies (which is eventually where I want to end up given the scale of the problems) will be impacted since I'd be coming from a non-technology company, even though I have 9 years experience working in software.**

The good:

* Lots of opportunity to interact with stakeholders, working to understand their business problems, and developing creative data solutions to address them.
* The opportunity to present findings to senior management (CEO, CFO) of company that generates more than $1bn a year in revenue.
* A manager and executive sponsor who seem very excited to become a ""cutting edge"" finance department with respect to technology and analytics capabilities, even though they aren't aware of the all the possibilities.
* I have the opportunity gain valuable change management experience.
* I have the opportunity to work with my manager to build a team of data scientists and analysts if we get a few quick wins.

The big question that I keep asking myself is ""Should I stick this out and put my full effort and passion behind it to make the initiative a success, or am I being overly optimistic in my pursuit of bringing the full breadth of data-driven decision making to a finance department?"".",1
236,,1
237,"Sorry for another career related topic.

I just got a rejection from a Data Scientist job after a technical phone interview. I got Math PhD last summer and I’m currently a Data Scientist in a small company for four months. Due to various reasons I’m actively looking for other opportunities.

The reason they said is “PhD graduates usually go to bootcamps or take online courses to learn data science skills. Since you didn’t do any of them, we think you are not passionate at this career.” 

(I thought) I nailed all the technical questions (machine learning and coding) cause that’s what I’m doing everyday.

It’s such a dump excuse. End rant.",1
238,"I've been confused about what production ready code means. Let's say for example that you completed a random forest on a test set, by using the predict function, you are able to test the prediction on a test set. Why can't you use the predict function in a production environment? ",1
239,,1
240,"Been reflecting on how to use SQL in data science work relative to using (Py)Spark. In general, I'd like to do more with SQL, but find it breaks down for anything more complex than about a dozen lines of SQL. Instead, I've been finding myself using Spark more and more, and find Spark solutions to be more testable and legible with respect to SQL.

Details of my thoughts in the blog post, [The limits of SQL in data science, analytics, and engineering](https://towardsdatascience.com/the-limits-of-sql-in-data-science-analytics-and-engineering-4d7e48271a2f). Most controversial opinion is that I'm thinking Spark, DataFrames, and Scala could be developed and read by non-engineers to totally replace SQL.

What are your thoughts about using SQL in data science? Have you been able to use SQL for larger and more complex work? Are there notable benefits to using SQL in place of Spark Curious what other people think before I start trying to convert more people from SQL to Spark. Thanks!",1
241,,1
242,"I took advantage of the holiday sale to subscribe to Dataquest. While I like the idea of the format, the execution has been a letdown. In several sections in the intermediate python section, the correct code doesn't work due to back end errors. Checking the forums shows this has been an issue for over a month. I emailed support 3 days ago and still haven't heard back. I did get a response from the Twitter account but still no help with the issue. At this point, I am so frustrated with the lack of suppport that I would prefer to get a refund and try another program.

I wish now that I had gone with Datacamp instead.

&amp;#x200B;

\--update 4/3/2019

Dataquest did give me a refund and allowed me to continue working for a month. Outside of the response time and bugs during the changeover, I like their content. I resubscribed yesterday. ",1
243,"Working in SQL/Tableau. Basically we're looking at cancellation rates, and they want to take a small pilot program and measure the cancellation rate, but the program has about 20 customers a month, so one cancellation is 5% which makes the results choppy. 

He's under the impression we can ""normalize"" this data to smooth it out somehow to make it less susceptible to jumping around due to the small number of people in the pilot program. He said something vague about that we shouldn't be separating the pilot, but considering it as part of the entire customer population. He says he's done it in excel in the past but doesn't remember how.

Any suggested topics for me to research on this? Again, we're just running pure T-SQL and Tableau so I can't use anything like R to do any really heavy lifting.

EDIT: I feel I should point out that this isn't estimating future rates, we're looking at the existing rate over the last few months.",1
244,"I've been reading a lot about Bayesian statistics and its relationship to machine learning. I have a fuzzy understanding of many of the concepts, such as maximum likelihood estimation, bayes theoreom, prior/posterior distributions, etc, but if someone asked me in an interview to derive any of that or recall specific distributions from memory, I would be totally lost. I'm not even sure how to use that in a practical setting. 

Basically, is committing a lot of time to mastering bayesian statistics worth it to be an effective data scientist? or is it just something you learn in college and immediately forget?",1
245,"What worked, what are the problems you faced? etc.",1
246,"My current understanding is that “Data Scientists” are concerned with deriving new insights using ETL methods, however with the rise of ML models in production level settings new roles specific for building models have emerged. Now with this in mind I was wondering how many people in the DS world currently have model building and deployment as their central role. If you can share your personal experience that would be awesome.
Thanks!",1
247,"I've been noticing a bit of a trend with some of the new data scientists at my work.  Every problem with a categorical regressand they go straight for a Random Forest without first trying a logistic regression. 

I can only think of a handful of situations where this may be appropriate, for instance when you are too wide for logistic, or maybe when you are correlated to hell and back, but in the former case (and maybe the latter as well) I would probably still suggest a multivariate/discriminant analysis before a random forest.

Anyways, can someone else give me a good reason to go to a Random Forest without trying a logistic (or even discriminant) analysis first?  I'm concerned that either I'm missing something or they are.",1
248,,1
249,,1
250,"Pretty much interviewing for a new company and they sent me a package on google data lab to look over. 

I'm not sure what they want from me. Either they are using it already or they want to know if it's a tool I would want to do data science. 

When I looked into the data lab, its jupyter notebook on a google VM, combined with bigquary for SQL. 

What does google analytics offer more than that? Do you use it?

Does google provide the data too?",1
251,"Got a Microsoft interview coming up, curious on the format/and work environment? 

Thanks!",1
252,"Hi everyone. I would like to make an open call for participation in the Data Science StackExchange.

https://datascience.stackexchange.com/

I have no affiliation with it. This is not an affiliate link. Those of you that are familiar with the stackoverflow, you can understand what a big asset is for the developers to have such a community. If we participate in Data Science StackExchange, we can do the same!

What any StackExchange needs:

1) Votes! Votes! Votes! Votes are the mean to moderate and improve the content of the site.

2) Answers. At the moment, DS has \~4700 unanswered questions. We are a community of 38.000 members. We just need to answer 0.12 questions each of us :P

3) Valid questions. If you have an awesome question (even if you know the answer), put it there. The content is the king. Another user will find it the next day and will really appreciate that someone got his back",1
253,I was watching [this](https://www.youtube.com/watch?v=1I0cUTXwr-k&amp;index=2&amp;list=PLUXSZMIiUfFSe4gpc8PLDECqViWi-2we3) data analytics video and thought the visualization style was really neat. Does anyone know how something like that would be made?,1
254,"I'm having some trouble finding what a reasonable salary for an entry level data science position in Canada is. I'm currently in Toronto and will enter salary negotiations soon with a tech company here. I am graduating with a BSc in Statistics this spring.

When I look on Glassdoor a lot of the salaries are mostly for (what I assume are) senior positions since they're 6 figures.

Does anyone have any insights into salaries for entry-level DS positions? ",1
255,,1
256,"About a month ago the mods asked for feedback on the [subreddit and suggestions for improvement](https://www.reddit.com/r/datascience/comments/adprzt/meta_seeking_input_on_subreddit_rule_and_style/). I have to say that the sub has been noticeably better less than a month later. There's a giant banner that appears when a new submission is made pointing folks to the weekly entering and discussion thread. Additionally seemingly all posts are now flaired appropriately and you just have to look at the current front page to notice the quality of content and discussion is much improved.

Being a mod is a difficult and thankless job, so I just wanted to notice the positive efforts of their work around here!",1
257,,1
258,"I’ve looking at different article that use naive bayes or logistic regression to test a certain feature like (subject line or location). I still can’t find a way that I can use that incorporate both customer history (features) and email features.

Features:

Email features:
 subject line,email type (promo, loyalty, holiday,..etc), delivery date, email text.

Customer features : 
Country, city, device (mobile, desktop,...), domain (yahoo.com, Gmail.com,...)

And the output variable which is (1 (opened), 0 (not opened))",1
259,,1
260,"Recently at work, our boss came over to us (a team of analysts), and asked us: By what % can we improve our demand forecasts in 2019? Evidently, she is making it a personal goal (for performance appraisals) to improve our forecasts by x percentage from last year. For context, we support a call center, and have short and long-term forecasts that help us adequately staff and prepare our budgets. Our demand is for the most part seasonal, however we're very sensitive to events, like when there is poor performance across the system, or an unfortunate tweet - which drive calls to our center and can blow up a forecast.

&amp;#x200B;

I understand the need for accuracy, and will relish in the chance to improve our forecasts, but when performance appraisals get involved, is it setting a bad precedent to hold others accountable for events beyond their control? In our group, PA's affect merit increase the following year.",1
261,"Hi r/datascience!

I would like to share my personal data science project on how I analyzed my weight loss data in 2018. You can read my [writeup](https://link.medium.com/9KJRGuzsqU) on the project on Medium, and check out its Github [repo](https://github.com/dknguyengit/logweight).

The 2 main goals for the project are:

* Build a machine learning model (namely regularized logistic regression) to classify whether I would gain weight or lose weight on a given day given how many calories I eat beyond my allowed budget and my step count for that day. The parameters of the model (the regression coefficients and the decision boundary) are also used to give simple, actionable numbers that I could use for my weight loss journey.

* Build this machine learning model from scratch without using 3rd-party libraries (aside from numpy and pandas). This includes the model algorithm (batch gradient ascent), k-fold cross validation, performance metrics, ROC curve, and other related visualizations. This turned out to be not as intimidating as I'd thought. In fact, the core algorithm for batch gradient ascent can be done in 3 lines of code!

I've tried to tailor my writing to be accessible to beginners (as I'm also a relative beginner to data science). Therefore, I'd truly appreciate any input on how I can make my writing and visualizations better.

Also, I'm thinking of doing to do a 30-day challenge, during which I followed the guideline outlined in the project, and see how consistent I can lose weight doing so (perhaps via daily updates through a Twitter account). I think it might be fun to use this as a real-life test set for my model, but I'm afraid of the potential public failure 😭 If you've read my Medium post, please let me know what you think about this idea.

Please also let me know if you have any question or feedback on my project!",1
262,,1
263,I was wondering if any Data Scientists uses causal inference in their jobs to assess relationships between exposures and outcomes. My background is in Epidemiology and we are taught causal inference and I work as a data scientist in a large healthcare company where causal inference is used because interpretation of models is really important in the healthcare field. I saw Netflix has a lot of economists and researchers that run causal experiments and Microsoft just recently open sourced DoWhy to make causal inference more accessible to more people like scikit learn made machine learning more accessible. I guess my question is do you think causal inference will become more main stream like machine learning in data science? And also which companies are currently using such methods besides healthcare companies etc?,1
264,"Over weekend I have written a ""cookbook"" how would you set up a **docker-friendly** Apache Airflow environment. This is a great workflow management tool, fit not only to Data Science environment. My solution *detaches the actual execution* from Airflow and only manages running Docker containers. Hopefully somebody finds it useful.

https://medium.com/@tomaszdudek/yet-another-scalable-apache-airflow-with-docker-example-setup-84775af5c451",1
265,,1
266,"Hi, I'm fairly new into my first Data Science role where my work thus far has been building a price sensitivity model (Python, mostly).

The team and I have just finished iterating the model for our 4th product. However, there's almost 200 products in total and we're debating how many models we actually want to create. 

The issue is, many of the products are related. Reducing 1 products price may increase sales by 100%, but 3 other similar products reduce by 10%. Alternatively, reducing one product could create a ""halo"" effect, which increases other similar products.

The products have some similar features, but some are unique to the subcategory the product is in.

Are there any methods that I could look into which cover this sort of problem? 

Thanks very much for any tips in advance. ",1
267,"I currently have a somewhat bulky windows laptop with a gtx1080 card and i7 processor and 16 gb ram. 

I wanted to go lighter because it’s a pain in the ass carrying this thing around when I go to conferences or to a library etc. 

If I’m doing machine/deep learning, I will need lots of memory, and a good processor plus gpu right? What about OS? Are Macs more preferable for Dscientists?

I want something that can do deep learning effectively that is also pretty light. Help pls ",1
268,"One of the local universities offers a BI program being taught fully on SAS EM and EG and omitting all coding. I’ve interviewed individuals from this institution who know how to use these two softwares, strictly as a drag and drop program, but have absolutely zero coding knowledge.  This lead to discussions at the office about how much we value coding knowledge and how useful it is in the industry. 

Wanted to know what your thoughts are on the matter. What do you think of a university program teaching BI without any coding? Would you value drag and drop BI knowledge over coding knowledge? Or any other thoughts you may have on this, very curious.

Thanks!",1
269,"Does anyone know of any interesting uses of municipal data, particularly though not necessarily in a private sector context? ",1
270,"Welcome to this week's entering &amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)  
* Traditional education (e.g. schools, degrees, electives)  
* Alternative education (e.g. online courses, bootcamps)  
* Job search questions (e.g. resumes, applying, career prospects)  
* Elementary questions (e.g. where to start, what next)  

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](https://www.reddit.com/r/datascience/wiki/resources) pages on our wiki.  

[You can also search for past weekly threads here](https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;restrict_sr=1&amp;t=month).

^(Last configured: 2019-02-17 09:32 AM EDT)
",1
271,"I find myself having a lot of free time in my current Data Scientist role so I'm considering freelance consulting for small businesses as a side gig. This, I believe, will be great for the money and also provide a means for me to continuously try new problems / update my skills. For current freelancers, how often do you have to deploy models for clients? What deployment / production solutions do you use and why? Also, can you give a rough breakdown of solutions you've provided previously by percentages (e.g. visualization / analytics / insights - 25%, predictive models - 40%, etc).  ",1
272,"I can't count the number of times I had to purge all drivers, install them again, have various screens not detected anymore, and so on...",1
273,,1
274,"I was talking with a colleague today about a bit of materiality assessment I'm working on.  I had found an interesting part in the comparison data that got a hold of our curiosity.  

&amp;#x200B;

But something my colleague said was ... let's leave this out if we can't fully and completely explain it.  Doesn't matter how interesting it is... if you can't explain it will cause more issues than anything.

&amp;#x200B;

What does this sub think?  Do you only provide explainable findings in your documents?  How do you handle interesting but (as of yet) unexplainable findings?",1
275,"I have no experience using Keras, but I'm trying to classify a set of images into the above mentioned categories (and also data charts). I tried using open pre-trained models (VGG16,InceptionV3,ResNet), and it seems that they are used to classify objects, like dog, cat, car, etc. 

Before training my own model, does anybody knows if there is an open pre-trained model for this?

Thanks!",1
276,"Hi, I'm trying to host a data science/machine learning contest at my company. We are an international company, with some branches overseas. Security is a huge issue, since I want to use actual company data for this contest. I have thought about trying to anonymize the data, but realized that wouldn't be possible for most the data I am dealing with. 

&amp;#x200B;

I'm looking for suggestions for how to mitigate security risks with this data. My biggest concern is that if a CSV file of our company data somehow was leaked online. Do you have any suggestions?

&amp;#x200B;

My thoughts/ideas so far:

* Make sure each of the participants agrees not to distribute the information (duh)
* Anonymize the few fields which can be anonymized
* Maybe create a private server where the contestants have to login and create their models remotely. The data would be hosted on the server.",1
277,"Two of the hottest posts from today completely disagree. One says we're entering a data science glut, the other that there's still a huge shortage.

What are the thoughts from the rest of the sub?",1
278,"Hey guys, I've been offered a graduate position in the DS field for a major bank in Ireland and I won't be starting until September, which gives me a whole summer (I'm still in college) for personal projects.

One project I was considering was learning a compiled language, particularly if I wanted to write my own ML algorithms or neural networks. I've used Python for a few years and I love it BUT if it wasn't for Numpy/Scikit-learn etc it would be pretty slow for DS purposes. 

I'd love to learn a compiled language that (ideally) could be used alongside Python for writing these kinds of algorithms. I've heard great things about Rust, but what do you guys recommend?

PS, I saw there was a similar post yesterday but it didn't answer my question, please don't get mad!",1
279,,1
280,,1
281,"What additional language would you use to build tools if you're already comfortable with python?

Does it make sense to have some sort of experience with JavaScript or some sort of front end architecture?",1
282,My company uses amazon for everything and I am trying to use pyCharm as a front for processing done on a EC2 instance. My coworkers dont want to use jupyter notebooks or lab but want a local IDE that can fetch data and run processes in the cloud. Also we want version control etc... Are there resources on how to get started running pycharm locally but doing all the computation and housing all the data in the cloud? Thanks!,1
283,"I use a default project structure that integrates a Makefile for reproducibility. However it would be nice to have some kind of version control on the data/analysis/models and it seems like that's part of the goal with [DVC](https://github.com/iterative/dvc). 

Anyone have experience/opinions on it?",1
284,"I've been working at a new job with a probation period of three months. While my offer sheet has me as a 'Business Analyst Assistant', the job descriptions on it were more geared towards sales (Ex: practice sales by calling on accounts, learn sales admin. by completing sales rotations). This is so that I can grasp our market in the industry and to learn our products. In the interview, I only listed excel, access, STATA as skills.

Well from the grapevine, I've learned that my role was more of a 'Sales Support' and were originally set with a 6 month transitional date to learn. The original role was more of a documentation and liaison for sales.


In the first few weeks they were testing my competencies in ""numbers"", by tasking me with creating reports (pivot tables) through excel. I was finishing the reports quick enough that they have tasked with me doing analysis that isn't just calculating past percent growth or amounts sold. Basically I've learned quickly enough I'm past my transition period and they are giving me additional responsibilities.

Luckily during the first few weeks of having nothing to do (settling in and orientation), I was learning python. I've been doing simple stuff for now, automating excel reports through pandas, simple regression analysis, seasonally decomposing our data and detrending it, and using SARIMA models to forecast our future sales.

Well, its past the two months mark and my manager is asking for a meeting to update and change my job responsibilities for post-probation. 

What would be more accurate job responsibilities that I should put, and should it warrant a change in job title/pay? ",1
285,,1
286,"Hello everyone!

A young data scientist here!  I have recently started a new job where Agile project management is being implemented for data science and there are so many different opinions about it within my team! 

Since I never worked within this framework.. so I was wondering if any of you guys have? And if so, what are your experiences? ",1
287," 

When should you do pre-processing to avoid over fitting?

Do you do it both on the training and the test set, which may give you different values. Or do you apply the same values from the training set to the test set, which may lead to over-fitting.

I am confused by this quote below. For example, if you use mode imputation for a class on the training set, should you use mode imputation on the class for the test set, even if you get a different mode? Also, if you use mean imputation for numerical data in the training set, should you also use mean imputation on the test set (meaning you will have a different mean value than the training set)?

""To provide a solid methodology, one should constrain themselves to developing the list of preprocessing techniques, estimate them only in the presence of the training data points, and then apply the techniques to future data (including the test set).""

[http://www.feat.engineering/review-predictive-modeling-process.html#resampling](http://www.feat.engineering/review-predictive-modeling-process.html#resampling)

&amp;#x200B;

Here is a link to the same question in Kaggle: [https://www.kaggle.com/questions-and-answers/80455](https://www.kaggle.com/questions-and-answers/80455)

&amp;#x200B;

Thanks!",1
288,"From a large recruitment company (Morgan McKinley), they have provided salaries for common analytics jobs. Interestingly they do not have data analysts as a job title, which i thought would be one of the more common ones.

it also looks like we are paid higher than EU and some US counter parts, although in Australia there is no start-up scene where you get equity instead.

link: https://imgur.com/pS3sReu",1
289,"I have built an web-based app where I can enter some text and output a word cloud of it. Currently I'm showing the word cloud as a static image. I would like to replace it with a dynamic image whenever I put my mouse on top of a word, its frequency will show up. My app is built using Python and Flask. I'm wondering how should I realize this function if possible not using any other language? Any hints is highly appreciated. Thanks in advance!",1
290,"Hey Fellow data scientists, I am sure you've seen this: it could be your client, your boss, your colleague. They ask for more. ""Can we try adding another year's data?"" ""Could you check if weather makes a difference?""

There is nothing wrong in asking, but they do not know that adding more data is not like a click away. Sometimes it takes half an hour, sometimes it could take days. So what would you do?

As I jot down the problem, I thought of a fews things we can do, so my 2 cents here:

1. make your model more flexible; anticipate the additional ask
2. be smart about how you share the results: if you know they will ask for more however comprehensive your model is, release in phases
3. clarify the objective: what do you want to prove? what is the hypothesis? how does adding additional data help?
4. communicate the investment here: adding data can be time consuming. are you sure it is worth the effort?
5. bring this issue up over coffee/lunch...

Now your turn...",1
291,,1
292,[https://www.reddit.com/r/medical\_datascience/](https://www.reddit.com/r/medical_datascience/),1
293,"Hi!

I've been using Spark to do lots of data processing on a SLURM HPC Server (i.e. shared memory, no distributed aspect).

I'm realizing that Spark isn't really intended for non-distributed computing. Is there a Spark equivalent for shared memory processing? Should I just keep using Spark?",1
294,,1
295," Welcome to this week's 'Entering &amp; Transitioning' thread!

This thread is a weekly sticky post meant for any questions about getting started, studying, or transitioning into the data science field.

This includes questions around learning and transitioning such as:

* **Learning resources** (e.g., books, tutorials, videos)
* **Traditional education** (e.g., schools, degrees, electives)
* **Alternative education** (e.g., online courses, bootcamps)
* **Career questions** (e.g., resumes, applying, career prospects)
* **Elementary questions** (e.g., where to start, what next)

We encourage practicing Data Scientists to visit this thread often and sort by new.

You can find the last thread here:

[https://www.reddit.com/r/datascience/comments/an54di/weekly\_entering\_transitioning\_thread\_questions/](https://www.reddit.com/r/datascience/comments/an54di/weekly_entering_transitioning_thread_questions/)",1
296,,1
297,"I'm looking for a website that is similar to hackerrank, codewars, but offers more data science oriented challenges (like data wrangling with pandas, maybe some data visualiations, some dplyr excercies, maybe even ML and so on).

Anyone can recommend something like that? So far I found few challenges on hackerrank but not much.",1
298,"I am an overly extroverted person who is seriously considering a career in BI &amp; data science. 

I enjoy working behind the scenes and working technical roles, but I do crave human interaction every now and again because of my extroverted nature. 

Would a data science position be a good fit for an extrovert like me? I am considering an analytical position since I am technically minded and do not enjoy roles with an excessive amount of face time with others. 

Thanks!!",1
299,,1
300,"Hi all -

I'm setting up a data science project/codebase that will need to be applied to different datasets/in slightly different contexts, with a modular and customisable approach. For the sake of discussion, let's assume I want to build code, notebooks and analysis for data coming from 3 countries: `uk`, `us` and `jp`.

I'm using a structure similar to [Cookie Cutter Data Science](https://drivendata.github.io/cookiecutter-data-science/).

A few questions on best practices:

- Should I create a separate folder in the different codebase areas (`data`, `references`, etc) for each case? i.e. `data/uk/raw`, `data/jp/raw`? Or `data/raw/us`, `data/raw/uk`?
- How should I think about code modularity? Should my notebooks and scripts include a general `country` variable at the top and then run everything using this? So preset to `country=""uk""`?

Thanks!",1
301," I'm new to Big Data and I'm trying to understand the topic of security available around Big Data when it comes to Big Data Analytics consultancies.

In particular I would like to know:

1. Do all Data Consultancies use the cloud or do some use private servers for added security?
2. What security measures are available in the Google Cloud Platform specifically?
3. What security measures are available with in Private servers?
4. Any other security measures that may be important when a client trusts you with their data.

I appreciate this may be super-specific so even if someone could point me in the right direction to answering these questions that would be amazing.

I'm just trying to wrap my head around what kind of security features are involved around storing Big Data in the (Google) cloud and on a private server.

Thanks!",1
302,"Out of things like linear algebra, probability, calc, data structures, graph theory, optimization, etc.

For me, it was probability hands down. It's one of the most deceptively fearsome monsters out there. Not super mathematically rigorous but so extremely difficult to apply. Still gives me the heebie jeebies to this day.",1
303,,1
304,"I have been learning Python and a little R, and am fairly new to programming, but this is the goal I have in mind. I want to make sure I am spending time on learning the right things and moving in the right direction. Any help you can offer would be appreciated!",1
305,,1
306,"Any one doing the 10-week open machine learning course? Looking for a study buddy 

It just started yesterday and it’s free incase any one is interested ",1
307,"Hi all,   


I am correctly doing a project where I need weather data as part of demand forecasting.   
I need the data aggregated per day or even week on a zip code basis.   
Some of the variables I  is:

* Temperature
* Sunny / Cloudy / Rain / Snow
* Amount of hours where the sun shined
* Amount of rain / show

Do you know some good packages from which I can get this kind of data?

&amp;#x200B;

Thank you in advance.

&amp;#x200B;

Best regards  
Dat\_Sci\_SAR",1
308,"I have found that in my company, it's hard to come up with the traditional data science/machine learning solutions for the tasks at hand. In my case it's because we are a somewhat recent team with limited access to data, and we mostly use unstructured and unlabeled data.

I wanted to spark a discussion about less traditional products and deliverables for DS and ML. What I have in mind when I think about data science deliverables are reports with trend lines, regressions or more complex predictors such as deep networks. However, I have been thinking if there are other possible solutions when the tasks aren't so straightforward - for example, instead of full automation of a task, building a suggestion tool that helps a human doing that task, or turning a multiclass problem into a binary problem.

Has anyone run into a problem that you couldn't fit to a traditional solution? How did you solve it? Thanks",1
309,"Looking for recommendations for good DS related conferences, preferably around the Balkans or in Germany.",1
310,"Okay, so let's say I built a DL model that uses 300 features to predict if a user will buy an item or not on my ecommerce site. The ecommerce site stores all data on a SQL database, however when building the model, many of the feature names were changed for dummy encoding and other reasons. To make matters worse, the original data extracted does not use the original data labels in SQL, but rather many of the fields were renamed with 'more interpretable' aliases.

How do I ensure that the correct data required to run the model is sent to the API? My guess is that all data would need to be re-encoded with matching labels for the model to use correctly. Has anyone ever run into an issue like this?",1
311,"Hello, I am a data scientist working in finance. I have always been super into electoral politics. I spend on average 1-2 hours a day reading and keeping up and I am working on some models and replications. In short I am a huge US politics nerd and I would like to marry my passion for politics with the craft of data science. It helps that I am also super fired up right now.

&amp;#x200B;

I don't really know how to get in touch - it's not like these jobs are up on LinkedIn. I want to join a Presidential or Senate campaign and help someone I believe in get elected. Does anyone know where to start? I am a Democrat.",1
312,"It’s sad how much time I’ve spent watching this little guy clean my floor. Am I the only one?

Anybody know about the ML that is at work?",1
313,"Hi,

I'm working in a financial firm, analyzing emails to make our client service more efficient.

One of the models I'm working on is to identify and flag emails with potential business impact, ex a client threatening to pull business. I'm pretty sure Amazon does this with their customer complaints and I'd like to do something similar, only I've no training data.

I tried a google search to find similar dataset but didn't get much. I'd love to hear some suggestions on how to approach the problem.

My own thinking is to measure some standard indicators like sentiment, combine it with the number of follow ups the client has sent, the client importance and standardize the result and this can serve as a business impact indicator.",1
314,,1
315,,1
316,,1
317,"I am giving my first steps in data analysis, gathering/cleaning.

To learn, I am trying to create a simple code that can detect heartbeats from color variations from the image coming from the camera on the iPhone.

This is what I have done so far:

I have created a code that detects faces and cuts them from the image.
then I get the average color from that face image.

Because the values are grabbed at irregular time intervals, I have to interpolate the data to convert it to regular time intervals.

Plotting the data I have [this](https://i.stack.imgur.com/bFfGu.png)

I think I am seeing something that looks like heartbeats there.

To confirm that I am not seeing artifacts from the camera, I sample a rectangle from the background and I get the same color with very little random variation. The background color is stable and shows barely any variation.

Now, I apply a Direct Cosine Transform to the data and get [this](https://i.stack.imgur.com/KMg17.png)

The DCT has negative vales.

The two first items of the DCT are peaks, at t=0 and t=0.10482311 seconds.

I read a paper where the researcher says heartbeats occur between 0.4 and 4Hz. I suppose this has a relation why the first two DCT items are peaks...

What do I do now?

I have tried to apply a threshold to zero every term from the DCT below 150 and do an inverse DCT to reconstruct the signal and got [this](https://i.stack.imgur.com/iAOcF.png).

A threshold of 85 gives me [this](https://i.stack.imgur.com/u3ljx.png)

I am not sure if I see a heartbeat there. I mean, the peaks where the beats start.

This is the data at regular time intervals I have (256 samples):

17.0,14.151599,11.303198,8.454798,5.74406,7.5946655,12.173319,18.0,18.0,7.448537,18.0,16.36569,12.0000515,13.0,13.0,13.0,13.0,12.442261,9.134232,11.052017,12.0,7.605861,10.42025,11.911684,3.4419365,2.0,2.0,14.082303,16.227417,9.639368,7.0,3.4693644,5.0578203,7.0,14.859163,8.363442,7.876806,16.721855,16.367476,13.054573,17.416235,6.6276655,11.617707,12.0,6.3224463,11.111255,14.0,14.0,14.0,14.0,8.705125,17.478954,18.0,17.259813,14.371727,12.0,12.0,17.304781,18.0,18.0,2.6055841,9.789778,8.290463,6.3248563,2.3246787,12.944895,2.999961,8.443108,16.994041,7.714527,11.132567,2.2226758,5.6030903,12.528458,16.932209,16.087227,7.9563236,16.43404,8.239223,17.576452,12.102208,15.194642,1.0,1.0,1.0,1.0,1.0,1.0,1.7313459,17.479614,11.889918,11.0,11.0,14.0,14.0,13.802156,12.975004,6.840872,14.405505,7.928815,1.4836411,7.193712,15.371663,6.2666273,6.1682196,17.532732,16.0,15.034918,9.363262,1.0,4.654352,17.0,17.0,17.0,17.0,10.1624565,2.696946,13.607519,10.2923975,1.0,1.49984,9.996923,7.0500054,17.0,17.0,17.343903,13.191299,1.6610342,5.2127213,7.0,5.6532416,3.0295517,12.250117,12.687657,2.9297333,7.463814,9.5274105,13.640531,18.061134,16.376305,5.9621263,4.2103305,7.751727,7.023478,2.4116693,14.6888685,11.718729,4.0103664,12.0,8.606849,1.0,1.0,7.0,7.0,8.867684,12.0,12.0,9.598275,4.9731455,2.0,2.0,2.0,2.4965348,4.843401,5.4067893,3.655766,7.0,11.899609,11.855668,10.36767,16.59431,7.843425,1.9749169,8.829407,12.43066,11.205647,16.514818,17.0,13.328903,11.462145,12.0,12.0,12.0,12.502206,15.606055,18.0,18.0,13.699917,2.0,2.0,8.122738,12.0342,12.311193,9.434023,8.419968,8.64551,2.1631317,7.9250226,13.173435,3.0252013,1.0,1.0,1.0,1.0,1.0,3.7013192,6.0,6.0,6.3827076,7.0,6.570015,6.0,6.0,6.0,6.0,2.8011405,7.071625,15.575444,17.0,17.0,6.811758,1.0,4.5509486,5.3095756,10.288496,13.577595,2.493825,10.179988,12.0,6.3059773,7.9304085,14.911688,8.452748,2.8948724,10.117218,12.0,12.0,15.008322,16.0,7.473282,4.4403195,12.0,12.0,8.330021,6.0,6.0,6.0,11.515245,0.946867,0.83356774,0.95877224,0.05619842,15.221931,16.469358,5.231963,1.7867849

and these are the regular time intervals

0.0,0.03317536,0.06635072,0.09952608,0.13270144,0.1658768,0.19905217,0.23222753,0.26540288,0.29857823,0.33175358,0.36492893,0.39810428,0.43127963,0.46445498,0.49763033,0.5308057,0.56398106,0.5971564,0.63033175,0.6635071,0.69668245,0.7298578,0.76303315,0.7962085,0.82938385,0.8625592,0.89573455,0.9289099,0.96208525,0.9952606,1.028436,1.0616113,1.0947866,1.127962,1.1611373,1.1943127,1.227488,1.2606634,1.2938387,1.3270141,1.3601894,1.3933648,1.4265401,1.4597155,1.4928908,1.5260662,1.5592415,1.5924169,1.6255922,1.6587676,1.6919429,1.7251183,1.7582936,1.791469,1.8246443,1.8578197,1.890995,1.9241704,1.9573457,1.9905211,2.0236964,2.056872,2.0900474,2.1232228,2.1563983,2.1895738,2.2227492,2.2559247,2.2891002,2.3222756,2.355451,2.3886266,2.421802,2.4549775,2.488153,2.5213284,2.554504,2.5876794,2.6208549,2.6540303,2.6872058,2.7203813,2.7535567,2.7867322,2.8199077,2.8530831,2.8862586,2.919434,2.9526095,2.985785,3.0189605,3.052136,3.0853114,3.118487,3.1516623,3.1848378,3.2180133,3.2511888,3.2843642,3.3175397,3.3507152,3.3838906,3.417066,3.4502416,3.483417,3.5165925,3.549768,3.5829434,3.616119,3.6492944,3.6824698,3.7156453,3.7488208,3.7819963,3.8151717,3.8483472,3.8815227,3.9146981,3.9478736,3.981049,4.0142245,4.0474,4.0805755,4.113751,4.1469264,4.180102,4.2132773,4.246453,4.2796283,4.3128037,4.345979,4.3791547,4.41233,4.4455056,4.478681,4.5118566,4.545032,4.5782075,4.611383,4.6445584,4.677734,4.7109094,4.744085,4.7772603,4.810436,4.8436112,4.8767867,4.909962,4.9431376,4.976313,5.0094886,5.042664,5.0758395,5.109015,5.1421905,5.175366,5.2085414,5.241717,5.2748923,5.308068,5.3412433,5.3744187,5.407594,5.4407697,5.473945,5.5071206,5.540296,5.5734715,5.606647,5.6398225,5.672998,5.7061734,5.739349,5.7725244,5.8057,5.8388753,5.872051,5.905226,5.9384017,5.971577,6.0047526,6.037928,6.0711036,6.104279,6.1374545,6.17063,6.2038054,6.236981,6.2701564,6.303332,6.3365073,6.369683,6.4028583,6.4360337,6.469209,6.5023847,6.53556,6.5687356,6.601911,6.6350865,6.668262,6.7014375,6.734613,6.7677884,6.800964,6.8341393,6.867315,6.9004903,6.9336658,6.966841,7.0000167,7.033192,7.0663676,7.099543,7.1327186,7.165894,7.1990695,7.232245,7.2654204,7.298596,7.3317714,7.364947,7.3981223,7.431298,7.4644732,7.4976487,7.530824,7.5639997,7.597175,7.6303506,7.663526,7.6967015,7.729877,7.7630525,7.796228,7.8294034,7.862579,7.8957543,7.92893,7.9621053,7.9952807,8.028456,8.061631,8.094807,8.127982,8.161158,8.194333,8.227509,8.260684,8.2938595,8.327035,8.36021,8.393386,8.426561,8.459737
",1
318,"I am working with certain data arrays of float elements. Corresponding to each vector are other datapoints. I am able to save them as CSV files which encodes the arrays into string on which I run literal eval on subsequent reads. Now, this is a really inefficient way of working with this data as I have millions of such rows. I tried to use HDFStore as I needed append functionality of table mode but it refuses to store the column raising   
""TypeError:Cannot serialize the column \[encoding\] because its data contents are \[mixed\] object dtype"".

Any idea how to proceed?

Thanks",1
319,,1
320,"I hope this is the right place to post this....I was wondering if anyone could point me in the direction of a way to help visualize my data problem. I have a product that can be customized to a high degree. however certain choices aren't compatible with other choices. So I wanted to first of all enter the data in some sort of interface and then from that generate a set of rules from it.

Let's say the product is a kettle that can come in 10 colours. It also has 5 different options for handles, but maybe one handle doesn't come in one of the listed colours so that's an illegal combination.  The kettle also has different power button styles. But some of those buttons don't fit certain handles. It also has different power chords, but they're not all compatible with certain handles etc etc. And maybe there are 2 different plugs that fit certain cables. But you don't choose the plug. The system just selects the plug that fits the right cable. You get the idea. Basically lots of lists of what is compatible with what. 

I started to use free online mind-mapping software to draw connections between all the various bits because it leant itself to how I'm picturing the data in my head, but can't do much with that visual. Is there any software that you can recommend for my purpose? One that will allow me to generate rules that I could use in some custom software to allow only valid variants of the kettle? A nice GUI like mind mapping software would be great.

Essentially it's a whole bunch of IF statements but clearly I don't want to have to write them all out. Especially because there are about 20 of these 'kettles'. I just want some sort of list, or spreadsheet that holds all the data ultimately.",1
321,"if I run a neural network and save weights in keras using `model.save_weights`. For 100 epochs, will it save the weights for best training or validation accuracy or it will save the weights of the last epoch ie 99th epoch weights no matter what the accuracy is. Or will it save the average of accuracies of over 100 epochs(which one though training or validation accuracy)?. 

&amp;#x200B;",1
322,"So I've been at my current role for a little over 1.5 years.  Was hoping to stick it out a bit longer, but for various reasons it feels like it's time to start looking to move on.

I've gotten great experience at this job (first DS job after a PhD in bio and then the insight program) - modeling, SQL, EDA, NLP, and have become a much better coder.  But that only shows in the work I've done at this job.  

So I'm actually leaning toward removing my personal github from my resume this time around, because I have all this experience, and kinda don't want people to glance at my insight project from ~2 years ago and see all this clumsy code (it's not *terrible*, but a lot of that project was just painstaking recoding of messy data, and its certainly not as clean as I'd like.  There's also code for a web-app I built using flask, but I had no idea what I was doing there and am definitely not looking at jobs now that will require anything like that).

So do people agree that for getting interviews for a second job (hopefully senior DS position), showing off side projects is less important than actual experience?  Or will I get dinged for not having a link to actual code I've written?",1
323,"I recently completed a timed 3 hour coding challenge with a company.

&amp;#x200B;

The problem was that most of my analysis was shit. I spent maybe a good hour and half familiarizing myself with the data i.e. making distribution charts, doing "".describe()"", etc. I basically wasted a good chunk of my time trying to figure out if I could include more features, remove irrelevant observations ,etc. The dataset itself was also tricky so I was thinking of doing some other loss function i.e. the median was zero when the variable spanned \[0, inf\]. I was thinking of maybe trying out robust regression for this problem.

&amp;#x200B;

Before I started modeling, I then wanted to test if the assumptions were valid to employ regression.  All of this was in one big ass lazy notebook.

&amp;#x200B;

In the middle of all of this, I noticed I only had like 20 min. left and I didn't write anything down. I tried to clean up my notebook and made some random comments here and there. I did some garbage logistic regression and submitted it just as time was up. It's frustrating since I feel like I wasted a good majority of my time just thinking about the data. I'm 100% sure, I didn't pass.

&amp;#x200B;

What do you guys do?

&amp;#x200B;

What was the rookie mistake I made?

&amp;#x200B;

I NEVER want this to happen again.",1
324,"I see a lot of how do I do XYZ, or what approaches should I take questions on here. But I’ve also noticed a large portion that get deleted after they’ve been answered. Is that due to the mods of sub or are posters deleting their question? I’m leaning towards not answering these types of questions in general because of this type of behaviour but was curious as to why first. 

This is an example : 

https://www.reddit.com/r/datascience/comments/ap0e6r/need_some_direction/?st=JRYJX4I7&amp;sh=88a483e0",1
325,"What are some ways to list the following technical skills:

\-MS office

\-Python

\-R

\-SQL

\-Tableau

\-Bloomberg

&amp;#x200B;

I am always confused/clueless about how to split these! (programs, databases, etc. vs in one single line)",1
326,"As a fledgling, what should one listen to, to maximize the learning. Podcasts are a great way to learn and know what's going on currently in the indutstr, So for starters what are the best Data Science podcasts?",1
327,,1
328,"As a soon-to-be-graduating student of a masters in mathematics I've been looking for jobs that would allow me to actually use math/programming in my day to day routine. Obviously datascience came up pretty soon and it generally felt like a good fit for me.

In Europe though we don't have big tech, and looking around there seem to be more lucrative professions in the math/statistics field. For instance a career like the actuary seems to have a higher salary and demand here, whereas I understand that the converse is true for the US .

What I'm asking, especially to any data scientists active in Europe, is if there is any actual demand for people competent in machine-learning and other advanced statistical methods.",1
329,"I Checked Superset and it was impossible to make it work. Too many issues during installation. I also checked tableau but it is 70 Dollars a month. What I'm looking for doesn't need to be free but it is for a hobby and my own usage so something around 10 bucks a month. 

The stool I need should have: 

\- Integration with mySQL

\- Be able to build dashboards and play around with sports statistics.

\- Have different ways of presenting data (Tables, Graphics, etc) 

As context, I'm not using big data. In fact the maximum amount of records I'd be processing could go around 100k, and the average dashboard will have 1k records. 

What tools would you recommend?",1
330,"Hi everyone,  
I want to up my data science and programming skills (R) by doing a pet project where I get daily ( or weekly) data updates from either scraped data or API calls, or other sources.

I then want to do some sort of cleaning, transforming, analytics on the data and plotting it aswell.  
This should be re-run / updated whenever the data is updated, daily or weekly.

Do you have any good ideas for data sources (API, Websites, etc.) which I can use for such a pet-project?  
Any advice is highly appriciated!

Thank you in advance!

Best regards  
Dat\_Sci\_SAR",1
331,,1
332,"Hi all, I'm relatively new to Data science and have some experience in NLP, using language models for text classification. I've a task at work which basically involves intent classification of emails and was wondering if it's a solved problem? So far I've come across 2 annotated data sets, Enron and Avocado ([http://cs.ru.nl/\~msappelli/data/](http://cs.ru.nl/~msappelli/data/)). However it seems avocado is not free and costs quite a lot ($1500), also a look at different papers in this field indicates a variety of approaches, does anyone have a suggestion on how to go forward with my experimentation, given that our internal dataset does not have any labels as of now.

References: 

[https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/viewFile/17105/16016](https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/viewFile/17105/16016)

[https://github.com/ParakweetLabs/EmailIntentDataSet/wiki](https://github.com/ParakweetLabs/EmailIntentDataSet/wiki)

&amp;#x200B;",1
333,"Hi All,

I'm working on a case study where I have to come up with a solution to minimize the stock outs in a distribution center. Has anyone worked in supply chain related problems? it would be of great help if I can get some guidance.",1
334,"Using the web browser, I see that the image *alt* attribute contains tags as to what their image recognition tech believes the image contain. Any idea why they might be doing this?

https://i.redd.it/5y5fn4zfrmf21.png",1
335,"I post something similar on the BI sub but want to have/ get some discussions going with the DS folks as well:

I was talking to a BI professor and he said the BI field is basically a ""*rebranding*"" of *Statistics* (and elements of C*omputer Science*). Since BI and DS are so closely related together,  he also implied that the activities going on with BI (which include DS) *are nothing new* and ***have been going on for ages*** (i.e. now it's just a rebranding exercise):

* Do the DS folks here agree with his views?
* Do you think DS as well will be re-branded in future? (What do you think it will be?)",1
336,"I am new to data science and am trying to work on projects to learn interactively. I am working on a project trying to find coordinates of branches of stores. I am having trouble figuring out a way to get a list of the addresses easily. For example, if I wanted a list of Costco's in Texas, what would be the best way to go about getting the data set without like copy pasting from Google results or from their website search results? 

Once I have a data set of the addresses, I think using something like Google's Geocoding API would be the best for getting latitude and longitude coordinates. 

Thanks in advance for your help. Looking forward to working on DS projects. ",1
337,"I'm an MS student specializing in Data Science and an intern at a start up that has a way to predict revenue using a decision tree and it's really inaccurate. My task was to optimize the current model to make it more accurate, but I told them that I'll probably need to start over using a different algorithm. I am currently cleaning the data (there's a bunch of missing and inaccurate data, but I've managed to clean that up somewhat), and was wondering what type of algorithm I should be using for this? I've got almost 21 different attributes/possible predictors for the revenue for each type of transaction that was done. These include things like the type of service that was used for the transaction, the client, the start date and end date for each transaction, a minimum and maximum estimate of how many hours the person who was involved in doing the work for the transaction, the actual amount of hours it took, and many others. 

&amp;#x200B;

Basically, I want to be able to feed these predictors into the model as that data comes in, which will show that predicted revenue for the end of the month. Any ideas?",1
338,"Hello data friends! I just wanna check in and share my journey over the last few years. It's atypical, and maybe the outcome would not be ideal for some of you but I think it's just dandy for me.

I graduated in 2014 with a double major in theoretical mathematics and behavioral science. Note, that this left me with no applied math like stats, and deep understanding of calculus and a little topology. I struggled to break into the tech world, and wound up doing a lot of random jobs, from retail to manual labor. 


I discovered data science and machine learning through Andrew Ng's coursera in 2016. I did the Galvanize DSi in early 2017, after about six months of self-study. During the job search, I continued working in a labor field I really enjoy (not going into it here, but it involves music, climbing on steel beams 100+ ft in the air, and a lot of rope). I ended up finding some contracts that supplemented that income well, and enjoyed the variety for a bit over a year. One of those contracts required me to learn Golang for ETL work. The same contract had a few opportunities for interesting mini-projects, but nothing really deep or involving machine learning.


At the end of 2018, I asked my boss at that company what the possibilities were for me in 2019, and he was honest. It'd be more of the same, and he didn't have the time or money to offer me more training to focus on development. So, I resumed my job search.

Since then, I did 51 applications. Four responses, three phone interviews, and then something strange happened. I had gotten to the in-person interview at a major organization, and the Golang experience on my resume caught their attention. I was forwarded to an engineering division, did a phone interview, code interview, then finally flew out this week for in-person interviews. No immediate offer, but I was told to ""start packing"" by their director of engineering as I left the building. 

My title and pay will be as a mid-level engineer, but they're hoping I can act as their liaison between engineering and data science and I am BEYOND stoked for the challenge. As I said above, I imagine the more academic folks here wouldn't be satisfied with this outcome, but I couldn't be happier. I'll be moving to an area of the country I love, working on a huge variety of tasks, with opportunities to learn and go back to school. 


It was a long, frustrating road to get here. 100% worth it. I was described as ""a wild stallion, ready to come to pasture and be broken"" in the interview. Uncomfortable description, honestly, but entirely accurate. I've blazed my own trail, and it was scary and uncertain at times, but it's turned out well. 


Here's to all you weirdos! Keep trying! You can do it!",1
339,,1
340," Hi,

The idea behind *Black Swans Meetups* is that: if data-scientists meet with new data-scientists, they will discover wildly different (often better) approaches, models, etc., which can be applied to whatever they are working on.

Paul Erdős, the most prolific mathematician ever to have lived, recognised this. He was always travelling around, staying with different mathematicians who gave him new ideas to prove new theorems. His motto was “another roof, another proof”.

I imagine each meetup would be held in some capital city, and data-scientists could go to share ideas, give cool presentations about what they’re working on, etc.

Please comment below your thoughts. To learn more, go to: [www.blackswans.io/post/143](https://www.blackswans.io/post/143).

Jack",1
341,"Hello all,

(Note: haven’t taken calc or linear algebra-planning on learning that later-want to get some data analyst projects under my belt while I learn more advanced stuff

So right now I’m going through OpenIntro to Stats to brush up on my Stats knowledge. I’m just curious if there is any book at there, in Python, that goes over the tools for Python in data analysis. Also is there a book that goes through projects and tutorials just to get a hands on approach to implementing what I’m learning?

(Mocs, books, papers, etc all welcomes but books preferred)

Thanks Y’all!",1
342,,1
343,"I'm having a hard time cleaning up lots of inconsistencies in my dataset.

These are company name with formats like these:

McDonalds - McDo - Mc Donalds 

Guns and Fun - Guns n Fun

Golden Boy 112309 - Golden Boy 998635 - Golden Boy 214938

Century Hotel by Hotelier CA - Century Hotel by Hotelier NY - Century Hotel by Hotelier MA

&amp;#x200B;

Your suggestions will be greatly appreciated. Thank you.

&amp;#x200B;",1
344,,1
345,"Might be a dumb question... or not appropriate for this sub. But I was thinking deeply about this problem recently.

Is extrapolation ever a big concern for anyone here?

2 cases,

1) Due to realistic constraints, training data might not cover enough numerical range. So you might be extrapolating on some out-of-sample data.  

2) Even if you have a big training data, what if it's not covering a realistic numerical range for OOS data that is rare but can happen?",1
346,"```python
# Import keras
from keras.applications.resnet50 import ResNet50

# Download a weights in hd5 format
resnet = ResNet50(weights='imagenet')

# Import h5py
import h5py
path = '~/.keras/models/resnet50_weights_tf_dim_ordering_tf_kernels.h5'

# Load a file
f = h5py.File(path)

# List all the keys
list(f.keys())

# List all the layers in CNN
layers = f.attrs['layer_names']

weights = {}
# Get weights for all the layers
for layer_name in layers:
    g = f[layer_name]
    for weight_name in g.attrs['weight_names']:
        weight_value = g[weight_name].value
        name = str(weight_name).split(""'"")[1]
        weights[name] = weight_value
```",1
347,"I am a student, so I use pycharm community edition. Is there any mode, lib or anything enabling to work with cells comparable to Spyder or is the only way to upgrade to professional version?

&amp;#x200B;",1
348,"Hi-- I have a basic understanding of how to use Python to create a random forests model. I have some data that has a person's age, gender, location, and so forth (I do not have smoking status in my data), and I would like to be able to predict whether or not each person in a smoker. However, I don't have a dataset to train a model on. I am trying data.gov and most of what I see is already aggregated. Anyone know of another way to find data for this?

Thanks!",1
349,"I recently decided to pivot from a more BI career to a Data Scientist/Analyst career, in order to grow into a more senior role, responsible for data strategy and the like. To this end I decided to go back to school, get my pre-reqs and start a Masters in Statistics. 

However, even entry-level Calculus and Linear Algebra punished me and I had to basically give up, having learned that this was something I definitely did not have in me. I do feel that I'm intelligent, just not in the same way as someone who's very comfortable in Mathematics. Of course the Masters in Statistics is out of the question. 

Which of course bring me to my future career. Is there a place for someone who doesn't ""get"" Math easily? If so, how?
",1
350,,1
351,"Hey all,

I am looking at developing something with a text data set that's licensed with CC by NC (https://creativecommons.org/licenses/by-nc/4.0/) tl;dr: you can do anything you want with it, just no commercial products. 

How does that apply to something as vague as word embeddings or a trained model? I'm still developing myself as a professional and I'd rather stay on the safe side. I respect these boundaries, but I am really curious if there is some discourse on it and where the line is. ",1
352,"I would like to point out I'm an accounting major and never took a database management class. 

I work as an analyst for large company and I'm very comfortable in SQL(multi hundred line queries for whatever business needs) and comfortable in tableau. Now you may be thinking this isn't data science at all. But they interviewed me because I work on a good bit of R and Python projects myself and of course my reporting and analyst background. 

The two questions where I failed:

What is a window function in SQL?

What is the difference between a dimension table and a fact table?

I told them I wasn't so sure. I researched what it was and I do window functions every day at work and use dimension tables every day at work !!!! I was unbelievably mad when I read up on this when I didn't know the technical meanings and names of these things despite doing it every day. 

After I reflected on it it makes me think what if companies or people who train junior analysts just use different naming conventions ? What's the differnece of knowing what it means versus knowing how to do it?

Those questions came after I told them about my background in reporting and essentially being in SQL every day and telling them about my personal projects in R and python (R and python are something we don't use at my job at the moment)

Looking back on it I felt like those questions were kind of smug. After those questions they told me thank you and that they would be in touch. 

",1
353,"The title says it all....looking for the best and most up to date information. Many of the options listed on results for ""top data science blogs"" are for schools and boot camps that I assume are mostly just shilling for their own services. I'd also be interested in any recommendations for Twitter follows - TIA. ",1
354,"""**I can't delegate my learning to others**. If I think AI and big data are so important to being successful, then I should get off my butt, go back to school, and learn about them so I can understand them.""

Those are not the exact words of  Risto Siilasmaa, Chair of Nokia's Board of Directors, but they convey the main message of his interview posted on [lexinexis.com](https://www.lexisnexis.com/communities/lexisnexis_biz/b/bizblog/archive/2019/01/10/nokia-chair-offers-insights-into-artificial-intelligence.aspx)

It's one of the smarter posts about AI I've come across lately. I hope you enjoy.

P.S. After taking a few courses about AI and big data, Risto made sure that all of Nokia's 100,000+ employees were able to learn about those topics also.

&amp;#x200B;

&amp;#x200B;

https://i.redd.it/k8luwgyl09f21.jpg",1
355,"Hey all,

So today at work I was compiling the results of an investigation I had done to compare the predictive power of 8 different datasets, putting the score given to each dataset together into a scorecard. This scorecard is going to be presented by our company to a client where we recommend them a dataset to use. However, for two of the datasets I was told to use older versions of their scores, which were worse than the current results, because we didn't want to recommend those 2  datasets, because it would be better for our company's bottom line to recommend one of the other datasets instead.

&amp;#x200B;

As a relatively fresh face in the work force, I feel a bit troubled by this. Is this the reality of data science in the workplace? Should I just get used to this type of thing happening? I'd love to know any similar experiences others have had.",1
356,"I currently work as a BI developer/consultant. My daily tasks are doing ETL and data pipelines, building OLAP/tabular models and dashboards/reports on top of those models. I like what I do but I want become a Data Scientist in short-mid term, and for that, I've been doing some courses (doing Andrew Ng's Machine Learning from Coursera now). I already have some background in statistics, operational research and quantitative models, from University.

Recently I applied to some companies, and have had some interviews for Data Scientist role, but I was denied in all of them because of my technical skills. And that's why I am doing the courses.

The thing is, I have had a job offer to work as a Big Data Engineer. They offer me some time to learn things like Hadoop, HDFS, MapReduce, Hive, Spark, Cloudera, Impala, NoSQL and others related (I have zero experience on those).
On one hand, this seems like a good set of skills to have, but on the other hand, I may be deviating from my final objective, by leaning towards the data engineer role instead of data scientist. 

Does anyone around here know/use these skills on a daily basis? Do you think that accepting this job is a good idea or should I keep working on my DS skills and preparing for other interviews?",1
357,,1
358,"Almost all of my experience is doing things locally.  Eventually, I'll be deploying a machine learning model, but wanted to start with something simple.  

&amp;#x200B;

I have a function that takes a longitude and latitude and calculates the minimum distance from a shape file. I want to deploy this function to a web service so that anyone can use it. What would I need to do this? I've seen the plumbr package to create an API, but what's the best way to get the API on a web server instead of working locally?",1
359,"Working in data science space, I used to lose track of the numerous database connection strings, command lines &amp; edge node IP addresses I deal with and I found storing/copying/pasting from text files fidgety &amp; error prone with risk of over-typing. So I created SnippetFu to make storing and copying text snippets easy. It's an electron based multi-platform app which stores everything locally in your file system and has no network communication. Sharing under GPL v3 in case anyone else finds it useful. Issues &amp; pull requests welcome.

[https://github.com/srinathh/snippetfu](https://github.com/srinathh/snippetfu)",1
360,,1
361,"I need to explain various settings of sas enterprise miner, particularly a method in filter node, which removes outliers by finding a “modal center ” and taking only data that is N (value of N can be set manually, default is 9.0) “modal spacings” away from the modal center, and removes all data what is further away. I struggled to find some explanation, but the ONLY thing I found is this explanation from the book, but I still don’t understand how it works.[Modal Center Explanation ](https://imgur.com/a/zM4YMjR) 

Does somebody understand and can provide a more detailed explanation or an example? I don’t know what to do. Extensive googling yielded nothing other than this book.",1
362,"This is technically our homework, but the prof is simply asking for basic summary statistics and I want to go as far as I can to extract value and information from this data. Data is from UCI entitled Dresses\_Attribute\_Sales \[[https://archive.ics.uci.edu/ml/datasets/Dresses\_Attribute\_Sales](https://archive.ics.uci.edu/ml/datasets/Dresses_Attribute_Sales)\]. The gist of the data is that there's 500 entries, and around 13 features. Most of them are categorical, the only one that isn't  is the rating, which is from 1-5. Some categories though have a large amount of factors. At the end column, there's the recommendation (with binary factors) which leads me to believe that either this dress was recommended or not.

&amp;#x200B;

We've only discussed K-Means, and I don't see that being useful here. I've researched and saw Multiple Correspondence Analysis to reduce the dimensions of the features, but that apparently only works if all the features are categorical. Another teacher suggested I create bins for the only numerical data, and apply that, and go from there. Ultimately, my goal is to create a classifier that can classify a dress given features into a yes or no for recommendation.

&amp;#x200B;

I've also read another paper that proposes K-prototypes, but I'm afraid I didn't really understand it all very much, even after reading this medium article ([https://medium.com/@Chamanijks/k-prototype-in-clustering-mixed-attributes-e6907db91914](https://medium.com/@Chamanijks/k-prototype-in-clustering-mixed-attributes-e6907db91914)). I also read k-prototypes work for mixed data, but cannot have a null numerical data. The data set has, so I'm wondering how to approach that if ever. I have to admit I'm fairly new to all these algorithms as such.

&amp;#x200B;

I apologize if this is looked down upon, but I do want to hear some suggestions for how to proceed. Idk in fact if what I want is simple or complicated, but at least a general direction and I can research from there. Thanks!

&amp;#x200B;

EDIT: Turns out its only 20-ish factors for some categorical features.

Edit2:  just an update in case anyone else is reading this. Me and my partner opted to use MCA to reduce the features, and used a normal kmeans method to get clusters. Data is really messy, but 2 clusters still provides some decent insight. From the 500 instances, we clustered them into 2 - 460 set and a 40 set. It's not very representative coz from the mca, a lot of features and their corresponding factors are relatively close to each other. The other cluster tho revealed some profiles of that cluster that seems sufficiently different the bigger blob. I wanna thank everyone who helped and gave me insight on how to approach this. Thank you! :) ",1
363,I'm a rising senior considering working on an applied statistics project with a professor and I was interested in working on a project on TDA but I don't have the math background to fully understand it. I'm taking a Topology class next quarter but would that be enough to prepare for a TDA project in the fall? I've been programming in R for about a year but I'm not sure if Python would be better for TDA. Does anyone know any resources for an introduction to TDA that is not too math heavy and is more applications focused? I would really appreciate any help or suggestions. If this would be too difficult of a project for an undergrad then I'd consider NLP or nonlinear time series instead.,1
364,,1
365,"Hey guys,
I am an ECE undergrad doing his first steps in data science. As my first project, I'm trying to use ANNs to forecast hourly electricity price (HEP).

I have found various technical and fundamental factors that affect  HEP that I'll use as inputs, like load, RES Generation, Gas price, Residual demand etc.

Every paper I've read, the researchers also use lagged values of HEP as inputs. However, noone clearly states how they select which lagged values they use as inputs. Some say the use Taken's embedding theorem, others Autocorrelation and select those with high autocorrelation.

Honestly, I'm feeling a bit lost. Could you guys point me towards the right direction?

Further info: I'm planning on doing the project on Matlab (it's a university requirement) and i'll probably use a NARX (teacher's recommendation).",1
366,"I'm presenting at the University of Manchester (England) tomorrow to Mathematics / Computer Science undergraduates on behalf of my data science team (Finance sector) as we are hiring interns / placement students for the first time and want to drive some interest.

I've always found that the best way to open a talk is with an interesting fact. I've tried finding one that's both interesting &amp; up-to-date but struggling and thought I'd ask the question to the Reddit community..

**What fun fact do you know about Data Science?**

(Preferably with source as I don't want to accidentally lie to 100 Math graduates, mostly because someone will definitely call me out!)

One that I've found, but with a questionable source from 2016:

By 2020 humans will produce 12 million Gigabytes of data..every second.. and only 1% of it will ever be analysed.

&amp;#x200B;

**EDIT: Summary of comments**

Truth has a half-life of 45 years (half of what a physicians thought they knew about liver disease was wrong 45 years later.

Source: [http://reason.com/archives/2012/12/24/half-the-facts-you-know-are-probably-wro](http://reason.com/archives/2012/12/24/half-the-facts-you-know-are-probably-wro)

Early data science could have proven Newton's theory of gravitation before him

Source: [https://en.wikipedia.org/wiki/Kepler%27s\_laws\_of\_planetary\_motion](https://en.wikipedia.org/wiki/Kepler%27s_laws_of_planetary_motion) 

AI beat a Starcraft II professional team

Source:  [https://deepmind.com/blog/alphastar-mastering-real-time-strategy-game-starcraft-ii/](https://deepmind.com/blog/alphastar-mastering-real-time-strategy-game-starcraft-ii/) 

The online business transactions between businesses as well as individuals would amount to about 450 billion transactions per day 

Source:  [https://imarticus.org/some-interesting-facts-about-big-data/](https://imarticus.org/some-interesting-facts-about-big-data/) 

&amp;#x200B;

Bonus: Some fun facts about porn!

Source:  [https://www.psychologytoday.com/us/blog/all-about-sex/201803/surprising-new-data-the-world-s-most-popular-porn-site](https://www.psychologytoday.com/us/blog/all-about-sex/201803/surprising-new-data-the-world-s-most-popular-porn-site) 

&amp;#x200B;

&amp;#x200B;",1
367,"Hey all, I had some free time this weekend to work on a side project and I found a dataset containing details on every parking violation in Los Angeles from 2015-Present. As you can imagine, this was not a small .csv file (9-million rows x 19 columns of text and numbers), and to make matters worse most information that you'd want in their own columns as integer values (such as year, month, day) were all formatted as text and saved in a single column.

&amp;#x200B;

I wrote a program here: [https://stevebottos.github.io/jupnotes/LA%20Parking%20Violations%202018](https://stevebottos.github.io/jupnotes/LA%20Parking%20Violations%202018) (for some reason the embedded links are being finicky) that will:

* run through the full .csv in manageable batches, processing data as it goes along until it saves it all as a new .csv containing only 2018 values
* run through the smaller .csv containing the 2018 values only and re-format the data into new columns and data types
* produce an interactive map displaying where each incident took place
* produce visualizations: incidents per month, incident occurrence by hour, and incidents broken down by violation reason

I thought I'd share it here for those that might be interested, along with some shameless plugs to my Linkedin: [https://www.linkedin.com/in/stephen-bottos/](https://www.linkedin.com/in/stephen-bottos/) and website: [https://stevebottos.github.io/](https://stevebottos.github.io/) where you can find more projects of mine. Feel free to send me a connect request on LinkedIn, I'll endorse your skills if you endorse mine!",1
368,"My company has moved into the full AWS ecosystem, so most of our data sits in S3. I have a new dataset that is sitting there, and I'm trying to bring it into R (or Python, willing to look at all options), but the amount of time it takes to download these files into either an RStudio instance (EC2), or a Sagemaker notebook seem to be much slower than I expected. The way I was asked to run this is to run an Athena query and use PyAthena to download the data into each environement.

For reference, it's taking 45 seconds to bring in 100K rows with 24 columns - which seems really slow to me. Is there a faster way to do this? Would it be quicker to download directly from S3? Should I not be downloading the data period and leveraging some other way to access the data?",1
369,"This one's self-explanatory.

Are there many positions and is it a competitive market?

Is it on the rise/fall?

Is the pay good, taking cost of living into account?

Are jobs concentrated in any particular industry?

I think it would be helpful to have a thread per city, so get a thread going for your city if it doesn't already exist.",1
370,,1
371,"When it comes to cooking, especially trying out new recipes, I am kind of a perfectionist. The measures have to be correct every time, weighing things precisely to the gram etc. So much so that I have a hard time trusting new recipes and have to switch back to older ones I can trust. Of course, I try out new things, and perfect my recipes according to my taste.

So I was thinking, why isn't there a spread sheet of empirical findings in cooking, why is the effect of something (whipping cream or eggs for such and such time makes it X, using this amount of sugar makes it Y, leaving it on the other hand makes it Z.)

&amp;#x200B;

I kinda can draw similarities between the things I'm working on right now (Neural Networks) where you also have to empirically try out new things and observe the changes, in order to learn more about neural networks. Why not for cooking? I can see this to help with more individual recipes, based on your profile and taste.

What do you think?  Interested in building something like that? Interested in open-source as well as open to potential business opportunity.

&amp;#x200B;",1
372,"I've got a task which involves testing multiple interaction effects on binary and continuous variables, and I'm just wondering the best way to approach it. Basically I want to be able to say whether an interaction between two categories has a significant effect on the outcome.

The best way I know how to do this is with a linear and a logistic model, are there any other or better approaches I could use that take advantage of machine learning?",1
373,"Hi, I'm 9 months into my first job after my masters. I work in a management consulting company, where we are heavily reliant on data and are ""data science"" orientated (my day is primarily spent working on R). Things are, unfortunately, not going that well and so I'm looking for a new role. My confidence is taking a beating and I'm burning out and all round fairly miserable.

&amp;#x200B;

I think there are two problems for me. The first is that I am slow at solving problems, whether they be debugging or finding the best approach to my analysis. I also tend to make mistakes and have a high rate of copy/paste errors, where I forget to change variable names etc. The second issue is a little more specific to me: I am a native english speaker, with basically no formal education in French (I essentially learned French with housemates during my masters), yet I work in a French speaking firm, where all communication with all colleagues is via French. I have gone entire weeks without a single conversation in English. As you can imagine, this burns up a significant amount of brain power and so it is difficult to parse out how much of my current situation is down to me just being a bad data guy, and how much is because I've gotten myself into the ridiculous position of working in a language I'm still learning.

&amp;#x200B;

I don't have any questions as such, but I was hoping to just get a bit of external perspective. My best talents have always been at the ""softer"" end of the spectrum (decent at maths, excellent at writing essays), so maybe it's just time to bow out, knowing I gave it a good whack? At the same time, there are lots of stuff about data science that I do enjoy. I'd be grateful for your thoughts!

EDIT 2:

Got the official word the other day that I am being let go. In some ways it's a relief to be out of such a crushing environment. And my contract is until April, so I have all that time to find a new role and upskill. Thanks for all the comments and perspectives, it definitely helped ease the blow and help me retain some confidence.

&amp;#x200B;

EDIT: Just to address a couple of points that came up a few times

\- Many of you have basically said, ""chill out, get a new job if you have to, but don't quit the field"". I have definitely considered this, but like I said,  it has been hard to parse out the French part vs my own skill level (and as has been mentioned, management consulting, which I hadn't considered before). My big take away from your comments is that the language and industry probably play a pretty big role in making things difficult and that there's no need to leave the industry. That's great news!

\- In terms of my perception vs my boss' perception: We have had some conversations where the feedback hasn't been awful, but there's been heavy emphasis on the room for (fast) development . My contract terminates in April, upon which I will either be offered a full permanent contract, or be let go (French law dictates that), and so I will actually be having a meeting with my boss soon to discuss my future in the firm. However, all that being said, I fully accept that my perception of the situation is very possibly worse than my manager's.

\- Regarding the French, I wouldn't expect to speak French in a Dublin or London office if a French person wasn't 100% comfortable speaking english, so I don't see why it should be the other way around (nor would my colleagues). And while, as was pointed out, english is indeed a valuable skill for some of our clients, the deal is you have to be able to work on any project in our firm, meaning being capable of talking with both english and french speaking clients, which to be honest, I think is fair enough. In terms of improving, speaking a bit more or asking for help isn't really an option, I am literally swimming in French for 45+ hours a week and I usually speak french with my flat mates, so it's not as if I can make more of an effort- I'm already flat out! Classes are of course an option, but I also need to eat, sleep and be human at some point.

&amp;#x200B;

Finally, thanks a lot for sharing your thoughts: It's helpful and appreciated.",1
374,,1
375,"I've been working with commercial insurance data and 90% of the data is 0. The goal is to predict the ""Pure Premium"", which is the amount of the insurance claim divided by the exposure of the product (Value of the building in my case). The data is spread among multiple years with some years having higher losses than others.  A lot of the data I'm dealing with is categorical or discrete data such as Year Built, Number of Stories.

&amp;#x200B;

Here's what I've done so far:

&amp;#x200B;

**Data Workup:**

* Truncate the data to remove anything above the 85th percentile
* Split Training/Testing by year so both sets include a ""bad"" year
* Binned discrete data so each category has equal amount of exposure
* Kept NULL data points as an additional ""Unknown"" category

**Models:**

* Poisson log-linked GLM
* Tweedie log-linked GLM (Using ""tweedie"" R package"")
* Poisson log-linked Elastic Net GLM (Using ""glmnet"" R package)
* Tweedie log-linked Elastic Net (Using ""HDtweedie"" R package)
* Tweedie GBM (Using ""TDboost"" package)
* Extreme GBM

**Model Performance (In order of what I looked at):**

* Maximizing Gini Coefficient
* Maximizing deviance ratio (1- Model Deviance/ Null Deviance)
* minimizing RMSE
* Model Complexity via Degrees of Freedom
* minimizing AIC

The tweedie based packages are hard to extract information out of, so it's hard to compare each model. For instance, I can't figure out how to get deviance ratio from the Tweedie ENET, but can get RMSE and gini.  Poisson ENET performed the best GINI, but had worse RMSE and DF.  The Tweedie ENET had a lower RMSE, but also lower gini.

&amp;#x200B;

Another problem is that when I bin the ordinal discrete data such as ""Year Built"", it loses the monotonic assumption so can lead to some non-intuitive coefficients. Also, I haven't been doing any cross validation, just running a model and just testing it on the hold out. Should I be doing CV even though most are 0?

&amp;#x200B;

Most of the research I've done is using Actuarial and insurance books and most of them suggest using the Tweedie distribution. What else can I do to improve the model?",1
376,"In the future, which of those fields will be hotter and sport a higher salary.",1
377,,1
378,"Welcome to this week's 'Entering &amp; Transitioning' thread!

This thread is a weekly sticky post meant for any questions about getting started, studying, or transitioning into the data science field.

This includes questions around learning and transitioning such as:

* **Learning resources** (e.g., books, tutorials, videos)
* **Traditional education** (e.g., schools, degrees, electives)
* **Alternative education** (e.g., online courses, bootcamps)
* **Career questions** (e.g., resumes, applying, career prospects)
* **Elementary questions** (e.g., where to start, what next)

We encourage practicing Data Scientists to visit this thread often and sort by new.

You can find the last thread here:

[https://www.reddit.com/r/datascience/comments/al0k5n/weekly\_entering\_transitioning\_thread\_questions/](https://www.reddit.com/r/datascience/comments/al0k5n/weekly_entering_transitioning_thread_questions/)",1
379,,1
380,"Hello all! I'm terribly sorry if this question is beneath the scope of this sub. But, I couldn't seem to find the answer via standard google searches.


I'm a graduate student studying data science. As such, I've been applying to pure ""data scientist"" roles. But, I was recently contacted by a consulting company (Accenture) and was asked to interview for Data Science Consultant / Data Management Consultant roles. I have a few friends who are consultants for companies like EY, and they seem to spend 75% of their time traveling and presenting pie charts. Not really what I had in mind for my own career path.


I was wondering if any of you wonderful folk could explain to me exactly what a ""data science consultant"" does on a day-to-day basis, how one would spend an average week on the job?",1
381,"Welcome to this week's entering &amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)  
* Traditional education (e.g. schools, degrees, electives)  
* Alternative education (e.g. online courses, bootcamps)  
* Job search questions (e.g. resumes, applying, career prospects)  
* Elementary questions (e.g. where to start, what next)  

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](https://www.reddit.com/r/datascience/wiki/resources) pages on our wiki.  

[You can also search for past weekly threads here](https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;restrict_sr=1&amp;t=month).

^(Last configured: 2019-02-17 09:32 AM EDT)
",1
382,"Welcome to this week's entering &amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)  
* Traditional education (e.g. schools, degrees, electives)  
* Alternative education (e.g. online courses, bootcamps)  
* Job search questions (e.g. resumes, applying, career prospects)  
* Elementary questions (e.g. where to start, what next)  

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](https://www.reddit.com/r/datascience/wiki/resources) pages on our wiki.  

[You can also search for past weekly threads here](https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;restrict_sr=1&amp;t=month).

^(Last configured: 2019-02-17 09:32 AM EDT)
",1
383,,1
384,"Hello everyone,

The project is called Deep Learner. This is a project my and my friends worked on during one of the Hackathons I thought it would be appropriate for this sub. The purpose of this project is to allow people prototype Deep Neural networks very very quickly and with writing 0 lines of code. For now you can only build regular dense networks. It also allows for data visualization using Tableau and you can also save models in json format. Please note this is very much work in progress and was made by 4 college students in 24 hours, so there will be bugs. We decided to make this open source, so you are more than welcome to contribute, I have posted a couple issues on github so feel free to contribute.  We are hoping to expand on it in the near future.

[Deep Learner](https://github.com/GioLomia/Deep_Learner)

Let me know if you have any questions &lt;3.",1
385,,1
386,"Currently, I'm working as as a Customer Service Rep at some company. Would love the feedback as I make the transition and can answer any questions regarding my background.

Here is Resume Part 1: https://imgur.com/LJ0fECB

Here is Resume Part 2: https://imgur.com/oJ9MsdZ

Edit: I will upload a Resume Part 3: The One Page Resume By Tomorrow Morning. Thank you for the feedback so far.

Resume Part 3: https://imgur.com/gv21B2P
This resume is 1 page. Thank you for the feedback!",1
387,"A lot of companies are creating new data science departments.
But everyone has their own understanding of data science.

Some think it is a data centric platform (combination of data lakes , data warehouse, Kafka streams), while some others think this is statistics and machine learning .. while there are othersothers who collectively call Data lakes, model programing and big data as data science.

How does your company view a data science department ?",1
388,"My employer, which is a big tech company, just launched a coding challenge for analyzing internal trouble tickets to find a way to reduce costs by reducing the number of unnecessary tickets. The challenge problem is worded in a way that's pretty obvious that they are looking for something along machine learning, though they didn't use the word explicitly.

I spent the last few months learning as much as I could (I have no CS, statistics or math background) about data science, machine learning and text analytics. I came to the conclusion that, machine learning is not cut out for this kind of task without tremendous investment - in time, money and quality training data. I submitted my solution for the challenge using other non-AI techniques, but I'm still wondering whether my assessment of the challenge was ""in the ballpark"".

Basically, the data provided to us for the challenge consists of about 2000 trouble tickets from one particular support department, including all the notes and some slightly higher quality summaries written by the technician at the end of support. 

Without any machine learning, I was able to tell simply by analyzing the n-gram frequency what the most common type of tickets are. Then based on those summary texts and the keywords I categorized the tickets. I suppose if there are enough data (maybe in the tens of thousands), a ML model can be trained to do the same categorization with some 90+% accuracy, but since the data set is way too small, and there's no consistent and reliable tagging on the data, I didn't even attempt it (but perhaps 2000 is not too small?). 

Either way, the real challenge comes after the initial broad classification. The biggest category (including false positives) from my own method contains just over 100 tickets, and under that category, there are a lot of different types of issues (we have a very complex environment). That's not gonna be enough data for any sort of machine learning to properly classify further. Besides, how do we know what are all the types of issues to even create the classes?

So I again used n-gram frequency to find common topics and again used keywords to classify. Was I able to come up with suggestions on how to reduce tickets? Yes, lots of them. Did I use any cutting edge, buzzword technologies? No. Maybe the management is looking for the cutting edge buzzword solutions to help sell out, but I don't think ML, DL, NB or whatever is going to help us here. I have also tried topic modeling, but the output from that was 60% to 80% garbage. I think I know why - trouble tickets note are extremely abstract, with key information hidden in just a couple of words, versus more natural conversations between people which are less abstract (people don't typically talk like dorks). Lastly, I have attempted word association, but the outcome was  pretty much tautology - it just reflects the n-gram frequency analysis.

Of course I want to win the challenge, but my bigger concern is whether the company is heading the right direction - it seems like people are hyped about ML and just want to ride the hype train as far as they can before it runs out of fuel. I believe ML is a wonderful tool on its own, but it's not snake oil. I don't think it can be very helpful in extracting answers to ""why"" from text data of moderate size. With my limited knowledge, it seems like they are asking to first predict whether a ticket can be avoided, and then maybe some unsupervised clustering of all the tickets that can be avoided, it just feels like there's no clarity like the problem of ""recognizing street numbers from photos"".

However I would like to hear your opinion and you experience :) Thank you!",1
389,"I feel like this sub only recommends a degree in statistics or CS for budding data scientists (I literally have not seen a single person on this sub recommend ""get a degree in physics""). But it seems like most tech companies don't really give a crap what the candidate's degree is as long as its quantitative. Some examples of degree requirements for data science roles at top tech companies include:

[Google](https://careers.google.com/jobs/results/6033539515744256-data-scientist-engineering/):

&gt;Master's degree in a quantitative discipline (e.g., Statistics, Operations Research, Bioinformatics, Economics, Computational Biology, Computer Science, Mathematics, Physics, Electrical Engineering, Industrial Engineering)  

[Netflix](https://jobs.netflix.com/jobs/868431):

&gt; Ph.D. in Computer Science, Statistics, Physics, or related quantitative field

[eBay](https://jobs.ebayinc.com/job/-/-/403/11381186):

&gt;Strong quantitative background with Bachelor’s degree in Computer Science, Math, Economics, Physics, Engineering, or related.  

[Amazon](https://www.amazon.jobs/en/jobs/750795/data-scientist):

&gt; MS in a quantitative discipline such as Statistics, Mathematics, Physics, Engineering, Computer Science or Economics 

[Facebook](https://www.facebook.com/careers/jobs/205743826659289/):

&gt; BA/BS in Computer Science, Math, Physics, Engineering, Statistics or other technical field. 

So it seems like in terms of degree, a degree in math, physics, economics or engineering should (at least in theory) be competitive with CS and Stats people. So why do people here automatically say get a degree in CS or statistics for a data science role? Or to put it another way: why do top tech companies not put as much emphasis on a degree in CS or statistics as expected? Seems like they just emphasize the ""quantitative"" part.",1
390,"Hi all.

&amp;#x200B;

I'm here to ask you a question about what should I do regarding my future (hope this is the correct place, if not feel free to tell me where should I post a question like this). Sorry all if my English isn't perfect.

&amp;#x200B;

I'm a student who's going to complete his first degree cycle in Mathematics. Here where I live (Italy), after this first cycle of three years I should go for a second cycle of two more years. I could continue with a course in Mathematics, but I'm starting to think about taking a course in Data science instead. I'm still a lot dubious about this and I would appreciate some help.

&amp;#x200B;

First of all the reason I'm considering the option to change is because of job stability. Continuing with Mathematics would mean trying an academic career, which it happens to be a lot more difficult and less rewarding the more I'm close to it. I definitely love Mathematics and I could also say I'm pretty good at it (not a genius anyway, obviously), but the idea of basing my future upon a risk (you never know if you're actually going to obtain some good results which could open up my way) and of passing a lot of years through not stable jobs, until I can finally become a stable researcher / professor (which is not guaranteed anyway) is starting to make me want to try others ways.

&amp;#x200B;

And so I'm thinking about Data science. I must say that I like Data science, it wouldn't just be for career, statistics has always been something that attracted me. But I like Mathematics more, so choosing Data science would be primary for my future. Still I want to be sure. Obviously I'm looking forward two things: salary and, more importantly, stability. I want to be sure that Data science would actually guarantee me a stable job. If not a stable job at least a stable career, meaning that if I lose my job I wouldn't have many problems finding another one. Moreover I'm planning to move away from my country and I would like to know how much this could be an obstacle.

&amp;#x200B;

In the end is it worth taking a course in Data science regarding the stability of my future? Can I be sure that by studying this subject I could stop worrying about the uncertainty of my job?

&amp;#x200B;

Thank you all for the help.",1
391,"I have a non-quantitative BS and will start a MSCS in the Fall but looking at my program’s curriculum and class syllabi, it does not seem to demand any advanced math. 

Machine learning and Deep learning courses are available but they don’t appear to have a strong theory emphasis. Looks like math is taught in an ad hoc manner. I want to go beyond the scope of my curriculum.

I’d like to be able to understand the average machine learning paper without spending hours on the side trying to learn maths I’ve never seen before. However, I do not need to be able to understand bleeding-edge machine learning papers. 

My current road math:

**Discrete math (propositional/first order logic, relations, mod arithmetic, intro graph theory, mathematical induction and proofs)

**Multivariate calculus

**Applied linear algebra (perpendicular frames, 3D matrices, SVD analysis, matrix diagonalization, Spectal Theorem, Root-Mean Square approximation, etc.)

**Intro to probability (probability spaces, random variables, stochastic independence, special distributions, limit theorems, etc.)

**Statistical theory (estimation, best tests, Rao-Cramer inequality, multivariate normal distribution, nonparametric methods, etc.)

Would this suffice as a good enough mathematical base (i.e. be able to derive new needed math quickly)?

If not, what should I add / topics I need to formally cover?

Real analysis?
More Stat courses?



",1
392,"So my company offered to sponsor me for a Data Science certificate, since I will be the only one without a masters degree in the data science team and they want me to at least have a certification or some sort of qualification.

I am planning on making this job my stepping stone; get enough on job experience and see what happens from there. I want something that will also help my CV in the future (a year or two from now)

My allocated budget for this is around $2500-2700, so any suggestions?",1
393,"Does anyone here have an opinion on using Golang for data science? My engineering department is thinking of changing infrastructure to go. As a Python/R guy, I'm being asked to code final production grade models to be integrated directly in the production code base.

Any thoughts on Golang in data science?",1
394,"Hi,

&amp;#x200B;

Since completing my Masters in Data Science, I have had a number of people contact me asking for my experience with the course and whether it is worth recommending. Therefore, I thought it best to summarise my decision for starting the course, what I have achieved during my studies, and the outcome in the years following. I created this article for Medium but thought it would be good to post it here as well to help discussions as I often see questions about Data Science Masters and whether they are worth it. 

### Why did I choose to study Data Science?

It was the spring of 2016 and I was coming towards the end of a 6 month internship at one of the largest consulting firms in the City of London. I had taken this role to gain experience and figure out whether becoming an Actuary was the correct route for my career. I quickly found passion in the data analytics of the role as I was being pulled into meetings to discuss numbers I had crunched or was able hack together a tool to automate previously manual tasks. However, I also found that the traditional track I would be heading on if I moved onto the graduate scheme no longer interested me due to years of standardised exams and little to no creativity. Furthermore, most of my work at this point was within Excel and I was gaining little to no coding experience.

It was at this point I also started to explore a magical term that kept coming up in my job searches: *Data Science*. I had come from a background in mathematics and, due to the nature of the job market in the UK, had been nudged towards the well-founded traditional roles such as accountancy and actuarial consulting. And yet, here was a new role that defied all the expectations I had set for myself of my future career. Where becoming an Actuary I would be solving problems by learning regulatory standards, Data Scientists are encouraged to creatively find solutions that fit within the commercial environment. Furthermore, the role opportunities were no longer fixed into a few select firms but almost all companies were looking for some variation of a Data Scientist and the idea that I could move into a completely new industry, from fashion to finance, greatly appealed to my interests.

However, as I started to apply for Data Science roles it quickly became apparent that **I was lacking two key skills: applying Machine Learning and coding.**

### What were my options?

The first solution was to simply teach these myself, I had the statistical experience to learn machine learning and had done enough coding in MatLab to feel confident that I could learn Python or R. However, if I was to do these I was unsure if this was enough and how I would clearly demonstrate my newly acquired skills on a CV to employers.

I considered online boot camps but they were often fixed in their content and I was unsure of how repeating someone else’s work would be received by employers. Furthermore, there was no guarantee that these were credible to employers and were expensive to self fund. Today, only three years later, the list of courses supported by universities makes this much more of a viable option and is something that is definitely worth considering but at the time these were lacking. Unfortunately, boot camps were a costly risk that I was uncertain would pay off.

Therefore, I decided to look for the options available at universities. At the time there were two types of courses that fit within my goals; business analysts courses and computer science machine learning. The former focused on applying analytics within commercial environments but, as this was run through business schools, was far more expensive at over £25,000 for one year of studying. The latter provided the teaching through academic research and focused more on teaching the underlying theory than the application. Furthermore, as this was an academic course run through the Computer Science department, the cost was considerably less for the year at £9,000 (for UK citizen).

### What did I choose?

In the end, I decided to play it safe and commit a full year to the academic masters in the hope that I would gain the applied knowledge in machine learning and develop my coding skills through project work.

Therefore, I joined the 2016/17 cohort of the Data Science MSc at City, University of London’s Computer Science department. This was the second year the course was offered at this university and, at the time, was the only university in London that offered a Data Science Masters (though others had some variations of this).

### What did I learn in the course?

The first term consisted of the three main topics of Data Science: fundamentals of data science, machine learning and visualisations. Each module consisted of a coursework component that we were given a choice of any publicly available dataset to apply our newly learned methods on. With these, I was quickly able to improving my coding skills and even built the confidence to start sharing [these projects publicly](https://www.philiposbornedata.com/2017/06/27/test/).

In the second term we had two core modules, Big Data and Neural Computing, and were given the choice of two optional modules. The list of options was comprehensive and enabled us to pick specialisms from computer vision to data architectures. I chose Data Visualisations (a continuation of the first term’s module) and Software Agents (the basics of AI by applying Reinforcement Learning). Again, these modules included coursework and with the fundamentals from the first term, I was really able to expand my applications and think creatively. Big Data also introduced text data and natural language processing.

Over the two terms, I had been given a broad overview of most of the Data Science topics and had a deep knowledge of Machine Learning and Neural Networks from the core modules. As we moved into the first component of the course, the dissertation, we were given the choice to complete this whilst in an internship role (and be provided an extension on the deadline to account for balancing whilst working). I found a suitable role, defined my research topic and over the following months applied all the skills I had gained so far towards [applying AI within business](https://www.philiposbornedata.com/2018/03/09/masters-thesis-summary-constructing-a-narrative-using-markov-decision-processes-applied-to-data-visualisations/).

### Did I gain the skills I needed from the course?

I had two goals to achieve; to demonstrate that I understand machine learning and apply these with coding. The course not only provided a clear ‘box tick’ against these on my CV but enabled me to continue to expand my skills after with more and more interesting projects. Part of any job application is to get past the initial checks and I was now doing this much more consistently. Furthermore, as I moved into interview stages, I had all these project to discuss and truly demonstrate confidence in my understanding far more than I would have achieved on my own.

The Masters opened up all the doors that I had previously been knocking on and even had recruiters contacting me directly following the projects I had posted publicly. In the end, I found that I enjoyed the research aspect of my dissertation and the freedom to pursue the field and have since move onto a PhD in Artificial Intelligence. Ironically, this is the last thing I would have considered back in 2016 but as the field is constantly expanding it is incredible to be at the forefront of this, particularly because many problems require an applied mindset and fit within commercial problems and are not simply theoretical.

### What advice would I give to someone considering moving into Data Science?

This is always a hard question for me to answer as each person’s position is different so will try to offer some advice based on my experience. In short:

1. **Establish** that Data Science is the right route for you and find a topic or detail to motivate this. For me, it was the ability to apply data analytics in a creative way and become a valuable asset in a business to help others improve their decisions.
2. **Evaluate** what the jobs you want are asking for and where your set of skills currently fall short. Although I had the technical background, I had not demonstrated my ability to apply machine learning or code and needed something to achieve this. For others on my course, they had not come from maths or stats backgrounds and so needed these to strengthen their knowledge.
3. **Review** the options available to you to gain these missing skills. For example, boot camps are increasingly more credible in the industry but they are often following a single path (i.e. learn on the same data and apply the same methods). This may work for some but I wanted to demonstrate my abilities in unique ways to stand out to employers. If you are considering a masters, thoroughly research the modules and who is organising the course as variations will exists between different departments, particularly business and academic schools.
4. **Expand and challenge** yourself through the course, don’t simply pick a course that covers topics you are already comfortable with to tick a box. Find something challenging that will encourage you to develop new skills.
5. **Demonstrate** your new skills by publishing your projects online, either through GitHub or Kaggle or your own site. Building a portfolio of project has taken me further in any interview than trying to describe these within the time limit would allow.

&amp;#x200B;

I hope you find this post useful if you are considering how to get into data science and will do my best to answer any questions you have about this. Am UK time so will most likely reply to questions tomorrow morning when I have some time. 

Thanks",1
395,"I work for a small company with a 2 person data science team. The data we use is not massive (largest analysis datasets typically in the millions). At this point we're still using our laptops to train models and so forth.

One of my goals this year is getting us off our laptops. Our DS tech stack is basically a Redshift database and we do analysis/run models in Python (scripts/packages for production stuff, Jupyter for adhoc). Everything is in Github.

Our company uses AWS so we have access to all those tools. We do have some scheduled workflows that run on EC2 instances currently. I am really looking for a solution that allows us to maintain similar flexibility and ease of use as the laptops, but can offer much better computing power. And also can provide Jupyter support for easy development. I want to move a lot of workflows to Airflow as well so something that would work well with all of that would be great.

What would you recommend?",1
396,"Tomorrow I'm interviewing [Anand Mariappan](https://twitter.com/anandraghu?lang=ca) (Reddit's Senior Director of Engineering - Data Science, Search &amp; ML) at a tech festival in Berlin.

I would like to ask him some challenging questions, like how are they using ML to deal with hate content, or why is still better to search ""reddit x"" on Google than to search ""x"" on reddit.

What are some other interesting questions for him? I promise I will update with the answers &amp; main take aways from the conversation!",1
397,"Apologize in advance if this belongs in weekly ask. 

Do you in general care about a candidate's thesis project for master program when hiring? 

&amp;#x200B;

I'm brainstorming thesis topics for MS in applied stats. Ideally I'd like to work on something implementable in the future and I have the following ideas:

1. Anomaly detection - I work in healthcare and often the targeted conditions are rare events
2. Method to ""combat"" imbalanced data - same as above but different approach (maybe combine both?)
3. Method for Generating Measurements and Weighting of each measurement -   
This happens often in business when trying to rank/group something without statistical training. They just come up with a model that take multiple measures. I'm just hoping to study ways to do this in a more scientific way by looking at 1. methods to come up with measures 2. methods to standardize measures so they are comparable 3. weighting them in a scientific method to come up with final model

&amp;#x200B;

Looking for brutally honest comments/criticisms. I'm also not sure if master thesis is about demonstrating my knowledge or about coming up with new methods. I certainly don't believe I can invent new things. 

I feel like #3 is ridiculous, but 1 &amp; 2 have probably be worked on or even ""solved"". 

Thank you so much for your time. I have never done this before so just any kind of direction would be really helpful.",1
398,"Me current: 

32 years old,  BA in Philosophy/Psych, M.Ed Curriculum and Instruction, Certificate in Educational Measurement (some applied ed research stats). 11 years in educational program evaluation, data collection and management. Also woefully never took math past HS precalc. 

I've read every thread on here and r/statistics. I am maybe 75% convinced I couldn't possibly get into a data science role even if I self-studied for a few years while working. I've been applying for analyst roles at a paycut and I'm having a terrible time- I get some calls but no bites. Now, people talk about portfolios and experience, but I'm pretty certain there is no way I could get a FANG job without more formal education.

But now I'm reading things that make me think even if took the dive and I spent 2-3 years studying full time for a dual MS in computer science and statistics would still leave me with a relatively low % shot of getting the kind of job I want.

Can someone give me some tough love and/or hope before I start thinking seriously about putting myself 40k in the hole going back to grad school?

&amp;#x200B;

&amp;#x200B;

&amp;#x200B;",1
399,"As a novice Data Scientists with alot of ambition and questions i thought it might be a useful idea to pitch an idea of a mentor mentee scheme for us data scientists. If youre an experienced data scientists who wants to help a beginner out you'd be making alot of people ecstatic.

That being said. 

I live in london, been working in Data Science for a year and a half, looking to do a masters in machine learning and hopefully envision a career in ML.

If you think you can help feel free to message me.

I hope this becomes a thing, lets better the Data Science community !",1
400,"Not sure if this is the right place to post, but here we go. So I graduated from college 4 months ago and I'm still searching for a job as a data scientist/analyst. A few days ago I got rejected from a job I **really** wanted (after the final round) and it crushed me, but I've been applying to other jobs, hoping I can get some interviews. Being unemployed is driving me crazy, especially since all my friends are either in school or have jobs and I'm in this limbo, still waiting for something to happen. Anyway, I could really use some words of encouragement/advice to keep me going. Thanks!",1
401,"Hi I'm hank and I'm an aspiring data scientist. I'm starting my transition into the field. I've taken a few courses on python, r, ml, and dl at nycdsa and wanted to continue my studying but found it hard on my own. 

I'm looking to see if there were any other aspiring dscientists in my position and wanted to essentially study together and keep each other accountable! 

",1
402,"I'm looking to break into the Data Science field and currently interviewing with a few companies, but I feel I lack certain edge because I don't have much to showcase (very little work exp). So I decided to start by working on mini-projects and putting them up on Github. I started with something really simple but I feel like I could do a lot better than that just Excel charts. So here are some of my questions about github projects.

* **The data part:** Do you (1) think of a problem and then find relevant data-sets or (2) look through a list of available data sets and pick one that piques your interest? So far I have tried method (1) but often I don't find data in a desirable formats or anything close. 
In this case, are there tools I can leverage that can collect data from websites and convert them into CSV or something (guess this is called scraping)? 
If method (2) is ideal for a newbie like me, where's the best place to find data to work on. 

* **The visualization part:** While creating killer visuals using R and Tableau is my goal, I'd like to, in the short run, be able to use online tools to quickly show, say, a pie chart or a bar graph (or maybe a combo of both) of an interesting trend I found. Any advice here?

Not entirely sure if these questions are valid or if the expectations are realistic, but feel free to put me in my place, if required. I'm here to learn. Any other advice you'd like to give me about getting some projects off the ground, feel free to comment or PM me. Thanks in advance!",1
403,,1
404,"Hi all, I'm a data science student working on various projects using biometric data. I've recently decided to start a blog to 1) get better at communicating findings effectively 2) give people a little bit of a look into data science and 3)have a platform in which I can discuss and share things I learn, problems I run into, and findings.   


Anybody have some tips for how to keep it interesting and/or manageable? Any advice is appreciated!   


I'll link it here if anyone is interested; but right now I just have an introductory post.  
 [https://blogs.valpo.edu/datadays/](https://blogs.valpo.edu/datadays/)   


Thanks!",1
405,,1
406,"My dad runs a small/medium business (about 50-100 employees) which handles payments for construction workers. I'm a statistics master's student and constantly telling him how data is revolutionising how businesses are run but besides obvious examples like Facebook, Netflix, Amazon etc., I'm finding it hard to come up with answers to his questions about how exactly data can be so revolutionary (especially given I have no business experience myself).

&amp;#x200B;

What are some low hanging fruit for utilising data for small businesses? And is it worth suggesting he look into hiring a data consultant?",1
407,"The first question we had for the panel came courtesy of /u/RyBread7:

**""What are the qualities or traits which differentiate good data scientists from the best data scientists? How, if at all, can these traits be learned or acquired?""**


Panelist Answers:
_______________________________________________________
/u/creampuffcrusader:

The best data scientists I've worked with had these two traits:

**A deeply rooted paranoia about data quality.**

Starting out a project by trying to replicate KPIs and current domain knowledge before jumping into the new and exciting work. Talking to stewards of the data about any quirks they ran into and taking the time to understand the data generating process. This can be learned either from mentor-ship or from experience. For me personally - it was combination of both mentorship and collecting battle scars.

**Holding themselves to the scientific method***

I had a mentor who was a data scientist before it was cool. He started the quantitative supply chain practice at the firm I work in back when the data scientist equivalent position was called Principal Analyst. He had this motto when interviewing stakeholders:

Tribal knowledge is a hypothesis unless there is evidence.
He had this uncanny ability of organizing knowledge by what has been verified, what can be verified, and what is interesting but maybe out of scope or not testable. And using this categorization to efficiently guide us to a quality analysis or product. Really - he was just very strictly holding himself and his team to the scientific method. It was remarkable.

This trait can definitely be learned. But it takes patience and experience.

_______________________________________________________
/u/amadeusmagrabi:

In my experience, the best data scientists are the ones who have **an intrinsic drive to deliver value for the business** and are **able to think outside the box to make sure that the whole team has the highest impact.**

Good data scientists ask their manager what the project requirements are, do their research, deliver a clean and thorough analysis, communicate their most important findings clearly and then ask what they should work on next.

Great data scientists take a more active approach and think about their work with more context. They ask what the larger goal of the project is and challenge the core assumptions. They have ideas for how a project could also benefit other parts of the company or raise awareness for potential conflicts that could occur down the line. They are informed about new frameworks or techniques that come out and suggest innovative ways how they could be used to improve a process. They are genuinely interested in how the business as a whole works and actively talk to people to understand their perspectives. They are full of ideas of what they should work on next. They pride themselves on how many people they helped and not on how complicated the technique they used was.

Importantly, they do all of this because they care about the impact of their work and not because they want the attention or boost their career. They do not start a discussion just for the sake of having a discussion and they are able to step back when their opinions did not resonate with others.

*As to how to acquire these skills:* 

If you do not have a data science job yet, this is hard to prepare. But it helps to read blog posts in which companies from different industries share how they get value out of their data (there are plenty of those on Medium).

Once you have a job, ask as many questions as possible without being too annoying and talk to everyone in the company. Do not be shy and just sit in front of your data. Constantly ask yourself why you are doing what you are doing, if it still makes sense or if there is a better way. Get involved, be curious and let others know about your thoughts. The more feedback you get on your thoughts, the better you can fine-tune your work to the business context.

_______________________________________________________
/u/tsutomu45
 
This depends on the role of the data scientist and the company.

In a tech company where seconds (and milliseconds) matter, then your knowledge of algorithms, statistical learning, and programming matters a lot.

However, if you're in a non-tech company, where data scientists tend to be more ""decision scientists"", and the transactions happen across days or weeks (think buying a car), then the ""soft-skills"" tend to dominate...things like understanding the business, iterating rapidly, and explaining results to non-math/non-engineering executives.

Both are learn-able. However, in my experience the latter (soft skills) are harder to teach.
_______________________________________________________
/u/dfphd:

There are three things that come to mind:

* **They are driven by outcomes and not methods - but can do either well.** 

The best data scientists I've met are the people that are willing to put their ego aside and cobble together a less elegant answer in two days than a more elegant answer in a week because that's what's right for the project. That's not to say that they cannot put together a complex, elegant solution to a problem - when the problem/project calls for it, they can roll their sleeves up and make that happen. But their bias is for getting results, not getting methodologies.

* **They say ""yes"" more often than ""no""**

It's really easy to say no. We can't do that, that can't be done, that won't work, no, no, no. Really good data scientists say yes - knowing that they may need to change the question for it to work, but understanding that they can likely figure something productive out.

* **They build strong relationships based on work credibility**

These people tend to do more than just be good at their job - they seem to always manage to leverage the quality of their work into really strong relationships at work, which in turn helps them be even more effective by having a lot of people who are willing to go to bat for them when needed. I think the first two attributes tend to help in building these relationships, but there is extra effort and time that they dedicate to cultivate these relationships over time.

Learning these skills, in my opinion, is largely driven by introspection, i.e., identifying that your objective should be to become as effective and efficient as possible, and that you may need to modify your behaviors, your habits, your comfort zone in order to become that person. Once you can legitimately convince yourself that these are skills worth developing, the rest becomes an exercise in keeping yourself honest - in constantly call yourself out when you are being a method-diva, when you're being a naysayer, and when you're marginalizing your relationships at work.",1
408,"We have written a Medium post explaining our work on applying deep neural networks to breast cancer screening.

https://medium.com/@jasonphang/deep-neural-networks-improve-radiologists-performance-in-breast-cancer-screening-565eb2bd3c9f

* We created a large dataset of mammograms, consisting of over 1,000,000 mammographic images (a.k.a the NYU Breast Cancer Screening Dataset), with accompanying cancer labels and lesion segmentations where applicable.
* We designed and trained a novel two-phase model for breast cancer screening that performs on par with expert radiologists in identifying breast cancer using screening mammograms.
* We are making publicly available our [paper](https://arxiv.org/abs/1903.08297), [tech report explaining our data](https://cs.nyu.edu/~kgeras/reports/datav1.0.pdf) and [code and trained models](https://github.com/nyukat/breast_cancer_classifier).
",1
409,"Why does the company need to know what happends in the algorithm, and what are the factors that affect the decision making? Or rather why do this at the cost of model performance?",1
410,"I started working as a Data Scientist a few months ago, and on the occasion I would receive messages on LinkedIn from people in my area asking for advice and mentorship, often over coffee. These are often college students or people trying to transition into the industry. 

I know the power of networking is pretty strong, but since these guys are pretty green, is it worth my time to invest? I do like helping people, and I think that my own journey to become a Data Scientist was filled with good and bad advice, however I don't want to be taken advantage of in terms of effort and time.",1
411,"I've ended up in more project management type roles as of late due to my company hiring more PhDs and less business analysts. 

Still adjusting, but constantly bothered by the fact I'm losing the skills that made me special in the first place.",1
412,"I am writing my dissertation which is in Political Science but basically just using machine learning to test the predictive abilities of political science theories. I am trying to transition into data science. I am proficient in R, but know that the machine learning toolkits in Python are unmatched. Thus, I am doing my dissertation in Python. I want to keep something similar to an Rmarkdown workflow, and Jupyter is that for Python as far as I can tell. Is it feasible or worthwhile to leave Rstudio behind and do both in Jupyter? What about using reticulate in Rstudio, is that functional or practical to use for Python? ",1
413,"What is the coolest data science thing you've done, at work or as a personal project?",1
414,April Fools!,1
415,,1
416,"Do you all have any best practices in structuring projects (i.e. directory structures for storing data, scripts, exploratory notebooks, etc.; naming schemes; breaking questions/tasks into pieces for teams to tackle in parallel)? This is a little ambiguous and certainly dependent on the specific project and/or field, but I want it to be open ended. Interpret it as you will.

Personally, I am sort of a ""hobbyist"" data scientist (I am a biologist; my ""data science"" type work is all on my own time), so all of the ""data science"" type things I do are exploration of open source biological data (RNA seq, protein-protein interaction databases, anything on the Allen Brain Institute's website; i.e. ""data-science-lite""). I'm usually testing out one-off ideas, looking for interesting ways to combine open source data, and seeing if I can gain any insight into my own project. 

I generally have separate directories for raw and transformed/joined data. I keep scripts in the directory in which they were applied to make it easier to keep track of what I did at each step of the process, and I keep exploratory/debugging notebooks in the parent directory. I also try to keep metadata files in each raw and transformed directory, but to be overly honest I am the only person working with any of it, so I tend to slack quite a bit on creating the metadata.

I haven't come up with any naming schemes that seem to work for me consistently, and since it's just me exploring data to see if I can use it for my own projects, I generally have no need to break it into smaller pieces to be executed by a team.

My approach has a lot of short-comings. In particular, I end up with data files haphazardly named and scripts spread chaotically throughout the whole directory structure. I can usually trace my way back to what I did, but it takes some time. This is particularly problematic when I try to return to a project with a new idea; I spend as much time remembering what I did previously as I do executing the new idea.

I'm just curious what you all do to structure your projects. I've not seen much here in the way of describing best practices in organizing personal or professional projects, so I thought I'd toss the question out to the community.",1
417,"I lead a (small) team of data scientists, roughly split into two. Analytics, and Machine Learning. Everyone in the team is either in the Analytics ladder, or the Machine Learning ladder (though movement between the two is definitely possible).

I'm currently in the process of putting together a competency framework for the Analytics ladder. The goal of the framework is to lay out what competencies are expected of analysts at different levels. This will then be used to help build career growth plans for analysts on this ladder.

Whilst I want to build a framework that is custom for our organisation, I'm aware that 80% of what makes a great analyst probably doesn't need to be custom, and would love to ""steal with pride"" from somewhere else.

Has anyone seen a good (public) framework that they could point me to? Any other thoughts or feedback welcome too.

If you're not sure what I mean by analyst, I think this post does a great job of articulating the Analyst role as I view it: https://hbr.org/2018/12/what-great-data-analysts-do-and-why-every-organization-needs-them",1
418,"Sometimes when I'm doing machine learning experiments or research for my lab, I often end up collecting my own data- image, audio, video, etc. Would other people find an app that lets you collect and label image/audio/video data right from your phone useful? Auto-export CSVs, labeled folders, etc.

&amp;#x200B;

I often find it pretty cumbersome to build custom apps every time I want to collect relatively simple data from a smartphone.",1
419,,1
420,,1
421," I am a software engineer looking to go into data science field. I was thinking of data analyst position to improve my data analysis skills.

I did some research and I found this article [http://nadbordrozd.github.io/blog/2017/12/10/what-they-dont-tell-you-about-data-science-2-data-analyst-roles-are-poison/](http://nadbordrozd.github.io/blog/2017/12/10/what-they-dont-tell-you-about-data-science-2-data-analyst-roles-are-poison/) .

Article's TL;DR:

1. data analyst is more manual job, you work with business, produce reports, presentation not software;
2. you will not gain right coding practices and you will not be learning about modern machine learning/statistical techniques. Also the code you may produce most of the time will be one-off, throwaway scripts, code that only you will ever see, manually operated sequence of scripts, clicking through GUIs etc.

So overall I understand the main idea of this article and it does make sense, is it really true? Is the code data analyst writes ""one-off, throwaway scripts""?

Also if I am coming from software engineer and I do have decent programming background, I am already familiar with coding best practices, wouldn't the skills I would improve in data analysis role be more valuable in becoming data scientist than staying in software engineering?",1
422,"Hi all!

Recently I discovered that Facebook did a super cool thing and made public their package for time series forecasting (yay open source!). As such, I took a crack at trying to use it, and the results are pretty neat.

[Check out this vignette I wrote and put on GitHub](https://github.com/pmaji/data-science-toolkit/blob/master/time-series/forecasting_with_prophet.ipynb) that explores the basic functionalities of Facebook's time series forecasting package called ""Prophet."" Would love know your thoughts and hope that many of you try your hands at building a forecast of your own! To entice you, here's one of the plots that resulted from the forecast, showing how well the model performs (metric = MAPE)  over different forecast horizons.

For those on mobile -- [here is a mobile friendly link to the write-up](https://nbviewer.jupyter.org/github/pmaji/data-science-toolkit/blob/master/time-series/forecasting_with_prophet.ipynb).

P.S. -- if you like what you see, consider starring the repo on GitHub. It's a part of [a larger repo](https://github.com/pmaji/data-science-toolkit/blob/master/README.md) I'm focusing most of my free time on right now that aims to provide easy-to-understand vignettes on the main subjects in data science with the goal of empowering people to expand their data science toolkit :)

&amp;#x200B;

https://i.redd.it/2iotz3r2kcp21.jpg

Happy forecasting!",1
423,,1
424,"I've been working in an image processing contractor job for the past year and a half. For the past 3 months, I've applied to around 500+ jobs with titles such as Data Scientist, Data Engineer, ML Engineer, Deep Learning, etc and have gotten only around 30 phone interviews, 3 on-site interviews, and no offers. I've probably applied to slightly more small companies than large ones, but the only on-sites were with small companies

I've already gotten feedback for my resume numerous times, and the main problems people bring up are that I have lots of gaps in my resume and my recent work have only been contractor or freelance roles. This was also why I had alot of problems getting a job before I landed my current contractor role. 

Although I've worked on personal projects with ML in the past, in my current job I mostly have worked on only image processing with a little bit of deep learning also. I'm not sure if I'm failing the business/product metrics case study questions because I don't really have any experience with that (my current job is more of a research role so I don't really deal with translating business problems into mathematical ones). In a recent on-site interview (after I passed the phone screen in which I was asked technical questions about ML and business/product metrics), the manager directly told me he would only consider me for a Jr. ML Engineer role (I don't remember what caused him to say that. Maybe because I apparently got some technical question wrong or I admitted I don't have experience using ML with dealing with APIs?) 

How can I makeup for the gaps in my resume? Am I better off working on more personal projects? Or just getting really good at knowing the theory behind ML? Because I don't have any non-academic work experience with ML (other than the brief freelance work and the brief DL work in my current job), should I not bother applying for DS/ML jobs and instead focus on image processing/computer vision/DL?",1
425,Data is often involved with a lot of ethical implications. But what are some good examples of win win scenarios? ,1
426,What's the difference between these two positions?,1
427,"This is a follow-on post to [Ed-Fi Alternatives](https://www.reddit.com/r/datascience/comments/93s53e/edfi_alternatives/). I'm not OP.

In that post OP was looking for alternates to Ed-Fi, and I'm guessing didn't find any (there was no followup). But in the comments, a developer/admin/arch? for a larger educational system was looking into using postgres for Ed-Fi. *Neato.*

I'm curious if anyone else is doing something similar, if it's working, and what choices have been made to get your project to where it is today.",1
428,"I'm confident in my technical skills, and I'm able to communicate my findings in a way the business folks at my company can understand, but I'm not good at identifying business opportunities where data science could be useful. If someone came up to me and said ""I'd like to understand X more, because that will allow us to Y"", I could turn that into a data science problem and work towards a solution, but I wouldn't have thought of ""understanding X allows us to Y"" on my own.

What can I do to improve my business acumen as it relates to data science? Any books you would recommend, for example?",1
429,"Hey Everyone, 

So I’ve been using Python ( and a tiny bit of R) for most of my DS projects, but I saw a really interesting YouTube video on Julia. I’d like to know what this community thinks of it as a language, seeing as how it was made for DS essentially, compared to the other more popular languages used currently. 

Will it end up supplanting Python/R?
Does it have any obvious advantage over the other languages other than speed? 
Is it useful/worth it to know?
Anyone here use it regularly?
I know it’s only in version 1.x but I think it has potential!
",1
430,"The last two might seem unrelated but I've heard epidemiologists are also data analysts, same for biostatisticians. I understand the that epidemiologists and biostatisticians may work in the healthcare sector, but how are they similar to a data scientist and data analyst? Are data scientist and data analyst just a broad terms?",1
431,,1
432,"I am a software engineer and have been offered the chance to become a data engineer. I am currently trying to sharpen my skills and become a data science (I am working on my masters part time while working) and I am wondering if this is a step in the right direction. The role would mainly be supporting models using hadoop, spark, and various other technologies. Have any of the data scientists started in data engineering and transitioned into their current roles? If it helps I am also very early in my career (early 20s).",1
433,"I used mainly R in college but a lot of the jobs out there requires that you know Excel, Python, and SQL...I'm having trouble learning everything or building a foundation for the other without feeling like a light switch.",1
434,"hey all - how do you show your ""projects"", data science problems you've worked on? Do you have a portfolio of sorts - something you show beyond your resume/linkedin? 

&amp;#x200B;

Thanks!",1
435,"I’m finishing up my analytics degree in December. I was thinking of getting an internship in the summer, but just wanted to know how important it was or is there something more worthwhile I can spend time in, such as learning new skills and software or building my own projects. 

Is it a make or break for getting a job right after graduation?",1
436,"Does anyone know of resources showing ML models deployed in a production environment? In class and at work (as an analyst), it's one thing to run scripts ad-hoc, sit and wait for the model to run, and then use results in some way. But as with everything in programming, it's a whole nother matter to have it deployed to a product out in the wild! Speed would obviously be an issue, are trained models saved and reloaded in some way?

Edit: Wow, thanks for all the responses! This was really more of just a general wonderment from someone who’s only been doing data science in a narrowly focused business environment.",1
437,"I'm a contracts manager (legal work/deal-making) with 8+ years of experience. I know a teeny bit of programming, I love spreadsheets, and I've always been interested in data. I'm not new to the workforce; I'm looking to make a mid-career change after 10 years and I'm hoping that my extensive work history, combined with newly acquired data analysis/visualization skills, will help me find a new, more dynamic career path. Unfortunately, I'm overwhelmed by the amount of questionable resources and promises (i.e. boot camps claiming $95k starting salaries after 10 weeks) and can't figure out what I actually need to be doing. 

I've been doing some online courses and self-study in statistics and Python for the last 3 months, but I feel nowhere near ready to start working on my own projects (still can't figure out Kaggle or Github), and I'm wondering if I'm even going down the right path. I'm seeing ads for bootcamps left and right, and wonder whether there is any merit to any of them. Basically, I have no idea if I'm wasting my time or going in the right direction. No idea how long it will take for me to gain marketable, meaningful skills. No idea of the breadth of knowledge or experience I need to have. 

Can anyone recommend a good way to find a mentor, someone to guide me through this process? I am not opposed to spending money (either on a mentorship or, an online course or a legitimate post-graduate degree)... I'm just struggling to figure out what is worth my time. ",1
438,"I’ve see a few “Data Science, Risk” jobs, but they all have standard job descriptions. Is this the same as enterprise risk? How is data science &amp; predictive modeling used in this space? ",1
439,"What are best practices for executing series of SQL commands in Python without interfering too much with other users sharing database access?

Some context: I run around 20 queries daily on a single DB. Right now those queries are spaced five minutes apart but I think that's quite clunky and would ideally start the next query if no other queries are executed at that time so I have my full results quicker. It's not ok to execute all queries one after the other and potentially lock the db until all queries are finished executing.

Edit: MSSQL DB, queries that are designed to select from all users their outsstanding payments, product types, etc. So often locking records for several seconds (10 max). ",1
440,"TL;DR: I did a performance analysis of my production classifier and would like to know what's the method that you guys use, and whether there are any flaws to my idea.

&amp;#x200B;

I work with text mining and the most important model that I have is a document classifier. It classifies if a particular document is a contract or not.

&amp;#x200B;

My team created a pipeline that fetches documents, OCR them, classify them and make them available in a web application, so that our users can find them way faster than by using the other methods.

&amp;#x200B;

The classifier was trained with 1K documents and deployed with &gt; 90% F-score to production (I did the training, testing and validation stuff to prevent overfitting). We then needed to tell the stakeholders our classification accuracy, because of that, I sampled 1K from the 33K classified documents and we manually annotated the sample so that we could calculate the number of contracts labeled as not contracts (false negatives) and the number of documents that were not contracts but were classified as contracts (false positives).

&amp;#x200B;

I then looked at the false positives and false negatives for patterns, after finding patterns in the errors, I created regular expressions that reduced the error for some patterns, and re-trained the models for the other patterns that came from new documents that were entirely different from the samples we had in the initial dataset. After updating the model, the F-score went up to &gt; 90% again, and we got better results when looking in the web application, so the problem of performance was solved. BUT, I think my approach to this problem was very intuitive and not very science-y, so I figured out another way of doing this, a more statistical way.

&amp;#x200B;

What I'm thinking about doing in the next time, is to make a [sample size calculation](https://www.surveysystem.com/sscalc.htm) using the total of documents in production as the population, confidence level of 95% percent and confidence interval of 3%. Then do a random sample of N documents, annotate them and calculate the F-score.

&amp;#x200B;

Now, my fellow data scientists, I would like to know how you do this kind of performance monitoring for classifiers. Also, do you think that my idea has any flaw ?

&amp;#x200B;

Another thing, my new idea will use a confidence interval of 3%, does that imply that the score that I calculate after annotating documents from my random sampling will have a range of +- 3% ? For example if I calculate a F-score of 94%, does it mean that my F-score, actually is 91-97%, because I did a sample of the population ? Or am I oversimplifying things and this is not how confidence intervals actually work ?

&amp;#x200B;

Thanks in advance for the input, I really appreciate it. Statistics is my weakness, since I entered data science from software engineering field.

&amp;#x200B;

EDIT: Edited sample size calculator link",1
441,,1
442,"I recently accepted a position where I have access to a really nice Linux server (56 threads 256G Ram) and we are currently in the process of getting access to an even larger server (100+ threads with 2TB Ram) -- we have a lot of heavy lifting to do. At my previous position I used a server with remote desktop and it was clunky so I'm trying spend some time getting familiar with a good setup early in order to increase my productivity and workflow later. I'm looking for recommendations on workflow. Here is my current workflow setup:

* Jupyter-lab server
* Rstudio server
* ssh tunnel from server to localhost on a Macbook Air or Fedora Workstation desktop through Chrome
* localhost:8000 to load up Jupyter-lab
* localhost:8001 to load up Rstudio

I generally write scripts in Jupyter-lab or Rstudio and once testing is complete I open up a tmux shell on the server and run code straight from the command line -- I use tmux so I can monitor it throughout without the need for being connected to the VPN. This has worked well so far but it still feels a bit clunky. Ultimately, I think a vim-python in one tmux pane and ipython in another would be ideal where I can Ctrl+enter send commands using vim-slime. I've tried this setup and it works, but the config is somewhat of a hassle and I need access to quick plotting to check data processing commands and model run outputs, which is not possible with ipython in the command line. An `ssh -X` would solve this, but now I'm adding things that seem excessive.

This setup is certainly better than my previous workflow. I'd like to see what other data science workflows look like when using a remote server. 

So, does this seem like a reasonable setup? What is your programming setup and workflow when using a remote server?

",1
443,"Is something upsetting you about your career, school, or job hunt? The daily grind can get frustrating, but a full thread is too high visibility for some folks. This thread is a good place to keep things low key and to find solidarity among our peers. 

We’ll try it out this week. We’ll make it a recurring thing if sufficient people show interest. ",1
444,"I can’t be too specific because I work in a really niche industry, but just over a year ago I got what I thought was my dream job as a data scientist in a scientific industry.  I retrained specifically for this and was super excited to get offered the position.  A year later, the position has not lived up to expectations and I am deeply unhappy.  Having never worked elsewhere as a data scientist I’m not sure if it’s just my company though.

For most of the time I’ve been here I have not had any work to do.  I feel like I’m massively underutilised, and I do nothing of value.  When I actually have a project to work on, I spend most of my time aimlessly trying to create ML models when in reality the data I have does not fully explain the values I’m trying to predict.  I have no deadlines, so I have no pressure to model quickly.  Nothing I’ve done goes into production.  I’ve stretched what should be week to fortnight-long projects into months because I have nothing to do.  I’ve literally had only 6 half-projects since I’ve been here.  I feel like I’m trying to find things to pass the time with, and it’s really starting to affect my mental health.  I like to be kept busy.

Also, none of the data scientists collaborate on projects, we’re all assigned our own work, which I feel is possibly not the norm.  It's really lonely, and I feel projects would get done a lot more quickly if we worked together.  We also never have code or project reviews, so I have no idea if what I’m doing is correct or not.  I taught myself to code in the language we use so honestly my code is probably horrendous.

I’ve tried to find my own projects, but it’s such a large and global company that it’s difficult to know where to start.  When I have managed to create my own projects, it’s taken MONTHS to get the data, so I just sit around waiting.  In the absence of anything else to do, I've been teaching myself web development.

It’s got to the point where I’m really considering changing to a software engineering/developer role as I really enjoy coding, and I feel like software engineering is an inherently more interesting and collaborative role.  Is it?

Is my experience typical for a Data Scientist, or is it just my company?  Should I try moving to a data science position elsewhere before abandoning it completely?

**tldr: data science job is really boring, involves a lot of waiting, no code reviews, and there is no team collaboration.  Is this typical for a data scientist or just my company?**",1
445,"[https://github.com/minimaxir/automl-gs](https://github.com/minimaxir/automl-gs)

Not just that, but it supports TPUs when using TensorFlow in Colaboratory and metric tracking at every epoch, allowing to you visualize *everything* during the experiment.

This was a convoluted experiment to test out ML code generation using Jinja, and things worked surprisingly well! Hopefully you all will find it useful!

(I asked the mods ahead of time about the self-promotion and they said it was OK for this use case.)",1
446,"Dear fellow redditors,

I've heard and read that soft skills are quite important as a data scientist (and professional life in general) – communicating results, understanding customer needs, navigating company politics etc.

But how do you cultivate and consciously improve these skills? Do you have practial advice, or can you point me to some good resources?

Thanks a lot!",1
447,"

I've always been interested in computer science, especially with ML and AI. I read many books about it our of pure interest. 

I'm also strongly interested in statistics, especially probability theory.

Here's the thing. I have the opportunity to do a masters in computer science OR a masters in applied statistics. I cant decide which one since I'm interested in both. 

My friend suggested that I do a data science masters because he said its basically statistics + computer science. 
However, It seems there's a stigma attatched to data science as a degree. 

Could someone explain why data science has this stigma and whether it is or isn't good to study?",1
448,"So I recently had some interviews with consultancies. I’m interested in working as a consultant because I think I would be able to gain a lot of experience - I just graduated as a M.Sc biostats and I think that working as a consultant would help me get interesting projects on my resume - as opposed to working one job, especially as a (bio) statistician where juniors often only get to program tables, figures and listings. But a friend of mine (software architect)  tells me that a consultancy is just a temp firm, that pay is low and that I should look for something else. I’m still interested in becoming a consultant but I’d like to hear what you experience as a consultant and what made you choose that path! ",1
449,"Sometimes, I feel like I'm about to lose it with this DS MSc! :' (

**From**:

1. Non-responsive/ blunder from team members for assignments and projects : (
2. Office work, and work - did I mention about the office work clashing with the MSc work timeline ....   :' (
3. My own personal weakness (e.g. impatient, stubbornness, etc.) - yes I will admit this : /

&amp;#x200B;

Yesterday I found out one of the team members met the Analytics professor on campus ***but he forgot*** to show him the project dataset we proposed together as a team. Instead he was just talking about HIS assignments with him - this basically drags our time-line and I was so about to lose it that day but keep my mouth shut, fortunately.

&amp;#x200B;

For DS MS students, please, I need your advice - what would you do if you're about to lose it given any circumstances you faced whilst doing this MS? : (",1
450,"People claim that coders are night owls. Now this may be true for some people...but here’s what they don’t tell you

Meetings at work and filling out various forms about progress checks, reading requests for bugs to get fixed, etc disrupt a coder’s attention to solving a particular problem the coder was assigned before. 

Some of these challenges require some dedicated focus and the only times you get that are evenings, weekends, and early mornings. ",1
451,"Hi, Data lovers D\_D  
I'm posting here, because i could not find it in the internet. :D  


Q.  What is **FinStudio / FinArch** ? ( i know it's software or tool for DW / Analyse  )   
A.  
Q. Dose anyone have experience with this software ? and If you can compare it with other similar software ? witch \_\_\_\_  
A.   
Q. Where can i get copy of it ? ( for Learning purposes )  


Thanks. ",1
452,"It feels like SV alone has created a 1000 AI/ML startups in the past year. 

We all know AI/ML is just statistics. There are numerous articles showing that the shortage in DS is huge simply because...almost nobody studies statistics in college. 

How can it be that all these people are up to something if they don't have the skills in their workforce?

""Forty percent of ‘AI startups’ in Europe don’t actually use AI, claims report"" https://www.theverge.com/2019/3/5/18251326/ai-startups-europe-fake-40-percent-mmc-report

What's going on in your opinion? ",1
453,"My friend, who is a data scientist at a major firm, said they just got license for a data ""robot"" that can do data cleaning and go thru many different models along with cross validation quiet well.

He thinks data science will be dead in a couple of years. What's your take?",1
454,"Does anyone here use Stitch Data for their ETL processes? If so, how's it working out for you and your organization?

We are looking into Stitch Data to see if we can automate pulling data from a variety of ticketing systems (later branching out into other databases) into our centralized GCP environment dedicated for enriched data. We ran into a problem and realized that it really only Extracts &amp; Loads, the Transformation is non-existent (contrary to what it advertises). This forces us to write our own programs (usually in Python) to do a secondary ETL. My opinion is that if we're writing our own transformations, then paying for a third party extract &amp; load is too much for, essentially, the easiest part in the ETL process.

Are there any alternatives that you would recommend? ",1
455,"I'm a neurobiologist and I would like to enter in the data science field. Mostly all the jobs I've looked at recquired an infromatic/mathematic/engineering background, although I may land some internship if I have the right tools.

I've started learning Python, but I have all day free so I'd like to study two programs, one in the morning one in the afternoon/evening. Which one would you advise that is absolutely worth it? Sas? R? SQL? Spark? Scala?",1
456,"I am seeing more and more lengthy assignments to ""test abilities"" given to candidates that require a significant portion of time to complete for consideration for Data Science and Data Analyst roles. Are these assignments truly necessary to test abilities as professionals? And after spending potentially hours of time on doing the work and submitting it, no feedback is given-the recruiter just disappears. 

&amp;#x200B;",1
457,"Release from #GoogleAI: general #tensorflow framework  for #NLP. 

#Lingvo is a deep learning framework used for sequence modeling tasks like machine translation, speech recognition, and speech synthesis. 

Link: https://medium.com/tensorflow/lingvo-a-tensorflow-framework-for-sequence-modeling-8b1d6ffba5bb


Github: https://github.com/tensorflow/lingvo",1
458,"Welcome to this week's entering &amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)  
* Traditional education (e.g. schools, degrees, electives)  
* Alternative education (e.g. online courses, bootcamps)  
* Job search questions (e.g. resumes, applying, career prospects)  
* Elementary questions (e.g. where to start, what next)  

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](https://www.reddit.com/r/datascience/wiki/resources) pages on our wiki.  

[You can also search for past weekly threads here](https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;restrict_sr=1&amp;t=month).

^(Last configured: 2019-02-17 09:32 AM EDT)
",1
459,I'm current a Data Scientist (ML &amp; Deployment) for a Fin Tech &amp; my significant other has asked that I come talk to her class for career day. How would you explain data science to an 8 year old? ,1
460,"Shiny App:

[https://zksmith.shinyapps.io/NCAAMB2019/](https://zksmith.shinyapps.io/NCAAMB2019/)

Github repo:

[https://github.com/smthzch/NCAAMB2019](https://github.com/smthzch/NCAAMB2019)

&amp;#x200B;

Quick little shiny app that allows you to view the predictions of my NCAA men's basketball model. Gives predictions for today's games as well as allows you to pick matchups of your own. I also included a short write up of the model which was fit using Stan.

&amp;#x200B;

Probably going to run out of hours on my free shiny account, but let me know what you think.",1
461,"Hello everyone, 

Long story short: I am a Data Scientist that works for a fortune 500 company in Brazil, and wants to relocate to Europe, but would need sponsorship because I only have Brazilian citizenship. Was a software engineer that transitioned to DS and I work with text mining right now. 

I would like to have some advice on what I should focus on next to maximize my chances of getting a Data Scientist position to relocate to Europe. There are a lot of different fields to work on and I feel kind of lost on how to proceed. 

Since Europe is very big, the options that I envision are:

- The Netherlands
- Germany
- UK
- Ireland
- Switzerland
- Belgium looks good as well, but I would need to study this country a little more to decide. 

Any one of them would be good, since I know that relocating inside Europe is easier once you're there, in case I'm not compatible with my first option. Also, I'm not picky about salary, having enough to pay the bills and eating out two times a week is enough for me, I know I can build upon my opportunity with time. 

I think it's important to give you details about my background, so that you have more information to work with. 

### My background

What I can do:

3+ years experience with software engineering before switching to Data Science so the programming, SQL, NoSQL and ETL stuff is a no brainer to me. I know how to deploy math models using Python and also know infrastructure, docker, Linux, Kubernetes, scalability, networking, etc etc. (I worked as a sysadmin for a year)

I am working with document classification for 1 year already, using TF-IDF + SVM + regex rules. I also do metadata extraction from the text (client name, document id, etc). I have hands-on experience with random forests, logistic regression, NaiveBayes, etc, the standard stuff for text mining. Classification is one of my strengths. 

I know how to explain these complicated concepts to business people, one of my presentations to a C-level executive on how word vectors could be used for a problem made me receive very good feedback from him. 

I am responsible for understanding the problem with the business people so that I can know which problem to be solved first to have better results to then solve it using ML/DL/whatever solves it, I also make the decisions on how the problem will be approached. 

I also know quite a bit about sentiment analysis, since it's what I do in my spare time. 

What I cannot do:

I don't know R (it would be easy to learn R, but I got lazy in that part, Python looks way simpler)

I just have very basic and  theoretic knowledge of regression, that part of DS is not used in my job because I do classification, so I never got past that famous real estate dataset.

I also have very basic and theoretic knowledge of clustering, I know it is very useful for profiling customers, recommendation and all that, but didn't get past KNN and K-Means examples, just the basics. 

My statistics kinda suck. I'm working on that right now by learning on online courses and trying to apply it to hypothesis testing in my work. But I still struggle with how to use random sampling, the exact meaning of confidence interval, p-value, F-test, T-test, etc etc. This is one area that I don't feel confident about. 

My math is not that strong as well, I struggle to understand the underlying maths on state of the art papers. But I don't know if knowing the obscure details of CNNs helps more than being good at using them in a practical setting (avoid overfitting, for example). 

My question is, based on my strengths and weaknesses, what skills should I focus on to have a bigger chance of getting a DS position in Europe? Customer clustering, A/B testing? Financial stuff? Object detection using CNN? Time series forecasting ? Should I stay in text mining and be VERY GOOD at it and search for positions in that field? Or should I know a little bit about everything and pray that it is enough to land the job, to then get very good at something ? 

Will a masters in science help me on getting a sponsored visa position? Or is it more about what I can / cannot do in practice, instead of academic success? 

I have a B.Sc in Computer Science BTW. 

My favorite area of study is computer vision, but I don't see a lot of job postings about it.  ",1
462,"I see a lot of job postings asking for experience creating, maintaining, and modifying data lakes and pipelines.

I've also heard a LOT about pipelines, and a little bit about lakes (mostly in passing), but I don't think I've ever seen someone actually talk about them in depth. What are they exactly? How do you build them? Do you need something like Spark or Hadoop? What about Azure? Where can you go to learn this power?! 

If anyone here works with these concepts, can you shed some light on this topic please? And perhaps drop some resources to study? Please?

[What does it mean?! WHAT DOES IT MEAN?!](https://i.redd.it/h7hw96tmqsn21.png)",1
463,"Hi guys, looking to speed up our routine DS/ML model exploration analyses and was directed to h2o. Post data preparation, we largely do exploratory work in r or python notebooks. It seems like the sort of thing we need but I wanted to get some opinions and other options too from the community. I have also tried knime. 
Many thanks in advance, ",1
464,"Hi All. I'm having a first world problem dilemma... and would love some advice from people who have been in a similar situation.

I am currently very privileged to be living the ""data science dream"". I work as a product data scientist for a big tech company in Silicon Valley, my work is appreciated by my stakeholders and peers, I am well paid (TC = $160k for 3yoe + stock), and I feel like I am constantly learning new things at work.

I am not originally from the US, I relocated from France where I am from, and would like to move back at some point, to reconnect with family and friends. My original plan was to stay 3 more years from today, and continue saving as much as possible to move back with some savings, with the prospect of retiring early.

However I am realizing that not only salaries will be significantly lower in France (we're talking 3x lower), but the prospects do not look so exciting from a DS perspective (e.g. archaic corporations who look for data analysts, or startups who use words like ""neural networks"" in every sentence).

Anyone has been in a similar situation and would be able to provide some guidance?",1
465,"Do any of you work as data analysts/scientists for law firms or in that field? What kind of work do you do, what do you like/dislike about it, and what advice do you have for getting into that field of data science?",1
466,"So you want a coveted internship? This answer is mainly geared towards software, but can be applicable to any industry.

I have some tips that helped me get my first software engineering internship in Silicon Valley, right out of my coding bootcamp. I break down some of the best ways to get an internship as quickly as possible, as easily as possible.

Whether you studied computer science in college, went to a coding bootcamp, or are self-taught, these tips will help you through.

If you prefer video format, here’s a video I made covering these topics:

[https://youtu.be/eyzKYYwB0ng](https://youtu.be/eyzKYYwB0ng)

The first main tip is to start as early as possible. Bigger companies who have the most internships available start early in August, September, an October with posting their internships. The earlier you start, the higher chance you have at beating the competition.

The second tip, and probably the most crucial one is to use your network. Using the back door to get your foot in is much easier than using the door that thousands of people are using (the automated online job portal). You can use LinkedIn, Facebook, and word of mouth to find people who worked at specific companies. On LinkedIn, you can use search queries like \[Insert college here\], and then use people filters such as 1st /2nd-degree connection, location, and company. This helps hyper-target your audience.

The best people in your network to reach out to are:

\- College / coding bootcamp alumni who work at the company you want to work at

\- Friends / classmates who interned at that company

\- Professors / mentors who might have connections with that company

\- Friends of friends who work there (use Facebook to search this - “friends of friends who worked at \[X company\]

The next tip (this is crucial, and will save you a ton of time). Don’t send your resume off into a black hole (such as Indeed, Glassdoor, etc) and do nothing else. My rule is for every job app you send into an online portal, you need to connect with one real person as well. There are a handful of ways to connect with a real person at this company - use a Gmail plugin like Clearbit Connect, or Hunter io to find peoples’ work emails by company search (give them a quick Google - you’ll see what I mean). These are extremely powerful tools. Then, send them a quick note:

\~\~\~

Hi \[person’s name\]!

My name is \[your name\], and I’m an \[type of engineer\] in \[location\].

I’m reaching out because I applied to \[company\] regarding your \[position\].

I have experience with \[this technology, skill, etc\]

Following up, I've provided my resume and cover attached letter below.

Would someone on your team be open to chatting more about this role by \[insert date to add time pressure\]?

Thanks so much!

\[Your name\]

\[Phone number\]

\~\~\~

Following up after they’ve responded:

Would you be willing to connect me to the hiring manager for this position per chance? I'd greatly appreciate it!

Thanks so much!

\[Your name\]

\~\~\~

The most important thing is to not be annoying. If they don’t respond after following up once or twice, try another person at the company.

If you’ve used the last 2 tips (network, reaching out) and have finally connected with a real person, you can ask them “How can I stand out in the intern application process for \[X\] company?”, or even better, ask to buy them a coffee and pick their brain about their experience working at the company, the company culture, and to see if you’d be a good fit.

Another way to stand out is to have an amazing portfolio. This isn’t absolutely necessary (at least for Software Engineers), but will help you stand out above the crowd. My tips here:

\- Host your projects on Github (clean up code, add ReadMe, etc)

\- Add your projects, with screenshots and descriptions, to your LinkedIn experience/projects section

\- Create a video outlining your design decisions, tech choices, etc (I did this when applying, and it definitely helped)

\- Deploy your projects to the web, and have a landing page which can direct people towards them

The next tip is to prepare for the technical interview. If you’ve gotten this far but fail the technical portion, chances are you won’t make it further. They can give you any question, but your goal is to be familiar enough with basic concepts, so you can adapt on the spot. Using sites like LeetCode can help improve your technical ability. It also helps if you’ve seen similar questions to the interview ones - LeetCode will help you with this. Sites like Pramp help you practice interview skills live, which is another surefire way to get feedback and improve your chances at doing well. Take a few deep breaths before you walk into the interview, and you’re ready to go because you know you prepared!

The final tip I have (and one that sped up my job search tenfold) is to track EVERYTHING. There’s a Gmail plugin called streak that allows you to track your job search in a funnel. Streak also allows to send template snippet emails, and you can see if someone has viewed your email. So handy!

I customized the funnel by tracking:

1. Company Name
2. Position Name
3. Contact Name
4. Contact Email
5. Contact LinkedIn
6. Date of Last Contact
7. Job Source
8. Job Posting URL

If you’re not a fan of Gmail plugins, you can also use a spreadsheet like Excel, Google Sheets, and my favorite (spreadsheet/database mix) Airtable! Airtable is a solid option, because it allows you to link different tables, attach documents, and organize things with ease. An Airtable tutorial would take a whole other post, but I encourage you to check it out!

The job search is ultimately a game of failure, persistence, and triumph. You ultimately need to create your own luck, and this happens by widening your pool. Start applying to as many places as possible! These tips I shared above allowed me to apply to 150 jobs in 3 days! Most of the time I ignored the cover letter (do they really matter, anyway?) and focused completely on connecting with a real person. That’s what will ultimately start you on your journey.",1
467,"I'm in the process of interviewing at a company and they sent me essentially a customer retention problem, asked me to explore the data, create a model, and evaluate it. Then make suggestions on what different models you might use, pros/cons, etc. I've done what I can with the data, and the logistic regression model is legitimately poor. I'm just wondering what managers are looking at when they look over the assessment. I'm already doing this in a language that is not my strong suit at their request. So though I know the theory and the process I'm using seems sound, I'm not sure if that's going to come across in an unfamiliar language under time constraints. Any advice?",1
468,"My firm is really not investing in quality control and infrastructure. I deal with it but have to essentially lay the foundation for many projects at the data collection level. I'm looking at new positions and wondering what the signs of a more robust and mature infrastructure are. Similarly, the signs of weak plumbing and quality control. ",1
469,"For those who tried to be data scientists and failed but still have the skillset of a shitty data scientist (Python, SQL, building not that great models)... what are those roles?",1
470,"My question is in reference to Kaggle competitions but in some contexts can apply to the professional world. 

What are the roles when **developing** a machine learning model within a team?

&amp;#x200B;

I could envision each team member independently coming up with a good model and than the team creating an ensemble of all of those models perhaps? Or perhaps there are different team members that focus on model creation / communicating the results?

&amp;#x200B;

I was tempted to enter a competition solo, but if having team members will provide a benefit, I may go for it. 

&amp;#x200B;

&amp;#x200B;",1
471,"/r/CollegeBasketball's runs a Men's [college basketball challenge](https://www.reddit.com/r/CollegeBasketball/comments/b2hznx/the_eighth_annual_rcollegebasketball_bracket/), they score various  the various subreddits by how accurate they are. Any interest in getting a group together for datascience? You can change your group at any time for this.

For our own DS twist, you can post your bracket picking methodology. I use a modified ELO weighted by Vegas odds. 


**Boring explanation for people who've never watched**

For the Non-US among us, March Madness is an annual basketball tournament similar to the knockout stages of football (single-elimination) that is used to determine the best college basketball team in the country  (think of it like UEFA Champions league but much more compressed in terms of timeframe). Since college basketball teams play in separate conferences (think domestic leagues), there is no way to claim bragging rights of the best team in the country. It's referred to as madness because the tournament takes place over 2 weeks and anything can happen (like giant-slayers in the FA cup if you're a Brit).

538 usually has a great writeup of the odds and their models (https://projects.fivethirtyeight.com/2019-march-madness-predictions/)",1
472,"I am in a  , BI , analytics , biostatistics, data science type of role  . Lots of stats comes my way but no one is a statistician that I can go to with questions . There are projects where some predictive modeling would be great but once again I don’t have enough experience to know with certainty that my approach is feasible or correct 

Where does one go when there is no one at work that understands what you are trying to do?
How do you find a mentoring of this type ?

(Industry is healthcare, hospital ) 

",1
473,Last thing I want to do when I get home from a full work day is more work. What keeps you going?,1
474,": (

Tough enough to do an MS whilst working, now, we're dealing with this!

There are a few types I found (you can add them if you want):

1. MIA due to their own commitments (as if some of us don't have one!) so can't contribute or contribute at the last minute! :' (
2. Wants to contribute but are either intimidated (by the work) or have no clue what to contribute (but genuinely want to do some thing) - ok, this is fair but of course, more work for you : /
3. Non-responsive team member - as in they won't respond to messages or email - only during meet ups, like in classroom only ... Jesus ... : / 
4. Hyper-active types that want to constantly meet the lecturer for consultations or discussions but not all team members feel like there's a need to meet the lecturer for the most rudimentary question : |

&amp;#x200B;

I am not too sure if I'm stressed out with the above situations or just a combination of the MS and work, thus not being able to see the bigger picture.

Any advice is really appreciated : (

&amp;#x200B;

&amp;#x200B;",1
475,"Hey guys.

I want to discuss about something that is itching me right now.

I recently posted in the weekly Entering thread. I am a student in mathematics and computer science who is studying to become a data scientist. I am currently learning C++ by myself and was told to transition to Python ASAP. I was reading a Data Structures and Algorithms book (in C++) during that time (and still am, spoiler!)

So I did my DD and told myself why not learn that subject in Python to learn the language at the same time? There's where it became more problematic. I understand fully that for someone who wants to become a data scientist, Python is mandatory since it has these beautiful libraries for machine learning &amp; co. But the problem I faced is that when I wanted to implement my own data structures in Python, I realized that so much is done under the hood that it's pretty much impossible to get an in-depth understanding on what is happening, and to optimize stuff on ""my way"".

So my question goes as follow : Since optimizing is a huge part in a data scientist job, and playing with data structures/optimizing algorithms is also so important, why is it not pushed more to get a core undestanding of it? I understand you can use stuff that you don't understand completely, but for someone who's JOB is to use it, shouldn't he understand at least the fundamentals?

I want to hear your opinions!

PS: Just to be sure, I am not ranting on Python, I am saying it's hader to get a grasp on the core because it's all done out of sight. I am not saying C++ is better either, I am asking why people do not recommend to learn a lower level language (any!) before learning Python.

Thank you guys.

T.",1
476,,1
477,"(Sorry for such a long post; main question is at very end.)

I have finally received an acceptance letter for a Statistics grad program (yay!), and plan on leaving my company in late summer to go back to school full time.  I currently work as a data analyst for an automotive supplier, and my boss is aware that I will be leaving the company, and he will be working with HR soon to start the process of finding (and potentially using me in part to train) a replacement.  Thankfully, everyone is very supportive.

I was the first person in the company, so far as I am aware of, who does ""data analysis"" and has a statistical background, novice as I am on paper in that matter.  I am not very happy with the way my job is currently structured and would have planned on leaving anyway if I had not gotten an acceptance.  My work is not very well defined; there are data management issues (like storage, access, standardization across sites) which slow work; and I do not have anyone in my company who is able to double check my work from a statistical POV—or even more preferably, elevate it to (and appreciate) a higher sophistication.  While officially on a team, I am not on a team of people who do what I do, and am very independent anyway.

I have been asked to help craft a job description for my replacement.  However, while I can easily regurgitate my current responsibilities onto paper and list what skills I have found useful for executing them, I would like to expand this task to communicate back to my employer how best to structure such a job, from hierarchy of needs they should be considering in order to streamline the data analysis process (instead of merely filling roles I have been haphazardly shoehorned into, and ignoring needs which subsume them), to better establishing specific duties to achieve those ends (instead of giving the next person as much autonomy as I have).

I would like to do this, and have come to this community for feedback on how to do so, for two main reasons: (1) I myself need to grow and manage my expectations for what a better data analysis or data science job looks like, and (2) I would like my successor(s) to experience that better if I have some latitude to reform it.

To give a rough outline for what I would like to learn and communicate back to my company, posed as questions:

- **What are the standard vertical and horizontal structures surrounding a technical job like an analyst?**  Right now, I receive work not only directly from my boss, but also often directly from different people in the company (some high up) who are aware of me and the statistical skills I provide.  Sometimes these projects do not have established timelines or well-defined metrics or goals, and this creates disorganization and workload/expectation problems.  After working like this for some time, it seems to me that a wiser system would be for projects to be administered through management, and interactions between groups (such as, a chemical test lab group and my group (myself)) to ultimately start and end from above.  Is this misguided?  How do project management and team interactions work in well-functioning systems?

- With deference to some of the prior considerations, **what sort of environment (have you found) works best for a data analyst to thrive in?**  For instance, I feel that I would have liked to have another person on my team who does what I do so I could bounce ideas off them and assert my own expectations better.  I also feel that the rest of the company isn't very good at managing their own expectations for what a single data analyst can do, and my position as an almost independent service provider within the company speaks to that.  How are data analysis teams organized and how do they manage the request-result cycle?

- **What functions often go underserved in a company starting to sophisticate its data analysis process, and what skills should it seek out to fill those?**  As I mentioned above, there are non-homogeneities in how data is collected and stored and made accessible between different manufacturing or test sites that we have, and some projects that they would want to work on in the foreseeable future will involve more sharing of this data between sites.  Data is often dumped into a ""vault"" specific to each site (with very limited read access), and can be made available in a hodge-podge way on a network we have.  It doesn't seem conducive to accessibility.  I am also woefully underinformed on the full extent of data management at our company, so the problem may just be my level of knowledge; but the prescription nonetheless may be bringing in someone with the skills required to interact with the data we have, even if vaulting and networks are enough.  Who works behind the scenes that a data analyst depends on?  What skills should that person have?

- Finally, **How can I combine the above into job description(s), for employer and prospective employee alike?**  How many people make a good team?  What should they each bring to the table?

These are the things about which I will likely ask more follow up questions.  That may come when I have done some more thorough investigation into what expectations and gaps people in my company find for data analysis.  I also may not be asking the right questions, and I may have different ones depending on the feedback I get here.

Right now though, I think this is my question for this post:

How would you characterize a ""good"" and functional data analyst role and what does their team look like?",1
478,"I've collected the snippets that I developed during my last 6-months, intensive MRes project. Almost every piece is my own code and most of these hacks were not published before. Hope it will help some researchers with their work.

[https://medium.com/@krassowski.michal/productivity-tips-for-jupyter-python-a3614d70c770](https://medium.com/@krassowski.michal/productivity-tips-for-jupyter-python-a3614d70c770)

One click less:

1. [Play a sound once the computations have finished (or failed)](https://medium.com/@krassowski.michal/productivity-tips-for-jupyter-python-a3614d70c770#3b5a)
2. [Integrate the notifications with your OS (ready for GNOME shell)](https://medium.com/@krassowski.michal/productivity-tips-for-jupyter-python-a3614d70c770#ad45)
3. [Jump to definition of a variable, function or class](https://medium.com/@krassowski.michal/productivity-tips-for-jupyter-python-a3614d70c770#3424)
4. [Enable auto-completion for rpy2 (great for ggplot2)](https://medium.com/@krassowski.michal/productivity-tips-for-jupyter-python-a3614d70c770#7a8a)
5. [Summarize dictionaries and other structures in a nice table](https://medium.com/@krassowski.michal/productivity-tips-for-jupyter-python-a3614d70c770#2c78)
6. [Selectively import from other notebooks](https://medium.com/@krassowski.michal/productivity-tips-for-jupyter-python-a3614d70c770#8dd4)
7. [Scroll to the recently executed cell on error or when opening the notebook](https://medium.com/@krassowski.michal/productivity-tips-for-jupyter-python-a3614d70c770#68cb)
8. [Interactive (following) tail for long outputs](https://medium.com/@krassowski.michal/productivity-tips-for-jupyter-python-a3614d70c770#8313)

*Processing gif ryp1i29gsum21...*

&amp;#x200B;

If you want to go straight to the code: [https://github.com/krassowski/jupyter-helpers](https://github.com/krassowski/jupyter-helpers)

Do you have your own, not so well-known tips as well?",1
479,"I released a new version of my Debian packaging for JupyterHub (https://github.com/1and1/debianized-jupyterhub#jupyterhub-debian-packaging). It makes the installation of a fully working hub on a Debian or Ubuntu server easy, with everything already installed and compiled (no build tools needed).

The package comes with a fully equipped Python3 kernel – the scientific Python stack and common visualization frameworks are built in. All additional packages beyond the JupyterHub core are organized into setuptools ‘extras‘. You can select them for inclusion (many are added by default), or remove unneeded ones to reduce the package size, by changing the “debian/rules” file.

On an Ubuntu / Debian workstation, using this package you get readily available notebooks for personal use, without the need to start a notebook server on the command line every time you want to edit a notebook.

Technically, this is a self-contained Python3 venv wrapped into a Debian package (an ""omnibus"" package, all passengers on board). You can build the package in a Docker container, so that you don't need to worry about installing build dependencies – the Dockerfile does that for you, without affecting your workstation or build host.

For more details, check out the GitHub README (see link above).


Changes since 0.9.4-3:

  * Extras: Added 'docker', 'nlp', 'ml', 'utils', and 'vizjs' (included by default)
  * Extras: Added 'arrow', 'nltk', and 'parquet' (optional)
  * notebook: update to 5.7.6 (CVE-2019–9644); also updated other explicit requirements
  * Tornado: kept at 5.x because of compatibility problems
  * Packaging: Switched to built-in Python3 venv",1
480,"[https://towardsdatascience.com/build-a-corporate-r-package-for-pleasure-and-profit-78b73ce4ff4b](https://towardsdatascience.com/build-a-corporate-r-package-for-pleasure-and-profit-78b73ce4ff4b)

&amp;#x200B;

I wrote an in-depth tutorial on the art of building a ""corporate"" R package, that is, a package with built-in ggplot themes, common data sets, templates, etc. Hope it's helpful to you!

https://i.redd.it/tnd67bafivm21.png

&amp;#x200B;

&amp;#x200B;",1
481,"We were able to get 4 members of the subreddit to volunteer to participate as part of the panel - hopefully if we get some good content and discussion going we can add more people to the panel moving forward.

**How does this work?**

Post any questions that you are interested in the panel answering.
Upvote/downvote any questions that you think would be good/bad for the panel to answer.
At the end of the week, we'll choose the top voted answer.

Caveats:
Any questions that are answered in the wiki and/or we don't feel would benefit from multiple points of view will be ignored. The idea is to focus on topics where 4 different professionals may have 4 different opinions/viewpoints.

Thanks everyone who has volunteered to participate, and let's get some questions going!",1
482,"With how inconsistent titling is among data science roles, I wanted to get a feel for how people perceive titles. How would you rank these titles (in terms of highest to lowest in the org), assuming ties are allowed and all other things equal (i.e., same company):

* Data Scientist
* Lead Data Scientist
* Principal Data Scientist
* Chief Data Scientist
* Associate Data Scientist
* Head of Data Science
* Data Scientist I
* Data Scientist II
* Senior Data Scientist
* Director of Data Science
* Manager of Data Science
* Sr. Manager of Data Science
* Sr. Director of Data Science
* VP of Data Science
* Data Science Specialist",1
483,"I was offered a data scientist job at a unicorn fintech firm with an established data sciences team. It was my first interview for a data scientist role and I had to interview with over a dozen people including multiple leaders within the company. Even before I was invited for a face to face interview, I underwent a coding assessment (timed). I usually do not do well in timed challenges as they make me nervous and I can get flustered easily. They rejected me after the assignment (I received the news while I was waiting in the lounge of another company getting ready for my final interviews with the second firm for a Developer role). 

&amp;#x200B;

&amp;#x200B;

But after the rejection, I decided that it wasn't the best assessment of my performance and I took all the feedback the team had for me and re-did the challenge over the course of next week. I reached out to the company again with my results and asked them to reconsider my work (with little expectation). I think the company liked my initiative and they invited me for onsite interviews. I said yes to this since I had another offer for a different role from a startup. My onsite interviews were average at best and shitty at worst. I felt I did not do well and went to bed at 5 in the evening. I could not answer questions from past since most of these questions were from five years ago. During the technical interview, the interviewers were looking for a very specific answer, but I had zero clue on what exactly they were looking for. I felt comfortable defending my work, but that's about it.

&amp;#x200B;

&amp;#x200B;

By next noon, I got the dreaded call from the recruiter and she tells me that they really liked me (very puzzling). They wanted me to do a few more interviews with the team since the team wanted to be sure that I knew my shit. Now, to give you a quick idea about my background, I don't have much data science experience outside of some projects I did while on my free time and my startup which focuses on visual data. So I was pleasantly surprised that the company gave me an offer in like two hours after I finished my final interviews.

&amp;#x200B;

&amp;#x200B;

I want to thank this community since it would have been pretty difficult to prepare for the interview without some of the posts here. My only advice is, if you have the grit, you can be anything you want.",1
484,"I’m considering changing industries and something that sounds interesting is video game analytics. Has anyone out there worked as a data scientist in the video game industry? If so, can you share your experience? What’s it like?",1
485,,1
486,"Welcome to this week's entering &amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)  
* Traditional education (e.g. schools, degrees, electives)  
* Alternative education (e.g. online courses, bootcamps)  
* Job search questions (e.g. resumes, applying, career prospects)  
* Elementary questions (e.g. where to start, what next)  

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](https://www.reddit.com/r/datascience/wiki/resources) pages on our wiki.  

[You can also search for past weekly threads here](https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;restrict_sr=1&amp;t=month).

^(Last configured: 2019-02-17 09:32 AM EDT)
",1
487,"I'm currently a senior data scientist in a small startup in Boston. I'm looking to change companies in the next year and want to begin getting experience leading a team. My current startup is very small and flat organizationally. I basically own the production machine learning pipeline and don't work closely with other team members on it, so no opportunities to manage juniors, etc.

My goal is to eventually be in a VP/Director of Data Science position and recognize I need experience leading a team. Our engineering group uses Agile (loosely) and believe this is common for many companies.

Given that I am looking to make a job change in the next year, should I pay out of pocket to get the Certified ScrumMaster designation ($1K USD and two days of classes)? Would this be a differentiator when interviewing? I'm thinking it may provide signal that I'm committed to developing as a project manager/leader, and also be valuable in its own right. 

And before this gets raised, yes, I understand that my chief value will be based on my core technical skills as a data scientist. I am already heavily invested there. FWIW, my background is PhD in engineering from a great school, 4 years experience in risk consulting for nuclear/defense industries, 4 years data science/machine learning experience.

Thank you for the input!",1
488,"Hello all!

I’m currently working on transitioning into the data science field. Former quant research associate and have a solid stats background. One thing I can’t really stop thinking is that, am I preparing to transition into a field that might not exist? It seems like no one really has a strong handle on what’s going to happen in the field, so I am wondering if I’m transitioning into a field just to transition back out, if I should focus on a more specified job (ML engineer, data engineer, etc.) or how to navigate things. Advice would be greatly appreciated!",1
489,"For those of you working in the field and have experience seeing the process of new employees being hired, 

How much value do you put in verified certificates from online courses? 

I’ve logged a healthy amount of hours and completed courses from various MOOC platforms (EdX, Udemy, Coursera, Datacamp), but have never paid for a verified certificate. Do you think for somebody pursuing employment that it would be worth it to pay for verified certificates? 

Thanks in advance for any insight ",1
490,,1
491,"I currently work as a data scientist at a Biotech company, that has no established data science team, leadership or infrastructure.  I have a Master's in CS  (specialization in data science) from a top 5 CS college and and undergrad from a top 5 engineering college in India. I joined the company right after college because that's the only job I got and there seemed like a big scope for introducing the company to some data science. However, after 2.5 years of coaxing and trying, my colleagues, management and leadership don't consider data science to be a priority and hence I've only been working on exploratory projects  (that use a little bit of Deep Learning) that have never made it into a product. I spend majority of my time doing data engineering and just vanilla scripting on Python and Matlab to automate otherwise labor-intensive  manual analyses. My skills and resume have suffered deeply over the last 2.5 years and I am clueless as to how to explain to recruiters and companies what I've done in the last 2.5 years at this company. I have interviewed with a bunch of companies and it CLEARLY shows that my data science skills have taken a deep hit when I'm not able to answer simple questions. I have taken multiple online courses and professional development programs, but that doesn't seem to be helping. I personally think I would make a great data scientist at any company. I would really appreciate any ideas on how to go about improving my current state of affairs.",1
492,"Hi Everybody,

&amp;#x200B;

I'm not sure if this is the exact right sub for this question--I posted it over in r/jobs as well but I was hoping to get some feedback from people in my field if possible.  

&amp;#x200B;

I was wondering how much flexibility telecommuting employees have as far as where they work from. For some context, I currently live in New York (In Data Science / Analytics) but my SO may be doing a degree program in England. I don't want to fully give up my NY residence if I don't have to, so I'm looking for remote opportunities which would allow me to work from either the US or the UK. My ideal situation is one where I could spend 2 or 3 months at a time in either country, while working remotely full time. Is this possible? Most Remote Data Science opportunities I've seen say something like ""Work from anywhere in the US"" but I'm not sure if this means you can't work outside the country, or just that you need to be based in the US (citizenship, resident, paying taxes etc). I'm born and raised in the US so that wouldn't be an issue.

&amp;#x200B;

So for anybody here with experience in a remote analytics role, were you free to work from wherever you wanted, provided you had a good internet connection and made yourself available during business hours?  

&amp;#x200B;

Thanks in advance!",1
493,,1
494,"Incompetent interviewers are so frustrating. Companies really need to do a better job of screening the people they allow to conduct interviews. 

So the situation was that I was in an interview process with big company that has a big AI group. I finished my second phone screen two days ago. The first one went really well. I really liked the person. I answered all of their technical questions and I received an email that they wanted to move forward.

The second guy was pretty weird. He didn't introduce himself, and I had to stop him to ask his name. He then proceeds to ask me about the one non machine learning project on my resume. I start to tell him about it, and he asks 

""Well do you have any ML experience? Because we do a lot of that here.""

Well then maybe you should ask me about the three other ML projects on my resume which you clearly didn't read until you asked me that question. I then started to tell him about one of the ML projects on my resume. He asks a few questions in that annoying way, where interviewers try to poke holes in your work to try to through you off balance. I'm thinking ""Dude I worked on this for a year. I know what I'm talking about."" I answer his questions and he seems satisfied.

He then asks me a few basic ML questions (e.g. explain linear regression and SVMs). I easily answer those. He asks me a coding question, which I also easily answer. Throughout this whole time he's challenging me by asking questions on things that he clearly doesn't understand that well. He tried poking holes in my solutions, usually by saying things that we're just wrong, which led me having correct his understanding of basic things (e.g. What is a random variable). I try my best to do it politely as possible.

He then says that he doesn't have anymore questions and if there's anything I want to ask him. I ask a few basic questions about the company, and we call it a day.

I get feedback today that they're not moving forward because of my lack of knowledge of NLP. Dude didn't even ask me about NLP. If he did he would know I'm pretty freaking knowledgable about it. We ended the interview 15 minutes early, which I don't maybe he could have used to ask me about NLP if it's so important. 

What's really frustrating to me about this is the AI group there is really large and the fact that I had a problem with this interviewer doesn't mean I wouldn't fit. In other situations I would just say ""Well at least I don't have to work with him."" But from talking to the other guy, I think I would have actually fit in really well there, and I just had bad luck by getting this one guy as an interviewer.

Anyway I guess there's not much I can do. Rant over.",1
495,"This is kind of a rant, but I see so many people who parrot the sentiment that ""data science"" degrees are a joke, or that it's ""just applied statistics"" and that there's a stigma. 

I don't have a degree in data science so I don't really have a skin in the game but to me, such arguments seem like a mix of gatekeeping and ""no true Scotsman."" I come from a pure math background and I've seen mathematicians say very similar things about statistics or physics or CS: ""oh that's really just applied math"" or ""they are not really rigorous like math"". And I found that incredibly annoying and I guess the reason why I get annoyed by this sub's hate for data science too.

I see people coming from data science or business analytics degrees from schools like MIT, NYU, Carnegie Mellon that do just fine. Obviously these are good programs and there are countless other shitty data science programs not worth their salt. But it's the same thing with degrees in statistics or CS, innit? Yes, the popularity of statistics and CS means these master's programs have been sprouting like rabbits too. It's not just data science. Crappy schools that hastily create these programs for more money will be crappy. It's true of any degree, really.

So I'm not sure why people keep shitting on data science degrees, other than to make themselves feel better and superior.",1
496,"I’ve talked a few data scientist and it seems that the model the model that’s often used in implementation is Random Forest. I’m wondering outside of an implementation environment, how can machine learning models be used to inform decision making in a non production environment? ",1
497,,1
498,"I’m looking to hear from those with in experience on both sides of the pond or with some reference point to compare the two. 

I’m thinking along the lines of 

- job market competition and mobility
- tradeoff between salary vs benefits
- education requirements
- career outlook
- career &amp; social status

Any thoughts? I’m happy to hear about regional differences too. ",1
499,"I was like one of you folks once, trying to think how to write a resume before I started working as a full-stack dev at a place I love. Over the years I have obsessed about how to make it easy for every one to build their resume. Using some AI magic, I ended up creating a site (a side project) that allows you to create a resume for free. Here’s the link: [https://thisresumedoesnotexist.com/](https://thisresumedoesnotexist.com/)

I've used [https://github.com/minimaxir/textgenrnn/tree/master/textgenrnn](https://github.com/minimaxir/textgenrnn/tree/master/textgenrnn) to generate the text by feeding it data scraped from various resources. My script runs in a ""while true"" loop and generates a new resume every 3-4 seconds. Resume is then saved to S3 and the same resume is loaded via CloudFront for all users.

I plan to make it more and more awesome, like you add your name and designation and it fills up your resume. But, I thought it would be nice to get a feedback from you folks and see if I can add the to my to-do for the side project.

I’d the following thoughts on why I started working on it:

\- I knew a guy who got a job at Google, who previously couldn’t get a job at an IT agency just cause his resume wasn’t good enough

\- Not all of us have the skills required to write creatively and organize it. That doesn’t mean you don’t qualify for a job

Things like these are weirdly still a hurdle for many (it is going to be 2020 next year!). I want them not to be a hurdle anymore :slightly\_smiling\_face:

So, pitchfork me if you hate what I built, but if you loved it or have any suggestions do share your thoughts with me. Appreciation will make my day, critique will help me shape it.

Thanks,

Alex",1
500,"Hello everyone. I’m currently in my last two semesters of graduate school earning my MSc in Data Science. Does anyone have experience being asked to pay for your own ticket to fly out to an interview for an internship? I have some friends claiming it’s complete BS for a fortune 100 company to ask me to pay for my airfare while others are calling me entitled for even asking them to pay. I feel that the company asking me to book airfare the week of is not very considerate of the financial situation most students are in. If anyone could just share their experience I sure would feel much better regardless. I have an open mind and don’t really know if I’m in the right or wrong here.


Edit:
Asked for skype interview, been ghosted the last 24 hours. I think I dodged a giant bullet. If anyone else has a similar experience with New York Life I would love to hear it.",1
501,"I recently read [this article](https://www.bain.com/insights/advanced-analytics-global-private-equity-report-2019/) from Bain’s Private Equity practice, and I’m curious if anyone has any experience with this kind of work. (I’m also interested in how this might relate to Bain’s [Macro Trends](https://www.bain.com/insights/topics/macro-trends/) practice.)

&gt;At a time when private equity firms face soaring asset prices and heavy competition for deals, advanced analytics can help them derive the kinds of proprietary insights that give them an essential edge against rivals. These emerging technologies can offer fund managers rapid access to deep information about a target company and its competitive position, significantly improving the firm’s ability to assess opportunities and threats. That improves the firm’s confidence in bidding aggressively for companies it believes in—or walking away from a target with underlying issues.

**Questions:** Does anyone here use their data science skills for private equity research or economics for a consulting firm like Bain? What is that work like? What tools do you use, and how would you recommend someone interested in making a switch to that field? Any recommended resources to learn more about that career path?

**Background:** I currently work as a marketing strategist, I’m starting a dual-degree MBA/MS in Business Analytics in the fall with elementary programming and math experience (though I do have an MA in humanities). Yet I can’t decide if the Data Science or Financial Analytics track would be better for me getting further into my research and strategy career.

Any advice or wisdom is welcome.",1
502,"Yes, *it's superficial* and the person enrolling or (even, say, recruiters) would need to see the content of the programme e.g. individual coursework/ structure/ research *to get an idea of the package*. 

e.g.:

* MSc. in Data Science
* MSc. in Business Intelligence 
* MSc. in Predictive Analytics 
* MSc. in Business Analytics and Data Science
* etc. 

Some of these can be very different (content  or even field wise), but upon inspection of their structure, they would or could overlap considerably to the point their difference is moot, to both enrollees and recruiters. 

&amp;#x200B;

But, from a personal or professional-level, would the title of a Masters programme influence your decision for enrollment or even recruitment? ",1
503,Did the MSPH prepare you well for the job?,1
504,"Hey everyone, I'm considering switching my major from CS to Statistics &amp; Data Science with a minor in CS. I would be transferring to a different school for this, however. I am currently studying at Washington University in St. Louis and would be transferring to the University of Arizona.

My dad is against me transferring because of the drop in prestige. WashU is a top 20 school and U of A is a decent state school. He says that the name of your school will make a big difference when it comes to landing a good job. However, he is in the medical field so I feel like the impact of university ranking is much different when it comes to doctors. I know for engineering, outside of the powerhouses like MIT, Stanford, Cal, CMU, etc the name of your college doesn't make a huge difference.

I wanted to ask people in the field, how did the name of your university affect your job prospects? Would I be really worse off in my career by transferring? Thanks",1
505,"Dear fellow DS-Redditors,

in our company, my Data Science team is currently struggling with the 'last mile', i.e. have our insights and predictions bring about actual change.

We have sufficiently mastered the technical aspects, with APIs and platform at our disposal and available to others. Also, we've established trust with senior management executives.

What remains is to convince coworkers from other departments, e.g. sales, to work with us. Many hesitate to cooperate or to make use of our results and our work, and I feel like this boils down to a couple of human reasons:

* The generally resist change, especially when initiated by others
* Their division manager might have a long-standing rivalry with our division manager
* They see us and our suggestions/results as 'invading their territory'
* They view us as young and snobbish know-it-alls

How would you approach this problem? 

As a last measure, we could make our case with the executive level and have them pressure their guys to cooperate. However, we'd really like to solve this problem 'bottom-up' instead of 'top-down'.

Cheers and thank you!
Derek




PS: I found some resources describing similar problems, but I feel like they don't exactly match our situation:

* https://hbr.org/2019/01/data-science-and-the-art-of-persuasion
* https://www2.deloitte.com/insights/us/en/deloitte-review/issue-16/behavioral-economics-predictive-analytics.html",1
506,"Hello all, I’ve searched for an answer to this question but I am not satisfied with some of the answers I’ve found. I’m sure Python and R probably have a lot of custom features/libraries and you could probably design some very unique visuals OR handle massive amounts of data; however, a tool like Power BI just seems so much better for everyday business needs.

I guess I’d sum up my question as: “why write lines of code in Python to create a plot, change the width of the line, add a title, and make the bars of the values red and some blue, when you could just drag and drop? 

Finally in reporting using Python and R visualization, how do you distribute the results to customers? Export the charts to Excel? Can they be hosted on a cloud platform? I’m completely ignorant of how reporting works using Python and R visualization and I’m curious on hearing some explanations. 

Thank you! ",1
507,"As mentioned in an earlier thread, we know that there are several contributors to this subreddit that are in data science leadership positions, and we'd like to leverage that to help answer questions for the subreddit from the perspective of those in positions of (some level of) power.

For the sake of having some objective definition, we are defining data science leadership as professionals that fall in one of two buckets:

**Senior Management Data Scientists:**

* Supervise a team of data scientists
* Responsible for defining overall data science strategy for company (e.g., defining career paths, building capabilities, growing the footprint of data science within the company)
* Title expected to be Director level or higher (though not a hard rule as some companies brutally undertitle their people).
* Not necessarily expected to be most technical person in the organization

**Higher-level individual contributors:**

* May or may not supervise a team of data scientists
* Responsible for identifying emerging trends and their feasibility for your company, and to own the technical development of data science initiatives for your company/major function (e.g., Finance, Sales, etc.)
* Expected to be most technical person in the organization, and serve as subject matter expert for both junior data scientists and senior business leadership.
* Title expected to be Principal Data Scientist or higher (though, again, not a hard rule as some companies call their most senior data scientists just Senior Data Scientists).

**What we are asking from you:**

Once a month, we will post a thread for users to propose a question for the panel. The question with the most votes will be shared with the members of the panel through a direct message. You will then have one week to provide your answer to the question - we are expecting this to be a 2-3 paragraph exercise, so not something that requires an essay. Once you have submitted your answer, I will compile all the answers and post them to a new thread, referencing each user and their respective answer. We will the open the thread for additional commentary from the sub.

&amp;#x200B;

**If you believe you meet the criteria and want to participate:**

\- Send me a PM with a brief outline of your qualifications (doesn't need to be much more than what is included in your flair, would be helpful to include years of experience)

OR

\- Post your qualifications on this thread (same as above)

I will compile the list manually and then begin the process once we have a critical mass of people to answer questions. I don't expect to get an overwhelming number of sign-ups, but if we do, we may change up the panel on a month-to-month basis to get everyone involved and not end up with too many answers to the same question.

If you have any questions, feel free to ask them!

&amp;#x200B;",1
508,Wondering how people here store all information they need for their job. For example how-to's to clean data in Pandas or important Tableau tutorials.,1
509,,1
510,"[**Knitty**](https://github.com/kiwi0fruit/knitty) is a Pandoc filter and [Atom/Hydrogen](https://atom.io/packages/hydrogen)-friendly reproducible report generation tool via Jupyter, Pandoc and Markdown (fork of the [Stitch](https://github.com/kiwi0fruit/knitty/blob/master/docs/stitch.md) that is a [Knitr](http://yihui.name/knitr/)-[RMarkdown](http://rmarkdown.rstudio.com)-like library in Python). Insert python code (or other Jupyter kernel code) *to the Markdown document* **or write in plain Python/Julia/R with block-commented Markdown** and have code's results in the Pandoc output document.

Knitty is an important part of the [Best Python/Jupyter/PyCharm experience + report generation with Pandoc filters](https://github.com/kiwi0fruit/pandoctools/blob/master/docs/best_python_jupyter_pycharm_experience.md) (see there why writing in plain Python/Julia/R is great) but actually

Knitty is language agnostic and can be used with any Jupyter kernel. Can be used independently of Pandoctools and with any IDE of choise. So I guess it deserves a separate post. By the way: Atom/Hydrogen is also language agnostic. You can also try **VS Code** interface to Jupyter from [**vscode-python**](https://github.com/Microsoft/vscode-python) instead of Atom/Hydrogen. I highly recommend to try to think about ipynb as merely an output format like pdf instead of main format or intermediate format (albeit ipynb is great for presenting narrative interactively and it can even [be much more](https://github.com/kiwi0fruit/misc/blob/master/src/pdf_and_word_killer.md)). 

[**knitty repo**](https://github.com/kiwi0fruit/knitty).


### P.S.

[Knitty vs. Knitpy](https://github.com/kiwi0fruit/knitty/issues/1) joke.",1
511,"I have been working on a model for a few months, and I've added a new feature that made it jump from 94% to 99% accuracy.

&amp;#x200B;

I thought it was overfitting, but even with 10 folds of cross validation I'm still seeing on average \~99% accuracy with each fold of results.

&amp;#x200B;

Is this even possible in your experience? Can I validate overfitting with another technique besides cross validation?",1
512,"My company started having company-wide data competition. One thing that bugs me is that the expectations are to find ways to improve existing models or gain insights from the data (that supposedly weren't known before).

I just don't know if it makes sense to say your average data personnel (like myself) sprinkled across the company can beat our in-house research team that came up with the model.

So just curious about the possible motivation. Is it a low impact project that needs to be done but they don't have resource for it? Is it that they're looking for someone to go through the hassle of ensembling 100 different models to improve accuracy by .003? Or do they really believe in shooting in the dark hoping to hit something big?",1
513,"Hi everyone, first time posting here. I know Tableau isn't exactly ""Data Science"" per se but hoping some of you may have some experience using Tableau or other BI tools to share your thoughts.

Would love to get your thoughts/expertise on the best way to structure a Tableau team within an organization. Our team recently prototyped building reports using Tableau and management absolutely loved it. However, our concern is the amount of business partners that might come to us going forward to help build dashboards for them, which would be overwhelming.

Few Questions:

1. What do you think works better? A centralized or decentralized model? 
2. As a business unit, we are by no way ""IT"" and would want not want to maintain every single dashboard we build going forward.
3. Do you guys have a Tableau ""center of excellence"" to train other users in the organization on Tableau?

Thanks for your time!",1
514,"So I have a question regarding deep learning and more ""traditional"" machine learning usages in industry. My understanding is that deep learning is ""less transparent,"" in how it works, whereas ""traditional machine learning,"" is more transparent. This leads me to believe that for business use cases, such as for marketing, would prefer ""traditional machine learning,"" because the models can easily explain how they derived their results, whereas for a ""deep learning model,"" is less helpful if we're trying to explain why a prediction is off.

&amp;#x200B;

\^ Does anybody have insights on this? Has anybody (from industry) experienced less of a desire to use deep learning, because of not being able to ""justify"" the answers generated?",1
515,"Hi all,

&amp;#x200B;

Domain expert here, converted over to doing predictive modeling. My software engineering skills are poor, at best. I want to learn how to write production grade code that is versioned etc., and simulate putting models into production. Best way to do this would obviously be on the job, but unfortunately that is not a possibility right now.

&amp;#x200B;

What MOOCs, resources, tutorials would you recommend to start?  What about setting up pipelines and putting a model into production in miniature? The goal would be to get some background knowledge and to actually use it to do some projects at home that I can have in my portfolio.

&amp;#x200B;

There is no Kaggle or Datacamp for this stuff, so any advice is really appreciated!

&amp;#x200B;

Edit: Wow everyone, thanks for the suggestions! There is more than enough here to get me started. Hope other people interested in these topics find this useful as well.

&amp;#x200B;

&amp;#x200B;",1
516,"I'm currently looking into a career change and I've got my eye on big data. I've found 2 certificates from the university of Toronto and I was wondering about the differences between the two. 

Here's the first one -

https://learn.utoronto.ca/programs-courses/certificates/data-science

Now here's the second one -

https://bootcamp.learn.utoronto.ca/data/

What I've noticed is that the first one is more statistics heavy while the second one has a much stronger focus on programming. But why? What is really the difference between data science and data analytics?",1
517,"Welcome to this week's entering &amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)  
* Traditional education (e.g. schools, degrees, electives)  
* Alternative education (e.g. online courses, bootcamps)  
* Job search questions (e.g. resumes, applying, career prospects)  
* Elementary questions (e.g. where to start, what next)  

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](https://www.reddit.com/r/datascience/wiki/resources) pages on our wiki.  

[You can also search for past weekly threads here](https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;restrict_sr=1&amp;t=month).

^(Last configured: 2019-02-17 09:32 AM EDT)
",1
518,"I've noticed that across the sub we have at least a handful of members that are a bit further in their careers - Directors of Data Science or Principal Data Scientists (or equivalent).

Would there be value in trying to identify the people that are in these roles and having a weekly feature were these people are asked a question and we post the answers? I think it would be good to get some more substantial answers to questions that are popular, and also to be able to compare and contrast answers based on role and experience.

Thoughts?",1
519,"Hi, i am what in the industry is called a data scientist. I have a master's degree in statistics and for the past 3 years i worked with 2 companies, doing modelling, data cleaning, feature engineering, reporting, presentations... A bit of everything, really.

At the end of 2018 i have left my company: i wasn't feeling well overall, as the environment there wasn't really good. Now i am searching for another position, always as a data scientist. It seems impossible to me to get employed. I pass the first interview, they give me a take-home test and then I can't seem to pass to the following stages. The tests are always a variation of:

* Work that the company tries to outsource to the people applying, so they can reuse the code for themselves.

* Kaggle-like ""competitions"", where you have been given some data to clean and model... Without a clear purpose.

* Live questions on things i have studied 3 or more years ago (like what is the domain of tanh)

* Software engineer work

Like, what happened to business understanding? How am i able to do a good work without knowledge of the company? How can i know what to expect? How can I show my thinking process on a standardized test? I mean, i won't be the best coder ever, but being able to solve a business problem with data science is not just ""code on this data and see what happens"".

Most importantly, i feel like my studies and experiences aren't worth anything. 

This may be just a rant, but i believe that this whole interview process is wrong. Data science is not just about programming and these kind of interviews just cut out who can think out of the box.",1
520,"I recently got my first job as a data scientist and wanted to share some thoughts about the job hunt process and tips I found helpful for landing a first gig in the field.

&amp;#x200B;

Some background (without giving away too much PI): I had a varied education and career path to this point. Both my BSc, MSc, and PhD were in STEM fields. I decided to make the switch to data science after seeing some friends have success in the area.

&amp;#x200B;

I had no formal experience in data science/AI, although I had much coding experience (mainly python and matlab) from my degrees. So I decided to self teach data science and then apply for jobs. There were many ups and downs in the process as a whole, and a lot of lessons I learned as I went along in the job hunt.

&amp;#x200B;

To form a solid understanding of the machine learning field, I started by going through a machine learning primer on [pythonprogramming.net](https://pythonprogramming.net). I found a nice mix of math theory (low level) and code. The course covered all of the main algorithms used in machine learning by first explaining the behind the scenes idea and then coding a algorithm from scratch and then (in some cases) using it on a dataset. Towardsdatascience also is great (for the right author) for getting a quick easy overview of something.

&amp;#x200B;

After this I applied to my first round of jobs, and found that this is probly not enough to get in the field. I got a few interviews, but response rate was about 7% of my applications (applied for about 50 jobs). I applied for all jobs online, via indeed, glassdoor, etc. While applying I started an excel file listing all applications and dates applied. This gave me a way to measure response rates and see what helped increase this.

&amp;#x200B;

So, after realizing I needed something more, I took on a new undertaking. I reworked through in depth math of the popular algorithms using Elements of Statistical Learning (textbook freely available online). Then, I found some data sets online (either off kaggle or the UCI repository) and went through an entire in depth project on these sets. Data cleaning, exploratory analysis, predictive. I mean really clean out the problem, I read publications about the dataset, established baselines, interpreted results, etc. I then made a github account and made a data science portfolio and posted a couple of projects on there. Then I reopened the application process and applied to about 50 more jobs. IF YOU TAKE AWAY ANY ADVICE TAKE THIS: make a porfolio and post a project. Choose a project that is socially relevant and any layman could see why its interesting (ie healthcare, not Gaussian data distributions). This astronomically increased my responses. I would estimate that, per 20 applications, I got interviews for 5-6 jobs. After much interviewing I finally got a good offer which I accepted.

&amp;#x200B;

Interviews follow the same basic structure everywhere, and here's what I learned going through them:

1. The HR screen. After bungling a couple of these I finally figured them out; after an HR screen now I would say I have a near 100% conversion rate to a second round interview. They don't know technical stuff, they want to get an idea of who you are and make sure you aren't a weirdo and can articulate yourself. So here's how to ace them: find a project you worked on and explain the technical concepts to them in VERY easy to understand ways. I found explaining algorithms using sports analogies very effective. Relate the project to someone who doesn't care about data science; why is the problem interesting, what are implications of your results. Besides that be prepared to answer the basics like ""why are you interested in this company"", ""how do you face challenges"", etc.
2. 2) the technical interview. The contents of this stage really varies. Most times, I would be asked to explain technical aspects of my DS projects. They would start off with ""explain a project youve worked on and how you solved it"". Why did I use this algorithm and not another, why did I do a dimensional reduction, how did I clean the data, etc. Then, I would get asked to explain the workings of a particular algo I had used. Some would ask that I explain it to someone who didn't know about computers, and some would ask I explain the math and algorithm structure. If you paid attention to my first point you'll be ready for the layman explanation. So be prepared for both. I would really prepare a nice ""lecture"" about an algo, because some would just say ""explain your favorite algorithm"".  Some will go through your resume and ask you to explain buzzwords, so be prepared for that.
3. 3) the coding challenge. These are annoying. They are generally easy, most I got were binary classification problems. A couple I got were just data sets and they said ""do something interesting"". If you've done a DS project it shouldn't be hard. The annoying part is that most would say ""this should take about 4 hours, heres 5 days to turn it in"". So what I imagine happens, is some candidates spend 4 hours and get some interesting insights and send it off, and others spend 5 days straight doing a crazy analysis of it. One company arranged a time I would like the challenge to be sent to me, and I had to submit results within 4 hours. I think this is the best format, as it really puts everyone on the same playing field. I would suggest doing a very simple practice classification problem from a common dataset (the UCI wine thing for example) and just get a ""template"" ready that isn't too difficult to change between basic datasets. Also, some jobs that blasted me a dataset without a phone call or email first I found quite rude and didn't pursue.

&amp;#x200B;

Final tips: I know many people on this sub complain about buzzword resumes; but Ill offer a different take. The people who get a giant pile of resumes to sort through are the HR people; I had a friend who is an HR rep for a DS company look over my resume. These HR people don't know DS; they have a job description for a role that has buzzwords in it (candidate should know regression, tensorflow, blah blah) and they match your resume to that. So I found that by including buzzwords  (listed algorithms I knew, math I knew)  I increased my response rate.

&amp;#x200B;

Also I added a section in my resume explaining the DS projects I had done and tools I used to do them (bold font the tools for fast reading), this also increases response rate (link to your github portfolio too). All in all, the job hunt process is a meat grinder and sucks. I sent out a total of about 100 job applications, got a couple cheapo offers that I declined, and accepted a solid one. I completed about 30 interviews. The whole process took about 3 months. The jobs I didn't get interviews for I think is because I didn't match the description exactly or didn't match the experience requirement, lots of them want big data framework experience which I didn't have (hadoop, apache etc). This would be easy to learn, but the screeners don't know this really so probly tossed my resume. I would've learned it myself but getting 4 coding challenges a week bogs you down a bit :P.

&amp;#x200B;

Remember, the increase in interview requests and inceased knowledge is not just a correlation, it's a causation. As you're applying, learn something new everyday.",1
521,"What are your thoughts? Are you going to switch, have you switched? ",1
522,"My company currently has a bunch of disparate marketing data sources coming from places like google AdWords, Facebook ads, Bing ads, commission junction, and many others. The company currently accesses each source using their respective webportals, which obviously is very limiting when it comes to analysis and multi attribution touch point modeling. 

We don't have a data engineer on deck that can build a pipeline from these sources, so I'm seeing this as an opportunity to learn how to do this myself. Google (praise thy name) has led me to some Medium articles on using fb apis to access marketing campaign data, but I haven't had much luck searching for Google AdWords (Google shopping) API tutorials for data pipelines, Bing, or others. I typically end up at websites selling prebuilt connectors, which is a bit frustrating.

Has anyone had experience doing this that can provide me with some links to useful guide, lessons, etc where I can start learning how to do this using Python? I'm looking to extract data from the apis, put it into a pandas dataframe and then write it into our SQL database...is this the right approach?",1
523,Google just released Tensorflow2.0 alpha!,1
524,"Hey guys, 

We're two friend who met in college and learned Python together, we co-created a package which can provide an estimate for the training time of scikit-learn algorithms.

Here is our idea of the use case for this tool:When you are in the process of building a machine learning model or deploying your code to production, knowledge of how long your algorithm can help you validate and test that there are no errors in your code without wasting precious time.

As far as we know there was no practical automated way of evaluating the runtime of an algo before running it. This tries to solve this problem. It especially helps in the case of heavy models when you want to keep your sklearn.fit under control.

Let’s say you wanted to train a kmeans clustering for example, given an input matrix X. Here’s how you would compute the runtime estimate:

    From sklearn.clusters import KMeans
    from scitime import Estimator 
    kmeans = KMeans() 
    estimator = Estimator(verbose=3) 
    #Run the estimation 
    estimation, lower_bound, upper_bound = estimator.time(kmeans, X)

Check it out! [https://github.com/nathan-toubiana/scitime](https://github.com/nathan-toubiana/scitime)

Any feedback is greatly appreciated.

&amp;#x200B;

edit: Code formatting",1
525,"I'm releasing Dequindre to the open source community under an MIT license. Checkout the project if you'd like, but I'm going to talk about Dequindre as an idea that became a full solution in the OP. Here are the links if you're interested:

[PyPI Project](https://pypi.org/project/dequindre/0.10.0) | [GitHub Repo](https://github.com/vogt4nick/dequindre/tree/0.10.0) | [Read The Docs](https://dequindre.readthedocs.io/en/0.10.0/)

---

### Why build ""a minimalist scheduler""?

A few months ago [I asked what the sub thought about current data pipeline technologies](https://www.reddit.com/r/datascience/comments/9uz05o/whats_your_opinion_on_current_data_pipeline/). The consensus was that Airflow was the best option, but every popular option requires significant resources to learn and implement.

I'm a data scientist working on a young product. I made that post at a time when we were unsure how to automate our data pipeline. Airflow is free, sure, but things weren't breaking yet and the time investment made Airflow an expensive option for us. We decided to point CRON jobs to shell scripts instead. It was fast, cheap, and easy to debug in the rare event of failure. It wasn't a permanent solution; it was a good-enough-for-now solution.

I revisited the problem a couple months later, and I realized there must be hundreds of teams like mine in this limbo: still unable to justify the cost of Airflow and growing too fast to rely on CRON and shell scripts. Clearly there's a need, yet there was no such scheduler that I could find. 

I started engineering my own solution. I didn't need all of Airflow's features. I thought, ""What can I take away from Airflow to make scheduling more accessible?"" I took away the UI. I took away the sqlite database. I took away asynchronous scheduling, bash operator, and triggers. I kept the scheduling, dynamic configuration, python operators. I even added some functionality to support virtualenv, pipenv, and conda environments. 

What remained was Dequindre: a minimalist scheduler I could setup in minutes. It's production-capable too. We're migrating to use Dequindre on my team at work. 

### What's Next?  

Dequindre v0.10 marks the start of ""public beta testing,"" which means I'll be answering public bugs, questions, and feature requests. I'll release Dequindre v1.0 when I'm confident the core functionality is tight. Right now I guess that might be April or June. There might be a v2.0 and beyond, but Dequindre is minimalist by design; there's only so many features I'll consider adding before recommending something more full-featured like Airflow. ",1
526,"When you are dealing with large data, how can we make sure, our system is still process it. I am dealing with 1555394 rows, 14 col data frame. My algo work fine on small chunk. But how can i make sure it is working on , because my system showing processing for about half an hour. And is there any way we can get intermediate result.. generally speaking . How can i know, if my system is not gone out of memory?",1
527,"If so, a couple questions:

* how'd you do it? 
* did your total comp go down when you did? 
* was it worth it?",1
528,"Background: 

I'm a few weeks into a new role at a startup as Data Analyst.  My team onboarding experience has basically consisted of ""ask the other data staff members anything, but don't expect anything proactive from them.  Documentation? What's that?""  I'm a career changer from a non-technical field in my early 30s.  The company is your classic tech startup - most employees 26 years old, move fast and break things culture, perpetual state of ""Series B funding deal should close any week now"".  Learning the company data structures has been basically consisted of pulling the teeth of my teammates, piecemeal.  It's been a difficult experience, to say the least. I want to be proactive at making things better for the next person, as well as teaching myself the ropes.

&amp;#x200B;

My questions:

\- What are your favourite strategies for introducing new employees to company-specific data knowledge?

\- Any tips for starting from scratch creating documentation for vast existing data structures with new tables emerging every week? Enforcing the docs' maintenance?

\- Success strategies for adaptable, willing newbies for what questions to ask to make everyone's life easier?  This includes stakeholders such as those who consume reports, managers, rest of data science team, and of course me.

&amp;#x200B;

I'm flailing right now - any guidance appreciated!",1
529,"Background:
I work as a lead project manager for a very large company. I am good at my job (or at least my yearly performance reviews say that) but I honestly don't like my job. I am regularly given failing projects and tasked with replanning the project. The stress is wearing me out. I want to work in data science - I'll have my MSc in data analytics within the year and I'm working on creating a portfolio and getting my first data science job. I incorporate data science techniques into what I do and I credit that with what makes me successful.


Situation: 
My company is very antiquated and slow to adopt new technologies. At the end of last year they announced they were going to start embedding data analysts within teams and hire some data scientists. I thought great, here's my chance to get into the field. 


I cannot get an interview to be a data analyst because, according to the hiring manager, I don't have experience. It's frustrating because I regularly demonstrate the application of the needed skills and knowledge, but okay fine.


Fast forward a few weeks a newly hired data analyst is imbeded with my team. I try to make the best of it and think, hey, I can talk data science with this guy.


The person hired doesn't have a background in data science. He doesn't know statistics or any programming languages. He had to ask me for help writing a simple SQL query so he could put the data into Excel and make a pivot chart. The hiring managers are business people who don't know anything about data science. The data analysts are being used as Excel jockies.


I don't fault the people hired as data analysts but it frustrates me that the managers have no idea what they are doing in regards to hiring and utilizing data analysts. I feel like within my company they are devaluing data science by having people not in the field doing the hiring and management of the analysts. It's looking more and more like I'll have to leave the company to work in my desired field. That will be difficult because I'll likely have to take a pay cut to get a job elsewhere.


This rant sounds a bit gatekeeper-ish and makes me sound conceited, but I'm just frustrated with the managers trying their best to use as many data science buzzwords as possible while not actually doing anything data science related.",1
530,"Hey folks,

I’m a sole Data Analyst at a small to medium company in the Upper Cumberland region of Tennessee. 

I’d love to join any groups / meetups / online geo-specific message boards etc.

If anyone knows of groups within this area, Nashville, Chattanooga, Knoxville, that would be awesome!

Thanks ahead of time. 

",1
531,I'm a data scientist for a Fortune 500 company in Bay area for almost a year and a half. I still get like 5-6 messages at least from LinkedIn every week about possible opportunities mostly at companies like startups. I don't want to waste their time since I'd not consider joining startups at this point of my career (also due to visa issues) but I feel like my interview skills will get rusty over time if I don't keep practicing them. Is it a bad idea to take their calls and take the interview even if I probably stay where I am anyways?,1
532,"Suppose you discovered a strong link between sunny days and apple's share price over the last 6 years, is it reasonable to act on that correlation going forward based on the longevity of the correlation or would you still want a logical reason to explain the correlation? Are there any systematic ways to eliminiate spurious correlations? If it cannot be explained, is there a minimum amount of time passed that can be used as confirmation? ie, if the same correlation has existed for 10 years or 20 years. ",1
533,"To be more specific, I am talking about the situation where you have deployed a binary classifier (could be multiclass) into production where you are taking actions on people based on the predicted outcome score from the classifier. One thing I have been thinking about is what kind of metrics to use to validate the confidence of the actual score outputted by the model. e.g. If a model outputs a score ('probability') of 0.74, what is the expected chance that the predicted event will actually occur?

&amp;#x200B;

The initial assumption might be that there is a 74% chance but that seems to be confusing the model's score with a confident probability which doesn't seem right. I've also looked into MC DropOut as a method of estimating confidence, but I'm curious about situations where Neural Networks aren't in play. My initial guess on how to approach this would be to deploy the classifier for a while and collect data on it's predictions and the actual future outcomes. Then, taking all of the predicted scores (that we take no action on), I would bin them up so that there's a bin for all the predicted scores in \[0.7, 0.75\] and a bin for predicted scores of \[.85, .9\], and so on. Then, I would calculate the average proportion of people that had the event occur, and would expect roughly 72.5% of the people to have the event occur in the first bin, etc.

&amp;#x200B;

But, I'm wondering if there is any way to quantify this better? I'm guessing research has probably been done on this and I just haven't come across it. Any ideas on good lines of research to look into, or maybe examples where this is already being done?

&amp;#x200B;

TL;DR: I've heard of Bayesian deep learning methods like MC Dropout that let you estimate how confident the model is in it's prediction. However, are there any techniques that generalize to more types of models that will let you estimate how confident you can be in your models predicted scores?",1
534,"Hey guys! My first post here and I hope you can understand my English!

**tl:dr:** Offered position as IT Audit, what is the relationship of that position with DS and would it be beneficial to take such position if my ultimate goal is to be a DS? (I still need to work more on myself to be able to apply for DS jobs). I guess the company just messed up positions and they just need people.

&amp;#x200B;

I applied for a job described as Data Scientist / Data Analyst in a big company somewhere in Europe. This big company has a new department in data analytics and they are hiring  new people as thing have been going well and they are understaffed.

 I go to the interview, I do a project, bla bla, you know the process. Now the thing is, before the last interview they told me my profile wouldn't fit one of Data Scientist, as I don't have the coding experience they are looking for.

Anyway, I understood that if I wasn't not becoming a DS I would be a DA ( From my research these are two different things, right?) . Now the thing is, the offer came something like an IT Audit position.

My background is in Finance and I have a  Master in Micro Data analysis.

What does my background has to do with IT Audit, and how is IT Audit related with data analysis and so forth?

My ultimate goal would be to be a Data Scientist, and I would like to know how (and if) being a IT Audit brings me closer to this goal.

My feeling is that they confused DS/DA and they just sold me the IT Audit because they need people.

Anyway, I am kinda confused right now about the whole thing.  
Wondering if someone could share their thoughs.",1
535,"I have been an analyst for several years, and recently moved into data science. Some of my roles have not always been terribly technical, because the employer was unwilling to provide tools. I have made do and practiced data science at home on my own time to improve or gain skills. 

I left my last job for what I thought was a long term data scientist role (government clearance!). It took 3 weeks to gain access to the data and once I finally did, it was incredibly messy and unstructured. I was told there will be significant and ample time for ramp up. I literally began building an NLP model yesterday and was looking to deploy it soon. 

I got the call from the staffing agency to not return to the facility due to lack of performance. They felt I made zero progress even though I was fleshing out issues and creating data science documentation for the team. Even when I asked, there were no clear details of what the organization was looking for. I had a path forward and expressed what I was working on to add value. If they wanted/needed something else, no one said a word. 

At 6 weeks, fired. Back to the drawing board again. I was told TODAY when I was being terminated they needed someone to lead the team and hit the ground running asap. When I interviewed with this company, none of these expectations were expressed otherwise I would have not taken the role. ",1
536,"I hope this is the right place to post my question. Quick facts: 

- We’re making an offer to our first data scientist tomorrow. 
- I’ve never worked with a data scientist before. 
- She’s a senior data scientist, if that means anything.
- Our product is an internal web app to help salespeople track down leads and make bigger deals. 
- We’re bringing her on to research ways to increase sales. 
- We run agile. 

I’ve never worked with a data scientist before. How do I define goals with her? How much should I be involved should I be in her workflow? How much slack do I give her to do research with no definite return?",1
537,"In my current job my title is Data Scientist but really I do a lot of dev work building prototypes for different ML/Statistics-based features. For me it feels so incredibly rewarding to see your prototype baby grow into a full fledged feature. 

However, in the last year several seniors left the team due to disagreements with management and I decided to start interviewing as well.

This is when I truly realized how data science really wasn't for me. I came into contact with several DS teams from different companies who develop purely in notebooks, spend all day writing SQL queries or spend more time in excel in a day than I have my whole life.

Nobody I met asked me a single programming question or even a question about system design. It really bummed me out until I started applying for SEng jobs with focus on ML/AI and realized this was my real title all along. 

Anyone else who struggled to find their true role in this sea of data science inflation?",1
538,"I have a Bachelor's Degree in Mathematics, and was accepted into a sixth month mentorship program under a data scientist with 7 years experience. Let's say I get 3 years experience as a Data analyst / Associate Data Scientist after my mentorship, then consider becoming a commissioned officer in the US military for 4 years to get the GI bill to help pay for Graduate School.

From your past United States Military experience, do you know if any Data Analyst or Data Scientist positions were available in the Military for officer personel that would count as authentic job experience on your resume?

Did you try to study Data Science while in the military? How hard was it, and how well did you improve your Data Science skills while completing your Military Service Obligation?

Did your service help you get experience and projects completed for certifications like 6-Sigma Black Belt?",1
539,"I am currently the manager of BI within a data team. One of my primary responsibilities is to help DS projects make it to production. Typically ""productionalize"" a project means make sure it continues to bear fruit in some kind of updated report. Typically a dashboard etc. I have completed the SCRUM master program and have been applying it within the team with the blessing of the chief data officer. He is asking me if I want to move into a BI architect role where I don't do development any longer and instead just help design it all and be the scrum master for the team (15 growing to 20). What are your thoughts on a data science SCRUM master? I have not seen anywhere where this role exist in a DS team. ",1
540,,1
541,"I’m a junior in my school’s data science program and have been having problems with some of my assignments, my laptop has 8gb of RAM and recently, with my bigger assignments and projects, my laptop can’t really handle it.  I am planning on getting a new laptop soon and was just wondering if it’s worth it to splurge for 32gb or if 16 will be enough for a career in Data science career. ",1
542,Anyone here create a DS team from scratch and have any advice to give? I took one of those jobs that most websites tell you to avoid; where you are hire number one for a DS team and where the company doesn't really have an understanding of DS. I am optimistic about the future and seem to get buyin for what I want but am hoping to learn from successes and pitfalls of others. ,1
543,"I recently had an interview for an entry level data scientist position. At one point the interviewer scoffed at using sklearn or other similar packages because: 1. he didn't ""trust it"" and 2. his data ""wasn't the kind you could just plug into a [model.fit](https://model.fit)()"" but was more ""nuanced and complex"".  For those reasons he instead builds all of his machine learning models from scratch. In my opinion it stuck me as a bit arrogant to think that an open source software is to be trusted less than something one or two people have fully reviewed.  But I'm also not sure of how many situations there are in which there is no available library or prepackaged model, or it is more advantageous to DIY.

Few questions here:

1. Does anyone else here find standard machine learning libraries such as sklearn untrustable? If so why? Are these models not to be used in production for some reason I'm not aware of?
2. How often does a data scientist really need to build these models themselves? Or put another way how big a project does it need to be before meriting a self-built approach? e.g. I can imagine prebuilt models being the go to for quick analyses but when company's core product is centered around a machine learning algorithm it may make sense to build it from scratch. I'm wondering what it looks like between those two extremes.
3. In what scenarios is it preferred to build a model from scratch? I can understand the situation where a library or language isn't available in a production environment, or the model needs to be written in a different programming language. I'm more interested in cases where this is a decision from the model builder and not imposed by infrastructure requirements.

Also throwaway account because interview specifics. and edited for clarity.

&amp;#x200B;",1
544,"I've been speaking to a PhD recruiter about data science positions at Google, and I wanted to see if anyone on here works/worked (or know about) as a data scientist at Google and can give some insight. What does your day to day life look like? How much coding do you do? Do you code in high performance languages (e.g., C++) or mostly in interpreted languages (e.g., Python)? How much does your position involve ML?

&amp;#x200B;

Ideally, I want to be in a position where I can focus on machine learning and software engineering, and from speaking with the recruiter, it seems the data science positions at Google is very applied stats heavy. She sent me a study guide for the phone screening, and it's very stats heavy, a lot of stuff, which I have learned from previous stats courses many years ago that I have forgotten. So I'd probably need to put in a lot of time to study stuff related to that just for a phone screen..

&amp;#x200B;

I'm trying to decide if this is something I'm interested in pursuing and/or if it fits my background. She made me aware that for PhD applicants at Google, you can only do a single-track interview process, meaning that I wouldn't be able to simultaneously be in the interview process for a data science, software engineering, ML position. She said she could put me in touch with the recruiter for the PhD ML software engineering positions, so I'm curious to find some information about the positions labeled as ""ML software engineer"" before deciding which track to pursue. The title ""ML software engineering"" sounds much more aligned with my background and interest but I was always under the impression that ML and DS positions have a lot of overlap and are pretty much the same positions?

&amp;#x200B;

&amp;#x200B;",1
545,"When you start a new project at work that is public facing in some way, does your project manager ever bring up ethical issues or outcomes?

We have regular racial awareness trainings and other equality workshops and I really appreciate that we do discuss these things even if we cannot always solve it. But at the same time, we don’t discuss how our products could have unwanted impacts. It’s the we do as we told situation. 

While the title of the article is a little dramatic it was an interesting read.

https://medium.com/s/story/data-violence-and-how-bad-engineering-choices-can-damage-society-39e44150e1d4",1
546,"I'm a big fan of python pandas. 
When dealing with bigger datasets I had to resort on Spark, which is cool but I don't really enjoy as much as pandas.

I'm searching for something in the middle, and found Modin and Dask. They are both subset of pandas but way more scalable.

What's your experience on this tools? Which do you prefer and why?

https://modin.readthedocs.io/en/latest/
https://dask.org/

Thank you! ",1
547,,1
548,"Wanted to get this community's thoughts around this latest news article (also included a response):

[https://www.bbc.com/news/science-environment-47267081](https://www.bbc.com/news/science-environment-47267081)

&amp;#x200B;

Quote from the article (please read the full article as it's short):

&gt;“Often these studies are not found out to be inaccurate until there's another real big dataset that someone applies these techniques to and says ‘oh my goodness, the results of these two studies don't overlap‘,"" she said.  
&gt;  
&gt;“There is general recognition of a reproducibility crisis in science right now. I would venture to argue that a huge part of that does come from the use of machine learning techniques in science.”

&amp;#x200B;

I also found this respectful response from Favio Vasquez -

[https://towardsdatascience.com/a-quick-response-to-genevera-allen-about-machine-learning-causing-science-crisis-8465bbf9da82](https://towardsdatascience.com/a-quick-response-to-genevera-allen-about-machine-learning-causing-science-crisis-8465bbf9da82)",1
549,"Hi all,
I’ve lurked here for a while since I’ve been working part-time on a Masters in Predictive Analytics at Northwestern. I recently accepted an offer as a Data Scientist at a consulting firm, so I’ll be jumping from a business analyst job into this vast world of data science. 

My question is whether anyone here has found ways to shortcut the learning curve being new-ish to the field? Are there practical things I can do or habits to acquire so that when I start I’ll be set up for success?

As an aside I’m documenting my job search process so I can help those just behind me in the process of becoming a DS. Will post on that thread once I’ve finished. ",1
550,Everyone at my office uses Excel. I want to use what I'm learning in DS at work so I can practice and implement it. The problem is that everyone at work uses Excel and no one uses SQL/Python in their usual workflow. How can I make this adjustment work?,1
551,"[https://www.coursera.org/specializations/deep-learning](https://www.coursera.org/specializations/deep-learning)

&amp;#x200B;

I would really like to know if anyone found this specialization valuable and worthwhile?  I have taken some courses on Coursera that were not always great, just wanting to get feedback before making this investment of my time. ",1
552,,1
553,"I've been a professional 'data scientist' for nearing on 4 years now, and as I'm sure many others have noticed, the term can mean wildly different things depending on where you are employed. After being in industry for a while I've observed there tends to be about 4 main different flavours of 'data scientist':

**Data Analyst**

5 or 10 years ago, these people would've just been called BI analysts or data analysts- just doing basic data viz, reporting, dashboards and SQL querying. Then companies started to try and sex up these positions by giving them a new buzzword title 'data scientist'. There may be a few of these people who do some basic ML and stats but in my experience this is uncommon. Usually good with tools like Tableau etc

**Statistician**

Again, 5 or 10 years ago, these people would've just been called statisticians or mathematicians. They focus mainly on inferential modelling or if they do predictive it's using traditional statistical techniques like linear regression. These guys are highly skilled in stats theory and some in ML as well, but they tend not to have great CS/software engineering skills, and usually their work consists of ad hoc analyses that they aren't responsible for delivering to production. Typically program in R, or in more old school organizations maybe something like SPSS.

**Machine Learning Engineer**

This is where the major growth area in 'data science' has been in the past 5-10 years IMO. These people typically have good CS/Software Engineering skills and are involved in deploying models to production. They tend to focus mainly on predictive models and most will be in strong in more 'modern' ML techniques, but some (not all) may be weaker in 'traditional stats' models. Work mainly in Python but may drop down to lower level languages when required.

**Data Engineer**

These people range from plain old DBAs rebranded to Big Data Engineers who work with Spark/Hadoop/Cassandra etc and work in Scala or Python or maybe even Java. The Big Data Engineers might also be proficient in the ML libraries specific to their particular big data architecture.
 
---

To me, all of this begs the question, should we just ditch the terms 'data science' and 'data scientist'? In my opinion, they are vague, generic buzzwords that do nothing but confuse people. Be interested to hear other people's thoughts though.

It'd also be great to have a little bit of discussion about my classification system, do people think I've missed some categories, got some things wrong? Which types of 'data scientist' do you think are most in demand, attract the best salaries? What proportions of the 'data science' industry are employed in each area? What qualifications do you need for each subtype?",1
554,"As a data scientist, it’s important that you lead data evangelism efforts at your company.

The effort you put into these initiatives can lead to increased trust and credibility for you and your team. Without these two things, no matter how great your technical abilities are, your ability to impact your company will be limited.

In this article, I explore six initiatives that can help you achieve this goal. Let me know your thoughts/if you have other data evangelism efforts worth looking into!

https://towardsdatascience.com/why-data-scientists-need-to-lead-data-evangelism-efforts-f433f7fac936",1
555,"Hi friends,

I'm currently looking for a budding data science teammate to build out and expand on the analytics for an app I'm working on. What's a good place to look for budding data scientists looking to grow the resume/portfolio?

**Background**:

Last year, I spent several months studying data science in hopes of working in behavioral health analytics. I loved it, but grew tired of analyzing random datasets for my portfolio; I really wanted to analyze my own data, but wanted to automate the process as much as possible. I switched over to web &amp; mobile dev and began work on the app in React Native. After several months, I finally launched the app in December. I was proud of the product, but also recognize that it needs some love, especially on the analytics side. Soon after launch, I landed a mobile dev gig at a startup and haven't had time to sit down and do everything solo like I used to. It has a (very) modest user base and I want to continue development on the side. It's obviously just volunteer work - the app is currently free - but I'd be happy to chat about options if it goes somewhere!

Anyway, many thanks. If this isn't the sub to look, my apologies. If you do know where I might find interested souls, please let me know!",1
556,,1
557,"Sure is an exciting time to be in data science! Particularly so with the magic of machine learning (ML). Why it’s so exciting that it’s attracting millions of highly intelligent and deeply trained future professionals. Hence, I think we should reflect on the future of data science. Here are my predictions…

Blog post: [What does a Principal Data Scientist look like in 2025?](https://medium.com/@matthagy/what-does-a-principal-data-scientist-look-like-in-2025-545a571ec89f)

&amp;#x200B;

Let me know what you think. Personally, I may be focusing more on my software engineering skills going forward.

&amp;#x200B;",1
558,,1
559,"Does anyone have any experience organizing large data analysis projects? It seems that the majority of project organization tools for data science (DVC, datmo, mlflow, etc) assume a very model-centric approach.

On the other hand, I am currently dealing with a project that doesn't need any predictive models, but contains lots and lots of data to be explored, analyzed, summarized, and re-organized (rich geographic datasets can be quite multidimensional and messy). As the result the project directory looks approximately like this:

    ./DS-project
    |
    |__ data/
    |
    |__notebooks/
    |    |
    |    |__thing_to_analyze_1/
    |    |    |
    |    |    |__01_aa_analysis1.ipynb
    |    |    |__01.1_aa_analysis1.ipynb
    |    |    |__02_aa_analysis2.ipynb
    |    |    ...
    |    |
    |    |__thing_to_analyze_2/
    |    ...
    |
    |__src/
    |    |
    |    |__utility_package_1/
    |    |    |
    |    |    |__README.rst
    |    |    |__setup.py
    |    |    ...
    |    |
    |    |__utility_package_2/
    |    ...
    |
    |__README.md
    |__environement.yml

Currently the biggest pain is caused by the notebooks. We are following notebook naming convention suggested [here](http://drivendata.github.io/cookiecutter-data-science/), but due to the sheer number of `thing_to_analyze_x` folders and the number of notebooks in them, it can be quite hard to find previous research (even when notebook summaries are documented in some sort of README file).

Does anyone have experience dealing with such projects? Date based project/notebook naming seems quite interesting (e.g.: `2019-03-05_thing-to-analyze-1`), but I'm afraid it might make it harder to understand which stuff is old and which stuff has been recently revisited.

",1
560,I am about to complete my B.COMM in Finance &amp; Analytics and would like to go the analytics route and work towards becoming a data scientist. Will Datacamp be useful for me in pursuing that career path? I have knowledge in C and Python already to work with. ,1
561,"Not sure if this is the right subreddit for this but I’m running out of ideas.

I’m trying to do a report on some lesser-known data services. Does anyone know of a ‘data service’ that would fit a company who’s service portfolio includes Data Enrichment and Data Cleansing services atm?",1
562,"There is a interesting question in the Python community about standartizing API that exports and accepts fast functions so that computation utilizing multiple packages can happen outside of the Python interpreter. Unfortunately it's not that popular question. Sometimes it turns into [Cython/Numba/C/C++ battles](https://github.com/pydata/sparse/issues/126).

There is a discussion of this issue: [Why Julia? Will Python/Numba and Python/Cython lose to Julia?](https://github.com/numba/numba/issues/3814). And I cannot foresee any solution to this disarray except maybe [interop at the C level](https://numba.pydata.org/numba-doc/dev/user/cfunc.html#example). If there would be a PEP specification for such API then it would be even better. But I guess the solution to this should be as pythonic as possible (mentioned Numba tools to create C functions in a pythonic way are really good).

But I'm not sure how scalable is interop at the C level approach (it's merely my lack of knowledge). Can there be compositions of compositions?

## Python to Julia transpiler

In contrast to Python Julia language doesn't suffer from lack of unified API and it constantly enriches packages ecosystem that can be easily combined. Now it even has a stable release. This actually brings another possibility to fix the problem mentioned.

It would be nice to have Transpiler from subset of Python with special module named like ""Juthon"" to feature-complete subset of Julia (sometimes there are more than one way to do something in Julia).

And a idea looks like it should both be:

1. Standalone transpiler so that the user can write ""Juthon"" package and contribute it to the Julia ecosystem by transpiling.
2. Runtime decorator style transpiler (with interface like Numba has) that calls Julia (or compiled python library in the future) from Python. So that a small piece of code can be added right in the Python app written in Python.

I wonder if 2. possible though... If not then something like [enaml import](https://github.com/nucleic/enaml) can be tried that wraps transpiling and wrapping of Julia call. This can even be preferable approach.

A good example of a transipiler from Python is [Transcrypt](https://github.com/QQuick/Transcrypt/issues/619) that is a valid Python prior transpiling. But to achieve 1. this should be more like Julia in Python syntax than attempt to implement Python's standard library.

I guess it should be done via IDE friendly mapping and juthon module with source to source mapping for Julia autocompletion and lynting passthrough as it seems that automatic creating of typed and documented python stubs would require more work than source mapping; for example Julia to python transpiling for other modules inspection. That would mean lack of type inspection inside IDE - errors should be displayed by jit transpiler and later julia compiler.

[GitHub issue for this](https://github.com/kiwi0fruit/misc/issues/6).",1
563,"I ask this question because whenever I job searched, employers didn't really seem to care too much that I had background in the same industry as their company.

I've also met a lot of data scientists who ""industry-hopped"" from all kind of fields from pharma to finance to tech to online retail, etc. It seems to me that either companies don't really care that much about domain knowledge, or that domain knowledge is typically very easy to learn on the job. Would this be fair to say? 

If not, then when is domain knowledge helpful, and how can companies benefit from having data scientists that are very knowledgeable about the ins and outs of their domain?",1
564,"Hi guys,  


For a research project I need to make a data set out of film/movie clips. Obviously those clips are copyrighted. I am wondering could, splitting such clips into the individual frames that are then labeled be classed as fair use? It is purely for educational/research purposes and isn't going to be used to make money.  
",1
565,,1
566,"... What are your favorite tools for extracting/exploring DBs that don't require you to write SQL?

DISCLAIMER: I know SQL really well, so please no posts here about how everyone needs to learn SQL. I just get sad whenever I have to write a SQL query because the syntax is so redundant and painful.

My current go-to is to use dbplyr and DBI, although it does require some hacks/workarounds to do basic things with MS SQL Server, or else just to hook Tableau up to my DB and go to town.",1
567,"Welcome to this week's entering &amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)  
* Traditional education (e.g. schools, degrees, electives)  
* Alternative education (e.g. online courses, bootcamps)  
* Job search questions (e.g. resumes, applying, career prospects)  
* Elementary questions (e.g. where to start, what next)  

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](https://www.reddit.com/r/datascience/wiki/resources) pages on our wiki.  

[You can also search for past weekly threads here](https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;restrict_sr=1&amp;t=month).

^(Last configured: 2019-02-17 09:32 AM EDT)
",1
568,"Hi people! 

&amp;#x200B;

I am a data scientist fond of R programming and visualization.

I mainly use R, python, sql.

What are your essential tools and softwares you use for your daily work? 

&amp;#x200B;

My basic set up:

* Rstudio (must have)
* Sublime text 
* Atom
* Jupyter lab (as an alternative for jupyter notebook basic) 
* Notion (for documentation) 
* Pg admin (for sql queries... and I am looking for an alternative!)
* Orange (for quick visualizations and modeling) 
* Looker (as a tool for dashboard and analytics) 
* Heap Analytics (for even tracking on website = in my case - ecommerce)

Curious to get some new inspiration to make my workdlow smoother! 

&amp;#x200B;

Chhers :) ",1
569,"I work 50-55 hour weeks on average, but I’ve worked 60-70 occasionally. I wish I could work 35-40.

What’s typical in data science? How much do you work? Does this differ between industries, specialties (data engineer, analyst, scientist, manager role)?",1
570,"I'm Data Scientist for 4 months now and in our DS/DE team I am the only one left with a Windows notebook. Everyone else is using a Mac or a Linux system. I'm thinking about switching to one them because whenever I my colleagues try to teach me something no one knows how to do it on a Windows machine. With a Mac or Linux machine this would not occur.

So which OS are you using and where are the pros and cons especially when it comes to working in a DS team?

Thanks!",1
571,"I listed some questions I have. Take what you like and leave what you don’t:

- What questions did you choose to ask? Why? Did you change your mind about anything? 

- If there was a project, how much weight did it have in your decision to hire or reject the candidate?

- Did you learn about any non-obvious red flags? 

- Have you ever made a bad hire? Why were they a bad hire? What would you do to avoid it in hindsight? 

- Did you make a good hire? What made them a good hire? What stood out about the candidate in hindsight? 

I’d appreciate any other noteworthy experience too. ",1
572,"According to the [Bureau of Labor Statistics](https://www.bls.gov/ooh/mobile/fastest-growing.htm),  Statistician, Software Developer, and Mathematician are ranked #7, #9, and #10, respectively, on the list of fastest growing careers. Everything ranked higher than these careers are either in the field of renewable energy (solar panel installer) or healthcare (home health aid, physicians assistant).

So my question is why do so many people complain about the job market in Data Science when it's pretty much a mix of these 3 fast growing fields?

Is it because the industry has a higher barrier of entry than others and people are trying to get a DS job with just a BS? Would having an MS in Stats or CS (or both) make getting a job much easier? Or is this not the case? ",1
573,"I'm already knowledgeable on Python (pandas, numpy, etc) and SQL but I am interested in learning to map and visualize geospatial data. I know this is possible with Python using libraries such as geopandas, osmnx, and folium but I'm wondering whether Python is industry standard for working with geospatial data. I know ArcMap/ArcGIS exist so maybe those are so dominant it isn't worth spending the time to learn how to work with geo data in Python.

Any thoughts are much appreciated.",1
574,"Hi, we've recently had a new starter in our team. I get to work directly with her on projects. I'm pretty excited to be working with someone else, though I'm used to largely working solo.

Any practcal tips for working together, I'm thinking mainly from a coding perspective but open to whatever. I don't have a CS background, we're both pretty new to DS so I'm learning this stuff as I go.

To give an example, I have one file which runs all my functions, so they can run it and not have to remember which function gets called first (they came mid way thru a project I've been working on so I did the bulk of the work). The inputs/variables I've stored in a csv file I list in .gitignore because then they can play around with my code/ input variables without version control detecting a change.

Thanks.",1
575,"Trying to become a better all around data scientist/machine learning engineer candidate. I have never deployed a machine learning model outside of calling sci-kit learn in a flask app. I came across a blog post that shows a more realistic way to deploy models: [https://towardsdatascience.com/how-to-deploy-machine-learning-models-with-tensorflow-part-1-make-your-model-ready-for-serving-776a14ec3198](https://towardsdatascience.com/how-to-deploy-machine-learning-models-with-tensorflow-part-1-make-your-model-ready-for-serving-776a14ec3198).   


Can the sub recommend any books or video series to learn more about doing this? ",1
576,"I am looking to make interactive dashboards from data in a SQL database on a Linux machine. I have bit experience with data visualization packages in Python (plotly,matplotlib, seaboarn) but i feel these  aren't as  intutive and quick to build full dashboards as tableau and spotfire, but these programs (desktop verisons) seem to be only on Windows. 

Is there any good tools like these out there for Linux or has anyone gotten good results from using wine with some Windows data visualization tools?


Really looking for a tool for data visualization on Linux that I can quickly design a dashboard or a chart data quickly through a GUI as well as expansion to add functionality with Python through interactions on the dashboard (like in spotfire), finally as well would like to eventually be able to host the dashboard as a website while still including the Python functionality

Also has anyone used Google's online dashboard tool? Seems Interesting but haven't properly checked it out yet",1
577,"Recently I read an article: [Why Numba and Cython are not substitutes for Julia](http://www.stochasticlifestyle.com/why-numba-and-cython-are-not-substitutes-for-julia/). As I understood the main benefit from Julia is packages and math algorithms ecosystem that can be combined and reused. But they are put together during JIT compilation when in Python packages are put together during interpretation. So there is less bottlenecks and it's actually much more convenient to combine math algorithm this way.

The convenience matters a lot.

So I'm curious if I understood the main idea right and is there a really big deal about combining this way instead of another? If so then why there is no Numba specific packages ecosystem in development that can also be combined JIT compilation way? Or there is actually such Numba packages ecosystem being built and I'm simply not aware of it?

[Further discussion](https://github.com/numba/numba/issues/3814).
",1
578,"I want to start a data science business for (legally) collecting, analyzing and selling data from apps and wherever I can scrape but I'm either scared to ask about it or don't know how to do so without raising a flag on NSA, CIA, or whatever. ",1
579,"I work at a small startup with a fair amount of VC backing which has its ups and downs. I knew the deal going in since I've worked exclusively in startups for the last 10 years as a developer or data scientist. We all wear different hats, take on different roles, and no one person is assigned just one job. All of that is fine with me when it's within my realm of knowledge.

&amp;#x200B;

Lately, I've been asked to do shittier and shittier tasks. I've written so many powerpoints/slidedecks for our presentations and sales meetings that it's making me want to leave. I don't enjoy writing sales decks, I'm not good at it, and when I do them there's typically a lot of revision. The founders see this as ""professional development"" and enhancing my ""professional communication"". When I pressed them on my professional communication being lackluster they said no, that it was great for communicating with our clients and within the office. I asked them why they felt I needed further development, and their response was that I should know how to sell our product and services so that I could give presentations to clients. I told them I have no interest in learning how to be a salesman, attending sales meetings, or being involved with the sales side of the business.

  
They're still having me do these tasks because I have the greatest knowledge of what we do and the vast majority of the services/products are my work. Has anyone else been in a similar position and how did you get yourself out of it other than quitting? I'd rather not quit, I love the actual work we do, but this continued push for me to be more tied in with the front of the business is wearing me down.",1
580,"I'm a data scientist at a medium sized fintech company in Chicago, and I'm trying to convince my skeptical boss to start an internship program. He reluctantly agreed as long as I was mainly responsible for the day-to-day running of the program. 

I was actually never an intern myself in college, so I have no idea where to begin. I'm thinking a part time semester long internship may be best to begin with so I have a little time solo to work on my own job and have some time to figure out tasks to give the intern. 

If you've been a DS intern in the past, how did it go? Did you end up accepting a FT offer from the company afterward? Were you ever bored or didn't feel like you had enough to do, or did you feel overwhelmed? How were tasks delegated? I also want to include a career mentorship component, so if you had any experience with that, I'd love to hear about it.

If you've run a DS internship before, how did you balance your own work and mentoring the intern? Did you give them a single project to work on or just random tasks from other projects? Did you offer them a FT job afterwards? ",1
581,"I am a soon to be graduate in economics with a minor in data analytics and working on writing a program that simply pulls data and does some basic analysis. 


Unfortunately the BLS and most other primary sources don't allow scraping on their websites. I'm looking for inflation, unemployment, larger index fund (DOW, S&amp;P, etc), and maybe housing price data. Ideally from a couple reputable sources that I can crawl with some regularity. Does anyone have any good leads or ideas?

Apologies if this question is a bit 'below' this sub, Im really not sure of a better sub to ask lol.",1
582,"So I've been looking into [shorthand writing](https://en.m.wikipedia.org/wiki/Shorthand) systems which are what reporters and stenographers use to transcribe conversations. It's basically creating a reduced writing system and including use of symbols to write faster, and it will generally require some expertise to ""decode"". Experts in shorthand can apparently write over 200 words per minute.  
  

Naturally from here I started thinking about what the digital equivalent to shorthand would be and I've thought of some random ideas that may have a place in a similar system:  
   
  

- Text expansion, if you went crazy with this then there would likely be a huge learning curve.  
- Using a typed shorthand system like [keyscript](http://keyscript.wikifoundry-mobile.com/m/page/Alpha+Shorthand+Systems), then decode it with some ML system, although I'd imagine that this would have a lot of challenges.   
- Predictive text
",1
583,,1
584,,1
585,"So, I didn't get any comments on this elsewhere and I thought I'd try this subreddit: I've only just started reading about ML and have come across [this paper about composing melodies from (Chinese) lyrics](https://arxiv.org/abs/1809.04318); earlier I saw [this paper](https://arxiv.org/abs/1612.01058), which is apparently the basis for a new iOS app. The first approach, using RNN, seems to get much better results than the second (random forest), but, as you can imagine, it's way more sophisticated. So I'm wondering how difficult it is to implement something like the RNN approach--with GRU, encoder/decoder, and so on--given the description the authors have provided (and a boatload of MIDI tunes with lyrics). Thanks for any input.",1
586,,1
587,"I'm an experienced data scientist (I actually lead a large team) and am reasonably literate about computers, though I am not a developer or IT professional. My organization is split roughly 50/50 between Python users and R users (and a few unicorns who are proficient in both). The general consensus, with which I don't disagree, is that R is generally better for data analysis/exploration/visualization because of dplyr and 
ggplot2 (tidyverse), and Python is generally better for machine learning because of sklearn, Keras, and Tensorflow. And yet, R is good enough for machine learning (mlr, caret) and Python good enough for data analysis/exploration/visualization (pandas, matplotlib) that you don't \*really\* need to learn the other unless you stumble upon some problem for which there is no library in your preferred language.

I started out using R when I got into data science because the guy who was showing me the ropes was an R guy. I was able to quickly and easily get RStudio installed on my machine, load up the packages I need, and start learning the language. R has plenty of quirks, but it has served me well over the years and I am able to do pretty much anything I need to do with it short of really complicated deep learning, which isn't really a requirement at the company I'm at anyway. For nearly all of our ML problems, some combination of linear regression, random forests, or XGBoost will get the job done. And mxnet actually works pretty well for deep learning in R.

However, I always want to expand my skillset, and I have tried several times to work in Python. The first time, a friend showed me how to set up a Jupyter Notebook and I was able to get some basic things working in that after several hours of trying to set it up. The biggest pain was realizing that I had to install Python on a path without any spaces in it and then go set my Windows path variable to get it to work. I eventually decided that R tools suited me better and went back to R. I tried again a year later when I wanted to play around with deep learning and was able to get TensorFlow working after **several** **days** of wading through their never-correct documentation, scraping message boards for help, and eventually finding a blog post that solved the rest of my problem. Then I decided that the syntax was way more complicated than it needed to be (I wasn't aware of Keras yet), and went back to using mxnet in R.

The other day, I discovered the reticulate package for R and have been trying to get it to work, with no success. I have read through all the documentation, tried using conda\_install() and use\_python() to create a virtual environment with all the libraries I need, but it is failing to find numpy. On the reticulate page, my exact situation exists as an open issue and there has been a long chain of discussion but no resolution. Several hours down the drain.

My point is, RStudio installed just fine on the first try. All the packages load and work pretty much right away. I've never had to worry about keeping several version of R on my machine or changing any environment variables. I haven't had to spend endless hours digging through message boards just to get R to *run*. I really want to learn to like Python, but it *really makes itself hard to love*. I'm too busy to spend days and days setting it up and tweaking things. Why hasn't one of the most popular programming languages in the world been able to get some *basic* things right such as, ""You can run this installer on Windows 10 and it will work out of the box""?",1
588,"Out of curiosity, if you have a vision that you are about to code, can you just sit there for a while and write it? I feel like I’m a dummy for having to lookup the syntax and inputs for every other line. Idk what the standard is though, I’m a math geek who taught himself. So I get it if it would be unusual for a C++ expert to know the kurtosis of a lognormal distribution. Idk.. thoughts on the topic would be nice. ",1
589,"I feel like the ultimate goal would be to be your own boss and just cooperate with companies when they need help interpreting data. 

Would anyone here categorize themselves as this and how did you become it ?",1
590,"The python post was great. Best package I learned about was shap. Defiantly diving into that. However I prefer to work in R. We all know about keras, tidyverse, caret, etc 

So what are some other packages you find useful?

For me getting back into DS after long gap, I am rediscovering a huge set of new libraries so I don't know how well these are known but I have been amazed with [https://rstudio.github.io/reticulate/](https://rstudio.github.io/reticulate/) and [https://www.rplumber.io/](https://www.rplumber.io/)

&amp;#x200B;

&amp;#x200B;

&amp;#x200B;",1
591,"I’ve seen several people mention (on this sub and in other places) that they use both R and Python for data projects. As someone who’s still relatively new to the field, I’ve had a tough time picturing a workday in which someone uses R for one thing, then Python for something else, then switching back to R. Does that happen? Or does each office environment dictate which language you use? 

Asked another way: is there a reason for me to have both languages on my machine at work when my organization doesn’t have an established preference for either? (Aside from the benefits of learning both for my own professional development) If so, which tasks should I be doing with R and which ones should I be doing with Python?",1
592,,1
593,"I have a PhD in statistics and I've been in a few academic postdoc positions for the past 4 years. These positions have involved statistics, machine learning and deep learning. I've been trying to move to industry and I have finally secured a *data scientist* position at a mid-size startup company that isn't very well-known. I am looking forward to using this position to gain industry experience that would greatly enhance my chances of landing a  *senior data scientist* position. However, I am worried about how much data scientist experience counts when it's from an obscure and not very well-known company. Coming from academia, I know that having a degree or postdoc from a top-tier university makes you stand out from the pack. Is this also the case out in industry? Would *data scientist* experience from a top-tier company like Google, Facebook, etc. (or even mid-tier company) be considered more valuable than similar experience (in terms of scope and duration) from a relatively unknown startup?",1
594,,1
595,"I'm about to begin formally mentoring a junior peer.  I'm old and can't remember what it was like joining the workforce in the early days of the GWB administration.  Young data scientists of Reddit, what would you like to get out of a mentoring relationship?",1
596,"[https://research.fb.com/category/data-science/](https://research.fb.com/category/data-science/)  
[https://research.netflix.com/](https://research.netflix.com/)  
[https://www.aboutamazon.com/research](https://www.aboutamazon.com/research)  
",1
597,"I am very new to Autoencoders and anomaly detection, and am currently working on a credit card fraud dataset to understand how Autoencoders can serve in fraud detection. Please correct me if I am mistaken in my logic.

&amp;#x200B;

Objective: Binary classification of whether transaction is fraud (1) or non fraud (0). 

&amp;#x200B;

After loading the dataset in, I have done some basic feature engineering (normalization \[-1,1\] etc). Next, I separate the non fraud class (0) from the fraud class (1) (values as well as target variable).

&amp;#x200B;

After doing this, I feed only the non fraud data/target as my training data into the autoencoder using Mean Squared Error as my metric of evaluation. From my understanding, this is what will serve as the Reconstruction Error that is being used to compare the classes.

&amp;#x200B;

Finally, I predict using the autoencoder on the fraud class (1) data and calculate the Reconstruction Error on that data.

&amp;#x200B;

At this point, I have the Reconstruction Error from both classes. From my understanding, we use this Reconstructor Error to differentiate between data that is of the class Fraud and Non Fraud.

&amp;#x200B;

Suppose that I want to feed in a user input into my Autoencoder model that I have built to classify whether that data is fraud or not. How would I go about doing this from the point that I am at now? Would I just call ""[autoencoder.fit](https://autoencoder.fit)(userdata)""? Would that essentially give me a Reconstructor Error value to compare?

&amp;#x200B;

Any help would be great as I am very new to this concept!",1
598,,1
599,"Every article I can find just list the essentials like numpy, keras, pandas.

What are some lesser known libraries that are useful?

I'm thinking of things liem [great-expectations](https://github.com/great-expectations/great_expectations) and [pandas-profiling](https://github.com/pandas-profiling/pandas-profiling).",1
600,"I notice more and more recently that there seems to be quite a handful of data scientists with poli sci backgrounds. Drew Conway (the creator of the famous data science Venn Diagram) has PhD in political science. So does Chris Albon, who used to host the popular data science podcast Partially Derivative. Stanford literally has a data science track for their undergraduate political science curriculum: [https://politicalscience.stanford.edu/undergraduate-program/tracks/data-science-track](https://politicalscience.stanford.edu/undergraduate-program/tracks/data-science-track). In addition, a simple LinkedIn search of political science and data science will return a suite of profiles of data scientists with poli sci backgrounds.

When did political science become so data driven? My impression was that it used to be mostly about reading Hobbes, Locke, or Fukuyama and the like. So how is data science used in the academic discipline of political science? What tools or methods that are used in political science are transferable to data science exactly?",1
601,"Hello everyone! 

I am a budding data scientist working for a major municipality. In 2018 we started as a small data science team of 4, working from our laptops. Eventually, we got a linux server where we could host our work and deploy our first model on. However, this server is hosted outside of our company's architecture.

During this time, our municipality is making a hard push to become data driven, including automation of data entry, storage, and an overhaul of our IT architecture. I feel this is an excellent opportunity to take our data science team to the next level, and try to push for a small but complete architecture that can help us deploy our models internally. This would be a major help since we could directly connect to the existing databases (where now we have to use manual extracts to feed our models).

However, this is where my knowledge gets stuck. I have been reading up on things like linux, spark, docker, etc. But it's difficult for me to form a comprehensive overview of what architecture is standard for data scientists, and (maybe more important since I have to defend and push for this) why we would need this. 

For example: I try to push for docker implementation in order to shorten the gap between our new engineering team and the end product of data scientists (since the engineers want to use docker too). However, I don't know exactly why docker works so well for this and why it is better than other tools. However, I need to know this in order to defend our choices.

Any help with a comprehensive overview providing me with a structure regarding architecture and deployment would help greatly! (or anyone chiming to provide their knowledge from experience).

thanks in advance!",1
602,"As a part of a Data Science Team, visualizing our findings and results is crucial for making our work accessible to other colleagues in our team as well as other teams.  Until now I have used almost exclusively the python library matplotlib where I have become pretty proficient. In the past few weeks I have experimented with bokeh and holoviews for interactive charts and I really want to make those charts visible to other people than just me with my Jupyter Notebook. 

So I guess my first question would be wether you also use interactive charts?

My second question is about publishing those plots. I would need a running python process in the background when having the plots exposed because with a pure HTML file the browser can only interpret the javascript code embedded in the plot. As I understand it a bokeh server seems to be a practical idea. And then? The guys at bokeh - I think - are working with AWS and Elastic Beanstalk to show there demo plots. What do you think of this solution? Is it practical for a Data Science Team to publish these plots through an AWS Python Web App? Our Engineers are AWS Pros so the knowledge in our team is there. 

Thanks for your help!

Bokeh Demo Plots: https://demo.bokeh.org/movies
AWS Beanstalk: https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/create-deploy-python-apps.html",1
603,"Hi,

I was wondering what your experiences are when it comes to Segregation of Duties.
I am working in financial industry and quite often I find the role of data scientist a bit problematic with regards to the standard Business/IT/Operations setup that is enforced. 

Just to clarify - in essence it comes down to a point where one should not be allowed to keep production data on development servers, having write rights on development servers is allowed only for IT developers, developers cannot have access to production data... I think you get the point. 

I can hardly imagine the work of a data scientist without the possibility of trying out various algorightms on production (non-scrambled) data.

How do you guys deal with that? Anyone feeling like sharing their experiences?",1
604,"I saw they made a crappy implementation of FP-Growth. That's one of the slowest algorithms for FIM and using Java for HPC is the dumbest idea ever. IT GIVES YOU UP TO 100X SLOW DOWN OVER PROPER C++ CODE. If you're using Java/Hadoop for anything you should change career, because you are a fraud.",1
605,"I'm a recent convert to the Scala programming language and I'd like to show other data scientists just how powerful basic Scala can be. The most recent article in the series is particularly fun because we get to analyze actual reddit data by writing and running Scala code in our browser. See the blog post, [Interactively exploring Reddit posts using basic Scala in your browser](https://medium.com/@matthagy/interactively-exploring-reddit-posts-using-basic-scala-in-your-browsers-f394843069de). Learning some interesting things about Redditors...

&amp;#x200B;

What do you think? Does this article demonstrate the power and simplicity of basic Scala? Do you find it interesting to analyze Reddit posts and therefore find the article more engaging than something that just shows off the language?

&amp;#x200B;

Are any parts of the article and examples unclear? If so, let me know and I'll improve them. In general, I'd appreciate any critical feedback because I'd like to get better at developing such educational resources.

&amp;#x200B;

Lastly, any thoughts for other data exercises that would be even more interesting? Hoping to soon show people how to spin up a small ad hoc Hadoop cluster in 15 minutes using Databricks so people can work through big data exercises using basic Scala within Spark. Any particularly big data sets that you think people would like to explore in programming exercises?

&amp;#x200B;

Thanks!",1
606,"I heard that Stitch Fix has 50+ data scientists (not data analysts that they just call data scientists, I think). Does anyone know of other companies with such a large DS department?",1
607,"Hey, I'm interested in running my first multi armed bandit (instead of an AB test) but I'm struggling to find info on how long to run the experiment for,or how to tell significance. Normally in an AB, we would calculate the statistical power and significance needed to detect a minimum change. But I was wondering if this was the case with a MAB.

Is it as simple as seeing when your success metric starts to level off and then perform a t test or chi squared test on the variants? ",1
608,,1
609,"I'm a little confused, maybe I just read wrong info.

But are the typical data scientists supposed to code for machine learning ? 

I thought the first and foremost important knowledge &amp; skill is on stats/math &amp; business.  And programming is the least expected.",1
610,"A few days ago I began to think about how a company could implement a data science process, understanding that this type of implementation is transversal to all areas since it involves data collection to the delivery of results. For a process of this nature to be successful, it also implies a change in the mindset of managers and executives. Moreover, for that, we need to show what are the main benefits of making such a profound change in any company.

It also involves looking for the appropriate profiles according to the type of company, so that they support the necessary daily tasks.

&amp;#x200B;

This article deals with: what is data science, its benefits for a company, what a company needs to implement them and the necessary profiles.

&amp;#x200B;

I would like to hear some feedback about the points expressed here: [http://www.thinkingondata.com/implementing-data-science-process-in-your-company/](http://www.thinkingondata.com/implementing-data-science-process-in-your-company/)

&amp;#x200B;

Thank you!

&amp;#x200B;",1
611,"I’ve been working on a project for client that involves risk analytics. I was brought in to help with alternative modeling, but the client is proving difficult to work with as they’re expecting me to interpret the model results for them at a higher granularity than I am comfortable with. 

When working on joint projects like these, where do you draw the line on where your expertise ends and where theirs begins?  I’ve been trying to get the client to work with me on interpreting the results, but they’re not being very cooperative, instead leaving it to me to interpret the output. I have a surface-level understanding of risk, but I feel this isn’t enough to make concrete recommendations.",1
612,"I'm working on a project to assess FAIR policy of different knowledge graphs already in existence and was wondering which has the worst FAIR implementation and needs work to make it better.
Can be anything, but It'd be better if the topics is not super complex and something I can get right into without any proper background. ",1
613,"Welcome to this week's entering &amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)  
* Traditional education (e.g. schools, degrees, electives)  
* Alternative education (e.g. online courses, bootcamps)  
* Job search questions (e.g. resumes, applying, career prospects)  
* Elementary questions (e.g. where to start, what next)  

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](https://www.reddit.com/r/datascience/wiki/resources) pages on our wiki.  

[You can also search for past weekly threads here](https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;restrict_sr=1&amp;t=month).

^(Last configured: 2019-02-17 09:32 AM EDT)
",1
614,"I have read with great interest on this thread, especially (this thread)\[[https://www.reddit.com/r/datascience/comments/ats06d/im\_a\_data\_scientist\_starterpack/](https://www.reddit.com/r/datascience/comments/ats06d/im_a_data_scientist_starterpack/)\], as we all seem to have different perspectives on what constitutes a data scientist, and what core skills, so I thought I'd try something, which is to crowdsource a collective view within this subreddit of the key skillsets required.

&amp;#x200B;

Approach:

1. I will start off by posting top level comments as generic skill sets that are either business, technical, statistics and mathematics related.
2. Upvote the ones you believe are important core skill sets, but DO NOT downvote any other skills if you disagree/don't know is key. If you don't agree with a skill set not being core, simply don't upvote.
3. Leave your comments as second level comments so the top comments are always relating to the skills in question.
4. Add skills you think are important but you don't find them in top level comments.
5. By the end of the whole exercise, with enough votes, I believe we should then be able to see our crowdsourced key skills for this profession that are sought after and are important to being a good data scientist/analyst (note: my methodology may have loopholes, so please feel free to suggest some changes, I have a research methodology and statistics background but don't profess to be an expert, so comments welcomed)

&amp;#x200B;

If this whole approach sucks, heck, at least I tried!

&amp;#x200B;

&amp;#x200B;",1
615,,1
616,"Every time I finish a project or report, I get this overwhelming sense that I made a huge glaring mistake somewhere that I can’t see. This leads me to compulsively check, re-check, triple check my work, my math, my code, my assumptions and conclusions, wondering if something in the underlying data may have screwed me over somehow. I know having a healthy dose of skepticism is good but... I guess I’m looking for strategies/advice on how to keep that in check.

Edit: typo",1
617,"This is a little lengthy but I hope you find the story interesting and would greatly appreciate any feedback.

Some history that brought me to this point:

* Transitioned from a Software Engineer to Data Scientist role \~5 years ago, while working at a mid-sized software company in an extremely niche market in a smallish city.
* Got the opportunity to work on some run-of-the-mill problems (data analysis, classification, forecasting) and not so run-of-the-mill problems (rebate optimization for cooperative purchasing / buying groups).
* The business was interested in the results but never interested in moving our data science initiative forward as they weren't really forward thinking.
* My role slowly transitioned to managing the development and implementation of a new reporting solution using a software problem plagued with bugs, affording me less time to maintain existing models and continue to innovate; less time to practice data science.

As a result of the last event, I decided to look for another job with the constraint that I wouldn't be able to leave the city. Since there isn't a huge tech presence here, the frequency of data scientist job postings is about 0-1 times per quarter. Lucky for me, one popped up and I jumped on it, I was getting pretty miserable going back to managing a dev team at the company I'd been working for for 7 years and felt like the move was long overdue.

Not only was I desperate to get out of my current role, but the context and scope of the posting appealed to me - a data science role at a multinational company within a large (\~150 person) finance team (finance as in cost and management accounting and internal audit). Within the team I would be data scientist #1.

I haven't come across any literature on data scientists embedded within finance teams so I thought this would be a challenging albeit rewarding opportunity if I could innovate in the accounting space. The organization has a dedicated data science team focussed on innovation and run-of-the-mill user experience and revenue problems which admittedly sounded a little sexier but the team is located in another city.

My concerns:

* I accepted a slightly lower salary though it could be more if I'm awarded a discretionary bonus, based on overall company performance, and maximize my retirement savings investment matching plan.
* I have left a software company that was starting to embrace modern technologies (Azure, Docker, Angular, more reliance on web services) which would pave the way for the adoption of ML / AI in some of their products though we were probably 2-3 years away from it.
* The company I have accepted a job at seems very focussed on a small subset of problems which mostly could benefit from some data mining at best as they feel that opportunity exist but we need to discover it. For example, my first task is to complete a project that the previous person who was in my role had got to about 80% completion with. One of my short-term responsibilities is to establish KPIs, build some dashboards for users in operational and strategic roles, and help converge on a change management strategy since analytics is foreign to a lot of people at the org. Once the project is complete, they want to keep trying to extract insights for the particular problem, rather than exploring new use cases.
* I'm going to spend a tremendous amount of time trying to integrate data from a very heterogeneous set of sources from different providers (lots of time on the phone and exchanging emails), rather than have an eng team work on it.
* In line with above, I'm afraid that the organization will become obsessed with pumping out reports or that I will spend the next two years bringing them up to a basic level of analytics maturity.
* When I say ""predictive models"" they think ""financial forecasting"" rather than classification models for e.g. expense categories and feel that even financial forecasting is something ""we are a long ways away from"".
* I'm starting to fear there are limited problems in accounting on which the full breadth of data science can be brought to bear, leaving me with irrelevant experience and ""behind the times"".
* **My future job opportunities at technology companies (which is eventually where I want to end up given the scale of the problems) will be impacted since I'd be coming from a non-technology company, even though I have 9 years experience working in software.**

The good:

* Lots of opportunity to interact with stakeholders, working to understand their business problems, and developing creative data solutions to address them.
* The opportunity to present findings to senior management (CEO, CFO) of company that generates more than $1bn a year in revenue.
* A manager and executive sponsor who seem very excited to become a ""cutting edge"" finance department with respect to technology and analytics capabilities, even though they aren't aware of the all the possibilities.
* I have the opportunity gain valuable change management experience.
* I have the opportunity to work with my manager to build a team of data scientists and analysts if we get a few quick wins.

The big question that I keep asking myself is ""Should I stick this out and put my full effort and passion behind it to make the initiative a success, or am I being overly optimistic in my pursuit of bringing the full breadth of data-driven decision making to a finance department?"".",1
618,,1
619,"Sorry for another career related topic.

I just got a rejection from a Data Scientist job after a technical phone interview. I got Math PhD last summer and I’m currently a Data Scientist in a small company for four months. Due to various reasons I’m actively looking for other opportunities.

The reason they said is “PhD graduates usually go to bootcamps or take online courses to learn data science skills. Since you didn’t do any of them, we think you are not passionate at this career.” 

(I thought) I nailed all the technical questions (machine learning and coding) cause that’s what I’m doing everyday.

It’s such a dump excuse. End rant.",1
620,"I've been confused about what production ready code means. Let's say for example that you completed a random forest on a test set, by using the predict function, you are able to test the prediction on a test set. Why can't you use the predict function in a production environment? ",1
621,,1
622,"Been reflecting on how to use SQL in data science work relative to using (Py)Spark. In general, I'd like to do more with SQL, but find it breaks down for anything more complex than about a dozen lines of SQL. Instead, I've been finding myself using Spark more and more, and find Spark solutions to be more testable and legible with respect to SQL.

Details of my thoughts in the blog post, [The limits of SQL in data science, analytics, and engineering](https://towardsdatascience.com/the-limits-of-sql-in-data-science-analytics-and-engineering-4d7e48271a2f). Most controversial opinion is that I'm thinking Spark, DataFrames, and Scala could be developed and read by non-engineers to totally replace SQL.

What are your thoughts about using SQL in data science? Have you been able to use SQL for larger and more complex work? Are there notable benefits to using SQL in place of Spark Curious what other people think before I start trying to convert more people from SQL to Spark. Thanks!",1
623,,1
624,"I took advantage of the holiday sale to subscribe to Dataquest. While I like the idea of the format, the execution has been a letdown. In several sections in the intermediate python section, the correct code doesn't work due to back end errors. Checking the forums shows this has been an issue for over a month. I emailed support 3 days ago and still haven't heard back. I did get a response from the Twitter account but still no help with the issue. At this point, I am so frustrated with the lack of suppport that I would prefer to get a refund and try another program.

I wish now that I had gone with Datacamp instead.

&amp;#x200B;

\--update 4/3/2019

Dataquest did give me a refund and allowed me to continue working for a month. Outside of the response time and bugs during the changeover, I like their content. I resubscribed yesterday. ",1
625,"Working in SQL/Tableau. Basically we're looking at cancellation rates, and they want to take a small pilot program and measure the cancellation rate, but the program has about 20 customers a month, so one cancellation is 5% which makes the results choppy. 

He's under the impression we can ""normalize"" this data to smooth it out somehow to make it less susceptible to jumping around due to the small number of people in the pilot program. He said something vague about that we shouldn't be separating the pilot, but considering it as part of the entire customer population. He says he's done it in excel in the past but doesn't remember how.

Any suggested topics for me to research on this? Again, we're just running pure T-SQL and Tableau so I can't use anything like R to do any really heavy lifting.

EDIT: I feel I should point out that this isn't estimating future rates, we're looking at the existing rate over the last few months.",1
626,"I've been reading a lot about Bayesian statistics and its relationship to machine learning. I have a fuzzy understanding of many of the concepts, such as maximum likelihood estimation, bayes theoreom, prior/posterior distributions, etc, but if someone asked me in an interview to derive any of that or recall specific distributions from memory, I would be totally lost. I'm not even sure how to use that in a practical setting. 

Basically, is committing a lot of time to mastering bayesian statistics worth it to be an effective data scientist? or is it just something you learn in college and immediately forget?",1
627,"What worked, what are the problems you faced? etc.",1
628,"My current understanding is that “Data Scientists” are concerned with deriving new insights using ETL methods, however with the rise of ML models in production level settings new roles specific for building models have emerged. Now with this in mind I was wondering how many people in the DS world currently have model building and deployment as their central role. If you can share your personal experience that would be awesome.
Thanks!",1
629,"I've been noticing a bit of a trend with some of the new data scientists at my work.  Every problem with a categorical regressand they go straight for a Random Forest without first trying a logistic regression. 

I can only think of a handful of situations where this may be appropriate, for instance when you are too wide for logistic, or maybe when you are correlated to hell and back, but in the former case (and maybe the latter as well) I would probably still suggest a multivariate/discriminant analysis before a random forest.

Anyways, can someone else give me a good reason to go to a Random Forest without trying a logistic (or even discriminant) analysis first?  I'm concerned that either I'm missing something or they are.",1
630,,1
631,,1
632,"Pretty much interviewing for a new company and they sent me a package on google data lab to look over. 

I'm not sure what they want from me. Either they are using it already or they want to know if it's a tool I would want to do data science. 

When I looked into the data lab, its jupyter notebook on a google VM, combined with bigquary for SQL. 

What does google analytics offer more than that? Do you use it?

Does google provide the data too?",1
633,"Got a Microsoft interview coming up, curious on the format/and work environment? 

Thanks!",1
634,"Hi everyone. I would like to make an open call for participation in the Data Science StackExchange.

https://datascience.stackexchange.com/

I have no affiliation with it. This is not an affiliate link. Those of you that are familiar with the stackoverflow, you can understand what a big asset is for the developers to have such a community. If we participate in Data Science StackExchange, we can do the same!

What any StackExchange needs:

1) Votes! Votes! Votes! Votes are the mean to moderate and improve the content of the site.

2) Answers. At the moment, DS has \~4700 unanswered questions. We are a community of 38.000 members. We just need to answer 0.12 questions each of us :P

3) Valid questions. If you have an awesome question (even if you know the answer), put it there. The content is the king. Another user will find it the next day and will really appreciate that someone got his back",1
635,I was watching [this](https://www.youtube.com/watch?v=1I0cUTXwr-k&amp;index=2&amp;list=PLUXSZMIiUfFSe4gpc8PLDECqViWi-2we3) data analytics video and thought the visualization style was really neat. Does anyone know how something like that would be made?,1
636,"I'm having some trouble finding what a reasonable salary for an entry level data science position in Canada is. I'm currently in Toronto and will enter salary negotiations soon with a tech company here. I am graduating with a BSc in Statistics this spring.

When I look on Glassdoor a lot of the salaries are mostly for (what I assume are) senior positions since they're 6 figures.

Does anyone have any insights into salaries for entry-level DS positions? ",1
637,,1
638,"About a month ago the mods asked for feedback on the [subreddit and suggestions for improvement](https://www.reddit.com/r/datascience/comments/adprzt/meta_seeking_input_on_subreddit_rule_and_style/). I have to say that the sub has been noticeably better less than a month later. There's a giant banner that appears when a new submission is made pointing folks to the weekly entering and discussion thread. Additionally seemingly all posts are now flaired appropriately and you just have to look at the current front page to notice the quality of content and discussion is much improved.

Being a mod is a difficult and thankless job, so I just wanted to notice the positive efforts of their work around here!",1
639,,1
640,"I’ve looking at different article that use naive bayes or logistic regression to test a certain feature like (subject line or location). I still can’t find a way that I can use that incorporate both customer history (features) and email features.

Features:

Email features:
 subject line,email type (promo, loyalty, holiday,..etc), delivery date, email text.

Customer features : 
Country, city, device (mobile, desktop,...), domain (yahoo.com, Gmail.com,...)

And the output variable which is (1 (opened), 0 (not opened))",1
641,,1
642,"Recently at work, our boss came over to us (a team of analysts), and asked us: By what % can we improve our demand forecasts in 2019? Evidently, she is making it a personal goal (for performance appraisals) to improve our forecasts by x percentage from last year. For context, we support a call center, and have short and long-term forecasts that help us adequately staff and prepare our budgets. Our demand is for the most part seasonal, however we're very sensitive to events, like when there is poor performance across the system, or an unfortunate tweet - which drive calls to our center and can blow up a forecast.

&amp;#x200B;

I understand the need for accuracy, and will relish in the chance to improve our forecasts, but when performance appraisals get involved, is it setting a bad precedent to hold others accountable for events beyond their control? In our group, PA's affect merit increase the following year.",1
643,"Hi r/datascience!

I would like to share my personal data science project on how I analyzed my weight loss data in 2018. You can read my [writeup](https://link.medium.com/9KJRGuzsqU) on the project on Medium, and check out its Github [repo](https://github.com/dknguyengit/logweight).

The 2 main goals for the project are:

* Build a machine learning model (namely regularized logistic regression) to classify whether I would gain weight or lose weight on a given day given how many calories I eat beyond my allowed budget and my step count for that day. The parameters of the model (the regression coefficients and the decision boundary) are also used to give simple, actionable numbers that I could use for my weight loss journey.

* Build this machine learning model from scratch without using 3rd-party libraries (aside from numpy and pandas). This includes the model algorithm (batch gradient ascent), k-fold cross validation, performance metrics, ROC curve, and other related visualizations. This turned out to be not as intimidating as I'd thought. In fact, the core algorithm for batch gradient ascent can be done in 3 lines of code!

I've tried to tailor my writing to be accessible to beginners (as I'm also a relative beginner to data science). Therefore, I'd truly appreciate any input on how I can make my writing and visualizations better.

Also, I'm thinking of doing to do a 30-day challenge, during which I followed the guideline outlined in the project, and see how consistent I can lose weight doing so (perhaps via daily updates through a Twitter account). I think it might be fun to use this as a real-life test set for my model, but I'm afraid of the potential public failure 😭 If you've read my Medium post, please let me know what you think about this idea.

Please also let me know if you have any question or feedback on my project!",1
644,,1
645,I was wondering if any Data Scientists uses causal inference in their jobs to assess relationships between exposures and outcomes. My background is in Epidemiology and we are taught causal inference and I work as a data scientist in a large healthcare company where causal inference is used because interpretation of models is really important in the healthcare field. I saw Netflix has a lot of economists and researchers that run causal experiments and Microsoft just recently open sourced DoWhy to make causal inference more accessible to more people like scikit learn made machine learning more accessible. I guess my question is do you think causal inference will become more main stream like machine learning in data science? And also which companies are currently using such methods besides healthcare companies etc?,1
646,"Over weekend I have written a ""cookbook"" how would you set up a **docker-friendly** Apache Airflow environment. This is a great workflow management tool, fit not only to Data Science environment. My solution *detaches the actual execution* from Airflow and only manages running Docker containers. Hopefully somebody finds it useful.

https://medium.com/@tomaszdudek/yet-another-scalable-apache-airflow-with-docker-example-setup-84775af5c451",1
647,,1
648,"Hi, I'm fairly new into my first Data Science role where my work thus far has been building a price sensitivity model (Python, mostly).

The team and I have just finished iterating the model for our 4th product. However, there's almost 200 products in total and we're debating how many models we actually want to create. 

The issue is, many of the products are related. Reducing 1 products price may increase sales by 100%, but 3 other similar products reduce by 10%. Alternatively, reducing one product could create a ""halo"" effect, which increases other similar products.

The products have some similar features, but some are unique to the subcategory the product is in.

Are there any methods that I could look into which cover this sort of problem? 

Thanks very much for any tips in advance. ",1
649,"I currently have a somewhat bulky windows laptop with a gtx1080 card and i7 processor and 16 gb ram. 

I wanted to go lighter because it’s a pain in the ass carrying this thing around when I go to conferences or to a library etc. 

If I’m doing machine/deep learning, I will need lots of memory, and a good processor plus gpu right? What about OS? Are Macs more preferable for Dscientists?

I want something that can do deep learning effectively that is also pretty light. Help pls ",1
650,"One of the local universities offers a BI program being taught fully on SAS EM and EG and omitting all coding. I’ve interviewed individuals from this institution who know how to use these two softwares, strictly as a drag and drop program, but have absolutely zero coding knowledge.  This lead to discussions at the office about how much we value coding knowledge and how useful it is in the industry. 

Wanted to know what your thoughts are on the matter. What do you think of a university program teaching BI without any coding? Would you value drag and drop BI knowledge over coding knowledge? Or any other thoughts you may have on this, very curious.

Thanks!",1
651,"Does anyone know of any interesting uses of municipal data, particularly though not necessarily in a private sector context? ",1
652,"Welcome to this week's entering &amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)  
* Traditional education (e.g. schools, degrees, electives)  
* Alternative education (e.g. online courses, bootcamps)  
* Job search questions (e.g. resumes, applying, career prospects)  
* Elementary questions (e.g. where to start, what next)  

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](https://www.reddit.com/r/datascience/wiki/resources) pages on our wiki.  

[You can also search for past weekly threads here](https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;restrict_sr=1&amp;t=month).

^(Last configured: 2019-02-17 09:32 AM EDT)
",1
653,"I find myself having a lot of free time in my current Data Scientist role so I'm considering freelance consulting for small businesses as a side gig. This, I believe, will be great for the money and also provide a means for me to continuously try new problems / update my skills. For current freelancers, how often do you have to deploy models for clients? What deployment / production solutions do you use and why? Also, can you give a rough breakdown of solutions you've provided previously by percentages (e.g. visualization / analytics / insights - 25%, predictive models - 40%, etc).  ",1
654,"I can't count the number of times I had to purge all drivers, install them again, have various screens not detected anymore, and so on...",1
655,,1
656,"I was talking with a colleague today about a bit of materiality assessment I'm working on.  I had found an interesting part in the comparison data that got a hold of our curiosity.  

&amp;#x200B;

But something my colleague said was ... let's leave this out if we can't fully and completely explain it.  Doesn't matter how interesting it is... if you can't explain it will cause more issues than anything.

&amp;#x200B;

What does this sub think?  Do you only provide explainable findings in your documents?  How do you handle interesting but (as of yet) unexplainable findings?",1
657,"I have no experience using Keras, but I'm trying to classify a set of images into the above mentioned categories (and also data charts). I tried using open pre-trained models (VGG16,InceptionV3,ResNet), and it seems that they are used to classify objects, like dog, cat, car, etc. 

Before training my own model, does anybody knows if there is an open pre-trained model for this?

Thanks!",1
658,"Hi, I'm trying to host a data science/machine learning contest at my company. We are an international company, with some branches overseas. Security is a huge issue, since I want to use actual company data for this contest. I have thought about trying to anonymize the data, but realized that wouldn't be possible for most the data I am dealing with. 

&amp;#x200B;

I'm looking for suggestions for how to mitigate security risks with this data. My biggest concern is that if a CSV file of our company data somehow was leaked online. Do you have any suggestions?

&amp;#x200B;

My thoughts/ideas so far:

* Make sure each of the participants agrees not to distribute the information (duh)
* Anonymize the few fields which can be anonymized
* Maybe create a private server where the contestants have to login and create their models remotely. The data would be hosted on the server.",1
659,"Two of the hottest posts from today completely disagree. One says we're entering a data science glut, the other that there's still a huge shortage.

What are the thoughts from the rest of the sub?",1
660,"Hey guys, I've been offered a graduate position in the DS field for a major bank in Ireland and I won't be starting until September, which gives me a whole summer (I'm still in college) for personal projects.

One project I was considering was learning a compiled language, particularly if I wanted to write my own ML algorithms or neural networks. I've used Python for a few years and I love it BUT if it wasn't for Numpy/Scikit-learn etc it would be pretty slow for DS purposes. 

I'd love to learn a compiled language that (ideally) could be used alongside Python for writing these kinds of algorithms. I've heard great things about Rust, but what do you guys recommend?

PS, I saw there was a similar post yesterday but it didn't answer my question, please don't get mad!",1
661,,1
662,,1
663,"What additional language would you use to build tools if you're already comfortable with python?

Does it make sense to have some sort of experience with JavaScript or some sort of front end architecture?",1
664,My company uses amazon for everything and I am trying to use pyCharm as a front for processing done on a EC2 instance. My coworkers dont want to use jupyter notebooks or lab but want a local IDE that can fetch data and run processes in the cloud. Also we want version control etc... Are there resources on how to get started running pycharm locally but doing all the computation and housing all the data in the cloud? Thanks!,1
665,"I use a default project structure that integrates a Makefile for reproducibility. However it would be nice to have some kind of version control on the data/analysis/models and it seems like that's part of the goal with [DVC](https://github.com/iterative/dvc). 

Anyone have experience/opinions on it?",1
666,"I've been working at a new job with a probation period of three months. While my offer sheet has me as a 'Business Analyst Assistant', the job descriptions on it were more geared towards sales (Ex: practice sales by calling on accounts, learn sales admin. by completing sales rotations). This is so that I can grasp our market in the industry and to learn our products. In the interview, I only listed excel, access, STATA as skills.

Well from the grapevine, I've learned that my role was more of a 'Sales Support' and were originally set with a 6 month transitional date to learn. The original role was more of a documentation and liaison for sales.


In the first few weeks they were testing my competencies in ""numbers"", by tasking me with creating reports (pivot tables) through excel. I was finishing the reports quick enough that they have tasked with me doing analysis that isn't just calculating past percent growth or amounts sold. Basically I've learned quickly enough I'm past my transition period and they are giving me additional responsibilities.

Luckily during the first few weeks of having nothing to do (settling in and orientation), I was learning python. I've been doing simple stuff for now, automating excel reports through pandas, simple regression analysis, seasonally decomposing our data and detrending it, and using SARIMA models to forecast our future sales.

Well, its past the two months mark and my manager is asking for a meeting to update and change my job responsibilities for post-probation. 

What would be more accurate job responsibilities that I should put, and should it warrant a change in job title/pay? ",1
667,,1
668,"Hello everyone!

A young data scientist here!  I have recently started a new job where Agile project management is being implemented for data science and there are so many different opinions about it within my team! 

Since I never worked within this framework.. so I was wondering if any of you guys have? And if so, what are your experiences? ",1
669," 

When should you do pre-processing to avoid over fitting?

Do you do it both on the training and the test set, which may give you different values. Or do you apply the same values from the training set to the test set, which may lead to over-fitting.

I am confused by this quote below. For example, if you use mode imputation for a class on the training set, should you use mode imputation on the class for the test set, even if you get a different mode? Also, if you use mean imputation for numerical data in the training set, should you also use mean imputation on the test set (meaning you will have a different mean value than the training set)?

""To provide a solid methodology, one should constrain themselves to developing the list of preprocessing techniques, estimate them only in the presence of the training data points, and then apply the techniques to future data (including the test set).""

[http://www.feat.engineering/review-predictive-modeling-process.html#resampling](http://www.feat.engineering/review-predictive-modeling-process.html#resampling)

&amp;#x200B;

Here is a link to the same question in Kaggle: [https://www.kaggle.com/questions-and-answers/80455](https://www.kaggle.com/questions-and-answers/80455)

&amp;#x200B;

Thanks!",1
670,"From a large recruitment company (Morgan McKinley), they have provided salaries for common analytics jobs. Interestingly they do not have data analysts as a job title, which i thought would be one of the more common ones.

it also looks like we are paid higher than EU and some US counter parts, although in Australia there is no start-up scene where you get equity instead.

link: https://imgur.com/pS3sReu",1
671,"I have built an web-based app where I can enter some text and output a word cloud of it. Currently I'm showing the word cloud as a static image. I would like to replace it with a dynamic image whenever I put my mouse on top of a word, its frequency will show up. My app is built using Python and Flask. I'm wondering how should I realize this function if possible not using any other language? Any hints is highly appreciated. Thanks in advance!",1
672,"Hey Fellow data scientists, I am sure you've seen this: it could be your client, your boss, your colleague. They ask for more. ""Can we try adding another year's data?"" ""Could you check if weather makes a difference?""

There is nothing wrong in asking, but they do not know that adding more data is not like a click away. Sometimes it takes half an hour, sometimes it could take days. So what would you do?

As I jot down the problem, I thought of a fews things we can do, so my 2 cents here:

1. make your model more flexible; anticipate the additional ask
2. be smart about how you share the results: if you know they will ask for more however comprehensive your model is, release in phases
3. clarify the objective: what do you want to prove? what is the hypothesis? how does adding additional data help?
4. communicate the investment here: adding data can be time consuming. are you sure it is worth the effort?
5. bring this issue up over coffee/lunch...

Now your turn...",1
673,,1
674,[https://www.reddit.com/r/medical\_datascience/](https://www.reddit.com/r/medical_datascience/),1
675,"Hi!

I've been using Spark to do lots of data processing on a SLURM HPC Server (i.e. shared memory, no distributed aspect).

I'm realizing that Spark isn't really intended for non-distributed computing. Is there a Spark equivalent for shared memory processing? Should I just keep using Spark?",1
676,,1
677," Welcome to this week's 'Entering &amp; Transitioning' thread!

This thread is a weekly sticky post meant for any questions about getting started, studying, or transitioning into the data science field.

This includes questions around learning and transitioning such as:

* **Learning resources** (e.g., books, tutorials, videos)
* **Traditional education** (e.g., schools, degrees, electives)
* **Alternative education** (e.g., online courses, bootcamps)
* **Career questions** (e.g., resumes, applying, career prospects)
* **Elementary questions** (e.g., where to start, what next)

We encourage practicing Data Scientists to visit this thread often and sort by new.

You can find the last thread here:

[https://www.reddit.com/r/datascience/comments/an54di/weekly\_entering\_transitioning\_thread\_questions/](https://www.reddit.com/r/datascience/comments/an54di/weekly_entering_transitioning_thread_questions/)",1
678,,1
679,"I'm looking for a website that is similar to hackerrank, codewars, but offers more data science oriented challenges (like data wrangling with pandas, maybe some data visualiations, some dplyr excercies, maybe even ML and so on).

Anyone can recommend something like that? So far I found few challenges on hackerrank but not much.",1
680,"I am an overly extroverted person who is seriously considering a career in BI &amp; data science. 

I enjoy working behind the scenes and working technical roles, but I do crave human interaction every now and again because of my extroverted nature. 

Would a data science position be a good fit for an extrovert like me? I am considering an analytical position since I am technically minded and do not enjoy roles with an excessive amount of face time with others. 

Thanks!!",1
681,,1
682,"Hi all -

I'm setting up a data science project/codebase that will need to be applied to different datasets/in slightly different contexts, with a modular and customisable approach. For the sake of discussion, let's assume I want to build code, notebooks and analysis for data coming from 3 countries: `uk`, `us` and `jp`.

I'm using a structure similar to [Cookie Cutter Data Science](https://drivendata.github.io/cookiecutter-data-science/).

A few questions on best practices:

- Should I create a separate folder in the different codebase areas (`data`, `references`, etc) for each case? i.e. `data/uk/raw`, `data/jp/raw`? Or `data/raw/us`, `data/raw/uk`?
- How should I think about code modularity? Should my notebooks and scripts include a general `country` variable at the top and then run everything using this? So preset to `country=""uk""`?

Thanks!",1
683," I'm new to Big Data and I'm trying to understand the topic of security available around Big Data when it comes to Big Data Analytics consultancies.

In particular I would like to know:

1. Do all Data Consultancies use the cloud or do some use private servers for added security?
2. What security measures are available in the Google Cloud Platform specifically?
3. What security measures are available with in Private servers?
4. Any other security measures that may be important when a client trusts you with their data.

I appreciate this may be super-specific so even if someone could point me in the right direction to answering these questions that would be amazing.

I'm just trying to wrap my head around what kind of security features are involved around storing Big Data in the (Google) cloud and on a private server.

Thanks!",1
684,"Out of things like linear algebra, probability, calc, data structures, graph theory, optimization, etc.

For me, it was probability hands down. It's one of the most deceptively fearsome monsters out there. Not super mathematically rigorous but so extremely difficult to apply. Still gives me the heebie jeebies to this day.",1
685,,1
686,"I have been learning Python and a little R, and am fairly new to programming, but this is the goal I have in mind. I want to make sure I am spending time on learning the right things and moving in the right direction. Any help you can offer would be appreciated!",1
687,,1
688,"Any one doing the 10-week open machine learning course? Looking for a study buddy 

It just started yesterday and it’s free incase any one is interested ",1
689,"Hi all,   


I am correctly doing a project where I need weather data as part of demand forecasting.   
I need the data aggregated per day or even week on a zip code basis.   
Some of the variables I  is:

* Temperature
* Sunny / Cloudy / Rain / Snow
* Amount of hours where the sun shined
* Amount of rain / show

Do you know some good packages from which I can get this kind of data?

&amp;#x200B;

Thank you in advance.

&amp;#x200B;

Best regards  
Dat\_Sci\_SAR",1
690,"I have found that in my company, it's hard to come up with the traditional data science/machine learning solutions for the tasks at hand. In my case it's because we are a somewhat recent team with limited access to data, and we mostly use unstructured and unlabeled data.

I wanted to spark a discussion about less traditional products and deliverables for DS and ML. What I have in mind when I think about data science deliverables are reports with trend lines, regressions or more complex predictors such as deep networks. However, I have been thinking if there are other possible solutions when the tasks aren't so straightforward - for example, instead of full automation of a task, building a suggestion tool that helps a human doing that task, or turning a multiclass problem into a binary problem.

Has anyone run into a problem that you couldn't fit to a traditional solution? How did you solve it? Thanks",1
691,"Looking for recommendations for good DS related conferences, preferably around the Balkans or in Germany.",1
692,"Okay, so let's say I built a DL model that uses 300 features to predict if a user will buy an item or not on my ecommerce site. The ecommerce site stores all data on a SQL database, however when building the model, many of the feature names were changed for dummy encoding and other reasons. To make matters worse, the original data extracted does not use the original data labels in SQL, but rather many of the fields were renamed with 'more interpretable' aliases.

How do I ensure that the correct data required to run the model is sent to the API? My guess is that all data would need to be re-encoded with matching labels for the model to use correctly. Has anyone ever run into an issue like this?",1
693,"Hello, I am a data scientist working in finance. I have always been super into electoral politics. I spend on average 1-2 hours a day reading and keeping up and I am working on some models and replications. In short I am a huge US politics nerd and I would like to marry my passion for politics with the craft of data science. It helps that I am also super fired up right now.

&amp;#x200B;

I don't really know how to get in touch - it's not like these jobs are up on LinkedIn. I want to join a Presidential or Senate campaign and help someone I believe in get elected. Does anyone know where to start? I am a Democrat.",1
694,"It’s sad how much time I’ve spent watching this little guy clean my floor. Am I the only one?

Anybody know about the ML that is at work?",1
695,"Hi,

I'm working in a financial firm, analyzing emails to make our client service more efficient.

One of the models I'm working on is to identify and flag emails with potential business impact, ex a client threatening to pull business. I'm pretty sure Amazon does this with their customer complaints and I'd like to do something similar, only I've no training data.

I tried a google search to find similar dataset but didn't get much. I'd love to hear some suggestions on how to approach the problem.

My own thinking is to measure some standard indicators like sentiment, combine it with the number of follow ups the client has sent, the client importance and standardize the result and this can serve as a business impact indicator.",1
696,,1
697,,1
698,,1
699,"I am giving my first steps in data analysis, gathering/cleaning.

To learn, I am trying to create a simple code that can detect heartbeats from color variations from the image coming from the camera on the iPhone.

This is what I have done so far:

I have created a code that detects faces and cuts them from the image.
then I get the average color from that face image.

Because the values are grabbed at irregular time intervals, I have to interpolate the data to convert it to regular time intervals.

Plotting the data I have [this](https://i.stack.imgur.com/bFfGu.png)

I think I am seeing something that looks like heartbeats there.

To confirm that I am not seeing artifacts from the camera, I sample a rectangle from the background and I get the same color with very little random variation. The background color is stable and shows barely any variation.

Now, I apply a Direct Cosine Transform to the data and get [this](https://i.stack.imgur.com/KMg17.png)

The DCT has negative vales.

The two first items of the DCT are peaks, at t=0 and t=0.10482311 seconds.

I read a paper where the researcher says heartbeats occur between 0.4 and 4Hz. I suppose this has a relation why the first two DCT items are peaks...

What do I do now?

I have tried to apply a threshold to zero every term from the DCT below 150 and do an inverse DCT to reconstruct the signal and got [this](https://i.stack.imgur.com/iAOcF.png).

A threshold of 85 gives me [this](https://i.stack.imgur.com/u3ljx.png)

I am not sure if I see a heartbeat there. I mean, the peaks where the beats start.

This is the data at regular time intervals I have (256 samples):

17.0,14.151599,11.303198,8.454798,5.74406,7.5946655,12.173319,18.0,18.0,7.448537,18.0,16.36569,12.0000515,13.0,13.0,13.0,13.0,12.442261,9.134232,11.052017,12.0,7.605861,10.42025,11.911684,3.4419365,2.0,2.0,14.082303,16.227417,9.639368,7.0,3.4693644,5.0578203,7.0,14.859163,8.363442,7.876806,16.721855,16.367476,13.054573,17.416235,6.6276655,11.617707,12.0,6.3224463,11.111255,14.0,14.0,14.0,14.0,8.705125,17.478954,18.0,17.259813,14.371727,12.0,12.0,17.304781,18.0,18.0,2.6055841,9.789778,8.290463,6.3248563,2.3246787,12.944895,2.999961,8.443108,16.994041,7.714527,11.132567,2.2226758,5.6030903,12.528458,16.932209,16.087227,7.9563236,16.43404,8.239223,17.576452,12.102208,15.194642,1.0,1.0,1.0,1.0,1.0,1.0,1.7313459,17.479614,11.889918,11.0,11.0,14.0,14.0,13.802156,12.975004,6.840872,14.405505,7.928815,1.4836411,7.193712,15.371663,6.2666273,6.1682196,17.532732,16.0,15.034918,9.363262,1.0,4.654352,17.0,17.0,17.0,17.0,10.1624565,2.696946,13.607519,10.2923975,1.0,1.49984,9.996923,7.0500054,17.0,17.0,17.343903,13.191299,1.6610342,5.2127213,7.0,5.6532416,3.0295517,12.250117,12.687657,2.9297333,7.463814,9.5274105,13.640531,18.061134,16.376305,5.9621263,4.2103305,7.751727,7.023478,2.4116693,14.6888685,11.718729,4.0103664,12.0,8.606849,1.0,1.0,7.0,7.0,8.867684,12.0,12.0,9.598275,4.9731455,2.0,2.0,2.0,2.4965348,4.843401,5.4067893,3.655766,7.0,11.899609,11.855668,10.36767,16.59431,7.843425,1.9749169,8.829407,12.43066,11.205647,16.514818,17.0,13.328903,11.462145,12.0,12.0,12.0,12.502206,15.606055,18.0,18.0,13.699917,2.0,2.0,8.122738,12.0342,12.311193,9.434023,8.419968,8.64551,2.1631317,7.9250226,13.173435,3.0252013,1.0,1.0,1.0,1.0,1.0,3.7013192,6.0,6.0,6.3827076,7.0,6.570015,6.0,6.0,6.0,6.0,2.8011405,7.071625,15.575444,17.0,17.0,6.811758,1.0,4.5509486,5.3095756,10.288496,13.577595,2.493825,10.179988,12.0,6.3059773,7.9304085,14.911688,8.452748,2.8948724,10.117218,12.0,12.0,15.008322,16.0,7.473282,4.4403195,12.0,12.0,8.330021,6.0,6.0,6.0,11.515245,0.946867,0.83356774,0.95877224,0.05619842,15.221931,16.469358,5.231963,1.7867849

and these are the regular time intervals

0.0,0.03317536,0.06635072,0.09952608,0.13270144,0.1658768,0.19905217,0.23222753,0.26540288,0.29857823,0.33175358,0.36492893,0.39810428,0.43127963,0.46445498,0.49763033,0.5308057,0.56398106,0.5971564,0.63033175,0.6635071,0.69668245,0.7298578,0.76303315,0.7962085,0.82938385,0.8625592,0.89573455,0.9289099,0.96208525,0.9952606,1.028436,1.0616113,1.0947866,1.127962,1.1611373,1.1943127,1.227488,1.2606634,1.2938387,1.3270141,1.3601894,1.3933648,1.4265401,1.4597155,1.4928908,1.5260662,1.5592415,1.5924169,1.6255922,1.6587676,1.6919429,1.7251183,1.7582936,1.791469,1.8246443,1.8578197,1.890995,1.9241704,1.9573457,1.9905211,2.0236964,2.056872,2.0900474,2.1232228,2.1563983,2.1895738,2.2227492,2.2559247,2.2891002,2.3222756,2.355451,2.3886266,2.421802,2.4549775,2.488153,2.5213284,2.554504,2.5876794,2.6208549,2.6540303,2.6872058,2.7203813,2.7535567,2.7867322,2.8199077,2.8530831,2.8862586,2.919434,2.9526095,2.985785,3.0189605,3.052136,3.0853114,3.118487,3.1516623,3.1848378,3.2180133,3.2511888,3.2843642,3.3175397,3.3507152,3.3838906,3.417066,3.4502416,3.483417,3.5165925,3.549768,3.5829434,3.616119,3.6492944,3.6824698,3.7156453,3.7488208,3.7819963,3.8151717,3.8483472,3.8815227,3.9146981,3.9478736,3.981049,4.0142245,4.0474,4.0805755,4.113751,4.1469264,4.180102,4.2132773,4.246453,4.2796283,4.3128037,4.345979,4.3791547,4.41233,4.4455056,4.478681,4.5118566,4.545032,4.5782075,4.611383,4.6445584,4.677734,4.7109094,4.744085,4.7772603,4.810436,4.8436112,4.8767867,4.909962,4.9431376,4.976313,5.0094886,5.042664,5.0758395,5.109015,5.1421905,5.175366,5.2085414,5.241717,5.2748923,5.308068,5.3412433,5.3744187,5.407594,5.4407697,5.473945,5.5071206,5.540296,5.5734715,5.606647,5.6398225,5.672998,5.7061734,5.739349,5.7725244,5.8057,5.8388753,5.872051,5.905226,5.9384017,5.971577,6.0047526,6.037928,6.0711036,6.104279,6.1374545,6.17063,6.2038054,6.236981,6.2701564,6.303332,6.3365073,6.369683,6.4028583,6.4360337,6.469209,6.5023847,6.53556,6.5687356,6.601911,6.6350865,6.668262,6.7014375,6.734613,6.7677884,6.800964,6.8341393,6.867315,6.9004903,6.9336658,6.966841,7.0000167,7.033192,7.0663676,7.099543,7.1327186,7.165894,7.1990695,7.232245,7.2654204,7.298596,7.3317714,7.364947,7.3981223,7.431298,7.4644732,7.4976487,7.530824,7.5639997,7.597175,7.6303506,7.663526,7.6967015,7.729877,7.7630525,7.796228,7.8294034,7.862579,7.8957543,7.92893,7.9621053,7.9952807,8.028456,8.061631,8.094807,8.127982,8.161158,8.194333,8.227509,8.260684,8.2938595,8.327035,8.36021,8.393386,8.426561,8.459737
",1
700,"I am working with certain data arrays of float elements. Corresponding to each vector are other datapoints. I am able to save them as CSV files which encodes the arrays into string on which I run literal eval on subsequent reads. Now, this is a really inefficient way of working with this data as I have millions of such rows. I tried to use HDFStore as I needed append functionality of table mode but it refuses to store the column raising   
""TypeError:Cannot serialize the column \[encoding\] because its data contents are \[mixed\] object dtype"".

Any idea how to proceed?

Thanks",1
701,,1
702,"I hope this is the right place to post this....I was wondering if anyone could point me in the direction of a way to help visualize my data problem. I have a product that can be customized to a high degree. however certain choices aren't compatible with other choices. So I wanted to first of all enter the data in some sort of interface and then from that generate a set of rules from it.

Let's say the product is a kettle that can come in 10 colours. It also has 5 different options for handles, but maybe one handle doesn't come in one of the listed colours so that's an illegal combination.  The kettle also has different power button styles. But some of those buttons don't fit certain handles. It also has different power chords, but they're not all compatible with certain handles etc etc. And maybe there are 2 different plugs that fit certain cables. But you don't choose the plug. The system just selects the plug that fits the right cable. You get the idea. Basically lots of lists of what is compatible with what. 

I started to use free online mind-mapping software to draw connections between all the various bits because it leant itself to how I'm picturing the data in my head, but can't do much with that visual. Is there any software that you can recommend for my purpose? One that will allow me to generate rules that I could use in some custom software to allow only valid variants of the kettle? A nice GUI like mind mapping software would be great.

Essentially it's a whole bunch of IF statements but clearly I don't want to have to write them all out. Especially because there are about 20 of these 'kettles'. I just want some sort of list, or spreadsheet that holds all the data ultimately.",1
703,"if I run a neural network and save weights in keras using `model.save_weights`. For 100 epochs, will it save the weights for best training or validation accuracy or it will save the weights of the last epoch ie 99th epoch weights no matter what the accuracy is. Or will it save the average of accuracies of over 100 epochs(which one though training or validation accuracy)?. 

&amp;#x200B;",1
704,"So I've been at my current role for a little over 1.5 years.  Was hoping to stick it out a bit longer, but for various reasons it feels like it's time to start looking to move on.

I've gotten great experience at this job (first DS job after a PhD in bio and then the insight program) - modeling, SQL, EDA, NLP, and have become a much better coder.  But that only shows in the work I've done at this job.  

So I'm actually leaning toward removing my personal github from my resume this time around, because I have all this experience, and kinda don't want people to glance at my insight project from ~2 years ago and see all this clumsy code (it's not *terrible*, but a lot of that project was just painstaking recoding of messy data, and its certainly not as clean as I'd like.  There's also code for a web-app I built using flask, but I had no idea what I was doing there and am definitely not looking at jobs now that will require anything like that).

So do people agree that for getting interviews for a second job (hopefully senior DS position), showing off side projects is less important than actual experience?  Or will I get dinged for not having a link to actual code I've written?",1
705,"I recently completed a timed 3 hour coding challenge with a company.

&amp;#x200B;

The problem was that most of my analysis was shit. I spent maybe a good hour and half familiarizing myself with the data i.e. making distribution charts, doing "".describe()"", etc. I basically wasted a good chunk of my time trying to figure out if I could include more features, remove irrelevant observations ,etc. The dataset itself was also tricky so I was thinking of doing some other loss function i.e. the median was zero when the variable spanned \[0, inf\]. I was thinking of maybe trying out robust regression for this problem.

&amp;#x200B;

Before I started modeling, I then wanted to test if the assumptions were valid to employ regression.  All of this was in one big ass lazy notebook.

&amp;#x200B;

In the middle of all of this, I noticed I only had like 20 min. left and I didn't write anything down. I tried to clean up my notebook and made some random comments here and there. I did some garbage logistic regression and submitted it just as time was up. It's frustrating since I feel like I wasted a good majority of my time just thinking about the data. I'm 100% sure, I didn't pass.

&amp;#x200B;

What do you guys do?

&amp;#x200B;

What was the rookie mistake I made?

&amp;#x200B;

I NEVER want this to happen again.",1
706,"I see a lot of how do I do XYZ, or what approaches should I take questions on here. But I’ve also noticed a large portion that get deleted after they’ve been answered. Is that due to the mods of sub or are posters deleting their question? I’m leaning towards not answering these types of questions in general because of this type of behaviour but was curious as to why first. 

This is an example : 

https://www.reddit.com/r/datascience/comments/ap0e6r/need_some_direction/?st=JRYJX4I7&amp;sh=88a483e0",1
707,"What are some ways to list the following technical skills:

\-MS office

\-Python

\-R

\-SQL

\-Tableau

\-Bloomberg

&amp;#x200B;

I am always confused/clueless about how to split these! (programs, databases, etc. vs in one single line)",1
708,"As a fledgling, what should one listen to, to maximize the learning. Podcasts are a great way to learn and know what's going on currently in the indutstr, So for starters what are the best Data Science podcasts?",1
709,,1
710,"As a soon-to-be-graduating student of a masters in mathematics I've been looking for jobs that would allow me to actually use math/programming in my day to day routine. Obviously datascience came up pretty soon and it generally felt like a good fit for me.

In Europe though we don't have big tech, and looking around there seem to be more lucrative professions in the math/statistics field. For instance a career like the actuary seems to have a higher salary and demand here, whereas I understand that the converse is true for the US .

What I'm asking, especially to any data scientists active in Europe, is if there is any actual demand for people competent in machine-learning and other advanced statistical methods.",1
711,"I Checked Superset and it was impossible to make it work. Too many issues during installation. I also checked tableau but it is 70 Dollars a month. What I'm looking for doesn't need to be free but it is for a hobby and my own usage so something around 10 bucks a month. 

The stool I need should have: 

\- Integration with mySQL

\- Be able to build dashboards and play around with sports statistics.

\- Have different ways of presenting data (Tables, Graphics, etc) 

As context, I'm not using big data. In fact the maximum amount of records I'd be processing could go around 100k, and the average dashboard will have 1k records. 

What tools would you recommend?",1
712,"Hi everyone,  
I want to up my data science and programming skills (R) by doing a pet project where I get daily ( or weekly) data updates from either scraped data or API calls, or other sources.

I then want to do some sort of cleaning, transforming, analytics on the data and plotting it aswell.  
This should be re-run / updated whenever the data is updated, daily or weekly.

Do you have any good ideas for data sources (API, Websites, etc.) which I can use for such a pet-project?  
Any advice is highly appriciated!

Thank you in advance!

Best regards  
Dat\_Sci\_SAR",1
713,,1
714,"Hi all, I'm relatively new to Data science and have some experience in NLP, using language models for text classification. I've a task at work which basically involves intent classification of emails and was wondering if it's a solved problem? So far I've come across 2 annotated data sets, Enron and Avocado ([http://cs.ru.nl/\~msappelli/data/](http://cs.ru.nl/~msappelli/data/)). However it seems avocado is not free and costs quite a lot ($1500), also a look at different papers in this field indicates a variety of approaches, does anyone have a suggestion on how to go forward with my experimentation, given that our internal dataset does not have any labels as of now.

References: 

[https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/viewFile/17105/16016](https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/viewFile/17105/16016)

[https://github.com/ParakweetLabs/EmailIntentDataSet/wiki](https://github.com/ParakweetLabs/EmailIntentDataSet/wiki)

&amp;#x200B;",1
715,"Hi All,

I'm working on a case study where I have to come up with a solution to minimize the stock outs in a distribution center. Has anyone worked in supply chain related problems? it would be of great help if I can get some guidance.",1
716,"Using the web browser, I see that the image *alt* attribute contains tags as to what their image recognition tech believes the image contain. Any idea why they might be doing this?

https://i.redd.it/5y5fn4zfrmf21.png",1
717,"I post something similar on the BI sub but want to have/ get some discussions going with the DS folks as well:

I was talking to a BI professor and he said the BI field is basically a ""*rebranding*"" of *Statistics* (and elements of C*omputer Science*). Since BI and DS are so closely related together,  he also implied that the activities going on with BI (which include DS) *are nothing new* and ***have been going on for ages*** (i.e. now it's just a rebranding exercise):

* Do the DS folks here agree with his views?
* Do you think DS as well will be re-branded in future? (What do you think it will be?)",1
718,"I am new to data science and am trying to work on projects to learn interactively. I am working on a project trying to find coordinates of branches of stores. I am having trouble figuring out a way to get a list of the addresses easily. For example, if I wanted a list of Costco's in Texas, what would be the best way to go about getting the data set without like copy pasting from Google results or from their website search results? 

Once I have a data set of the addresses, I think using something like Google's Geocoding API would be the best for getting latitude and longitude coordinates. 

Thanks in advance for your help. Looking forward to working on DS projects. ",1
719,"I'm an MS student specializing in Data Science and an intern at a start up that has a way to predict revenue using a decision tree and it's really inaccurate. My task was to optimize the current model to make it more accurate, but I told them that I'll probably need to start over using a different algorithm. I am currently cleaning the data (there's a bunch of missing and inaccurate data, but I've managed to clean that up somewhat), and was wondering what type of algorithm I should be using for this? I've got almost 21 different attributes/possible predictors for the revenue for each type of transaction that was done. These include things like the type of service that was used for the transaction, the client, the start date and end date for each transaction, a minimum and maximum estimate of how many hours the person who was involved in doing the work for the transaction, the actual amount of hours it took, and many others. 

&amp;#x200B;

Basically, I want to be able to feed these predictors into the model as that data comes in, which will show that predicted revenue for the end of the month. Any ideas?",1
720,"Hello data friends! I just wanna check in and share my journey over the last few years. It's atypical, and maybe the outcome would not be ideal for some of you but I think it's just dandy for me.

I graduated in 2014 with a double major in theoretical mathematics and behavioral science. Note, that this left me with no applied math like stats, and deep understanding of calculus and a little topology. I struggled to break into the tech world, and wound up doing a lot of random jobs, from retail to manual labor. 


I discovered data science and machine learning through Andrew Ng's coursera in 2016. I did the Galvanize DSi in early 2017, after about six months of self-study. During the job search, I continued working in a labor field I really enjoy (not going into it here, but it involves music, climbing on steel beams 100+ ft in the air, and a lot of rope). I ended up finding some contracts that supplemented that income well, and enjoyed the variety for a bit over a year. One of those contracts required me to learn Golang for ETL work. The same contract had a few opportunities for interesting mini-projects, but nothing really deep or involving machine learning.


At the end of 2018, I asked my boss at that company what the possibilities were for me in 2019, and he was honest. It'd be more of the same, and he didn't have the time or money to offer me more training to focus on development. So, I resumed my job search.

Since then, I did 51 applications. Four responses, three phone interviews, and then something strange happened. I had gotten to the in-person interview at a major organization, and the Golang experience on my resume caught their attention. I was forwarded to an engineering division, did a phone interview, code interview, then finally flew out this week for in-person interviews. No immediate offer, but I was told to ""start packing"" by their director of engineering as I left the building. 

My title and pay will be as a mid-level engineer, but they're hoping I can act as their liaison between engineering and data science and I am BEYOND stoked for the challenge. As I said above, I imagine the more academic folks here wouldn't be satisfied with this outcome, but I couldn't be happier. I'll be moving to an area of the country I love, working on a huge variety of tasks, with opportunities to learn and go back to school. 


It was a long, frustrating road to get here. 100% worth it. I was described as ""a wild stallion, ready to come to pasture and be broken"" in the interview. Uncomfortable description, honestly, but entirely accurate. I've blazed my own trail, and it was scary and uncertain at times, but it's turned out well. 


Here's to all you weirdos! Keep trying! You can do it!",1
721,,1
722," Hi,

The idea behind *Black Swans Meetups* is that: if data-scientists meet with new data-scientists, they will discover wildly different (often better) approaches, models, etc., which can be applied to whatever they are working on.

Paul Erdős, the most prolific mathematician ever to have lived, recognised this. He was always travelling around, staying with different mathematicians who gave him new ideas to prove new theorems. His motto was “another roof, another proof”.

I imagine each meetup would be held in some capital city, and data-scientists could go to share ideas, give cool presentations about what they’re working on, etc.

Please comment below your thoughts. To learn more, go to: [www.blackswans.io/post/143](https://www.blackswans.io/post/143).

Jack",1
723,"Hello all,

(Note: haven’t taken calc or linear algebra-planning on learning that later-want to get some data analyst projects under my belt while I learn more advanced stuff

So right now I’m going through OpenIntro to Stats to brush up on my Stats knowledge. I’m just curious if there is any book at there, in Python, that goes over the tools for Python in data analysis. Also is there a book that goes through projects and tutorials just to get a hands on approach to implementing what I’m learning?

(Mocs, books, papers, etc all welcomes but books preferred)

Thanks Y’all!",1
724,,1
725,"I'm having a hard time cleaning up lots of inconsistencies in my dataset.

These are company name with formats like these:

McDonalds - McDo - Mc Donalds 

Guns and Fun - Guns n Fun

Golden Boy 112309 - Golden Boy 998635 - Golden Boy 214938

Century Hotel by Hotelier CA - Century Hotel by Hotelier NY - Century Hotel by Hotelier MA

&amp;#x200B;

Your suggestions will be greatly appreciated. Thank you.

&amp;#x200B;",1
726,,1
727,"Might be a dumb question... or not appropriate for this sub. But I was thinking deeply about this problem recently.

Is extrapolation ever a big concern for anyone here?

2 cases,

1) Due to realistic constraints, training data might not cover enough numerical range. So you might be extrapolating on some out-of-sample data.  

2) Even if you have a big training data, what if it's not covering a realistic numerical range for OOS data that is rare but can happen?",1
728,"```python
# Import keras
from keras.applications.resnet50 import ResNet50

# Download a weights in hd5 format
resnet = ResNet50(weights='imagenet')

# Import h5py
import h5py
path = '~/.keras/models/resnet50_weights_tf_dim_ordering_tf_kernels.h5'

# Load a file
f = h5py.File(path)

# List all the keys
list(f.keys())

# List all the layers in CNN
layers = f.attrs['layer_names']

weights = {}
# Get weights for all the layers
for layer_name in layers:
    g = f[layer_name]
    for weight_name in g.attrs['weight_names']:
        weight_value = g[weight_name].value
        name = str(weight_name).split(""'"")[1]
        weights[name] = weight_value
```",1
729,"I am a student, so I use pycharm community edition. Is there any mode, lib or anything enabling to work with cells comparable to Spyder or is the only way to upgrade to professional version?

&amp;#x200B;",1
730,"Hi-- I have a basic understanding of how to use Python to create a random forests model. I have some data that has a person's age, gender, location, and so forth (I do not have smoking status in my data), and I would like to be able to predict whether or not each person in a smoker. However, I don't have a dataset to train a model on. I am trying data.gov and most of what I see is already aggregated. Anyone know of another way to find data for this?

Thanks!",1
731,"I recently decided to pivot from a more BI career to a Data Scientist/Analyst career, in order to grow into a more senior role, responsible for data strategy and the like. To this end I decided to go back to school, get my pre-reqs and start a Masters in Statistics. 

However, even entry-level Calculus and Linear Algebra punished me and I had to basically give up, having learned that this was something I definitely did not have in me. I do feel that I'm intelligent, just not in the same way as someone who's very comfortable in Mathematics. Of course the Masters in Statistics is out of the question. 

Which of course bring me to my future career. Is there a place for someone who doesn't ""get"" Math easily? If so, how?
",1
732,,1
